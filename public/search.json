[{"title":"写给 28 岁的自己","subtitle":"一场告别、一段迷茫与一次自愈","url":"/posts/softness-and-strengh-at-28/","date":"2025-09-10T13:43:27.000Z","updated":"2025-09-11T03:51:26.000Z","category":"碎碎念","tags":["成长","感想"],"content":"临近我 28 岁生日时，我原本并没有写文章的打算。但这几天，一股强烈的倾诉欲突然涌现。一方面，近期似有若无的迷茫始终萦绕，我不知如何去捕捉并驱散这种迷茫，只能试着用文字描摹出我当下的心理状态；另一方面，也是最关键的，我想通过这篇文章，对照着过去几年写给自己的文字，看看我是否活成了曾经期待的模样。\n\n<!--more-->\n\n## 恋情结束\n\n\n今年我的状态并不好，很大部分原因是突如其来的分手，前女友在很短期的时间内喜欢上了她公司的其他人，向我并提出了分手。一开始出于恐惧失去这份感情、这份生活方式，我不断尝试过沟通，找出我们之间不契合的点，甚至努力改变自己以挽留她。但没有什么结果，四月中旬彻底分手。\n\n分手后我们仍有一些事情纠缠在一起：我的 Spotify、VPN、ChatGPT 订阅都还在和她共享；我之前在深圳的一些行李物品也都还在她家里放着，毕竟我家里在装修，所以就想干脆等家里装修结束之后再寄回来。前几天，我告知她可以把我的东西寄回给我了，她说我的显示器用着还可以，想继续留着用，我想了想家里的显示器也够，而且也不知道外包装还在不在、能不能邮寄，就答应了。\n\n东西寄完之后，我觉得是时候为这一切划上句点了，便告知她若想继续使用订阅，需从今天起和我平摊费用。她立刻回道：「那快递费也要你自己出哦」。看到这句话的这一刻，先前所有的不甘与残留的温情仿佛瞬间蒸发。我的指尖在键盘不断敲击，又反复按下退格键，最终语气平静地回复：「可以，那也请你结清这几个月以来的订阅费用以及显示器的折旧费吧」。她争辩了几句，我脱口而出「你不懂感恩」。她沉默后道歉了。而我在那一瞬间感到的并非是胜利，而是一阵深刻的恶心，随即是前所未有的清醒——或许我不想承认，但这几个月我一直在用「共享订阅」等方式拖延告别。我的内心或许还期待着一丝感激，而对方却早已将这一切视为理所应当。\n\n我忽然明白：若要靠自己不断让步才能去挽回这段感情，就算能挽回，而自己也必然会失去下一次的自己。莫名地又觉得她这次的道歉有些讽刺，恋爱的时候道歉总是我先说出口。\n\n这一段自 2020 年 3 月起，长达五年的感情，以这样的形式收尾了。我也终于完成了对这段关系的祛魅。这五年我也经历了很多难忘的时刻，我坦然为我当时的心动买单，我并不后悔，换成下次我依旧敢这样。\n\n分手后带来的情绪波动，也让我更容易的陷入了对未来的迷茫之中。\n\n## 迷茫之中\n\n\n迷茫并不是在最近才纠缠上我的，或许它始终围绕在我的身边，前几个月还有装修分散我的精力，但如今尘埃落定，这几天的迷茫情绪又开始占据上风。细想之下，这份迷茫，底色是我对未来的不确定。\n\n每当我站在人生的十字路口时，前方总会出现一团迷雾，让我无法看清前方的路，也不知道该朝哪个方向走。在大学的时候，我就想我以后一定要找一个离家很近、工资也不低的工作；第一份在武汉的工作满足了我对未来的期许，可惜遇到了管理风格我不能接受的领导，此时我又想我一定要找一个轻松一点，让我自己能学到东西的工作；在下一份深圳的工作我又满足了上一次对未来期许，但好景不长，让我对接客户时，我又想我一定要找一个更轻松的外企，不再有对接客户的烦恼；直到离开上家公司，现在我却没有找到一个轻松的外企了。\n\n如今回首看这几个关键的十字路口，不论我当时下定多大决心、做的什么决定、在不久后我发现我都选对了，只是在此刻以结果论来看也没有多么大的区别。虽然我的工作生涯暂时停止，但人生永远都会有新的十字路口出现。时间总会向前推进，和我处于什么状态都无关。\n\n我也明白了一个道理：当你有工作的时候，几乎所有的烦恼都是和工作相关的，心里想的都是放假、辞职、休整。可当你真的没工作了，会发现要面对的烦恼更加复杂、多样化。因为工作本身不止提供给你工资，还会给你带来社会身份与地位的认同感，当在职时的焦虑从时间稀缺、工作内容厌恶转变成了离开工作岗位后对金钱与前途的不确定，很难说二者谁更耗费心力。根据我的经历来看，这二者之间心态的转变通常会在半年左右稳定下来。\n\n我有些朋友在离职之后，会非常的焦虑，我也会劝他们在家好好休养一段时间，但他们担心长时间休养会让自己「退化」，这样会不会无法再融入到职场之中，陷入一种对自我存在性的焦虑，所以往往就是一段工作紧接着下一段的工作。我并不属于这样的人，两年多过去了，在刚离开工作岗位前半年会想想当时是不是继续工作是更好的选择，半年后这种想法已逐渐消散，如今我偶尔也会怀念一下公司上班时的日子，但我确信我已经无法再回到这种日子了。\n\n对于如今又站在人生十字路口的我来说，执着一定要先找到驱散眼前的这片迷雾的办法，或许并不是最好的办法，只需要慢慢沿着过来的道路前进，终究会能看清脚下的路。\n\n最近也和一个很好的朋友聊我的困惑，他说：「人的组成不光是靠精神或者意识，同时也靠肉体」。迷茫是属于精神层面的，这方面目前的我或许把握不住，但没关系，试着慢慢学会在精神层面与迷茫共处的同时，把握住肉体层面我能掌控的就好（比如健身）。\n\n## 8 年前的期待\n\n\n随着年纪增长，越发感觉到时间的残酷，刚毕业那会，我十分确信我能凭借技术找到一份不错的工作，因为对当时的我来说，技术就是我的兴趣爱好，也是我所追求的。但从 2021 年起，GitHub 的提交次数逐年下降或许在暗示我对「技术本身」的热情正在逐渐减退，这也同样加剧了我的迷茫与焦虑。\n\n但我不知如何才能去干预这种心态的变化，亦或者我不知是否应该去干预。这并非是我技术水平下降的多么厉害——如今 AI 技术的发展迅猛，善于使用工具的人只会比过去的人技术更强。让我不安的是：我是不是失去了「用技术改变一切」的心气。我常听到「技术只是工具」「技术应服务于业务」。可如果连手持工具的欲望都淡了，业务于我又有什么意义？所以我之前一直提醒自己要对技术保持热情。\n\n直到这次家里装修，我才意识到：我并不是失去了「用技术改变一切」的心气，而是走出了「手里只有一把锤子、眼里都是钉子」的阶段。心气还在，只是从「迷恋技术工具」转向到了「在现有条件下解决问题」上。\n\n这段时间我把热情投向了生活里存在的问题：独立设计并施工小型健身房；自己配木板并改色与桌腿做升降书桌；搭建铝型材衣柜；自选五金与柜门，拼装折叠衣柜门等等。这些产品同样有用户（我和家人）、有约束（预算、动线、美观）、有迭代（按现场不断改设计稿）、有交付（可用性、可维护性）。这种成就感相比于我独立上线了一个项目来说，有过之而无不及。\n\n回看当年我 [写给 20 岁的自己](/posts/11ab0263/)，大部分文字如今看来略显稚嫩与理想化。唯独文章末尾那句：「我不要自己做到最好、最优秀，只希望能在接下来的时光里，变得柔软而坚韧」，至今读来仍令我感慨。如今 8 年过去，我可以说：**我的确做到了**。只是在前进的过程中，心里偶尔也会闪过念头：柔软与坚韧，就够了吗？我似乎仍在寻找一个确定的答案，却始终没有定论。但这个答案真的重要吗？\n\n28 岁，我渐渐明白，或许我不必执着于一个答案，我只需要继续相信这一路走来的方式。愿我继续保持柔软、选择坚韧，在迷茫中走出属于自己的路。也许在未来某个瞬间，我会意识到：原来这一路走来的过程，就是答案。\n\n---\n\n阴历生日还未过去，所以这句祝福还不算迟——28 岁生日快乐，送给自己。"},{"title":"Solana Address Prefix Character Probability Analysis","subtitle":"Why Does the Same Character Have Different Difficulty?","url":"/posts/solana-vanity-prefix-vs-suffix-probability-en/","date":"2025-05-15T11:33:23.000Z","updated":"2025-05-15T14:33:23.000Z","category":"分享境","tags":["Solana","Base58","Probability"],"content":"Recently, someone opened an issue on my SolVanityCL repository about an interesting problem: for certain strings used as prefixes or suffixes of an address, the time to find a matching address can vary significantly.\n\nI didn’t think it was a big problem initially, so I replied to him simply that it was caused by the algorithm: Solana’s public key is unpredictable, even when private keys are incremented consecutively. Therefore, the estimated time is not accurate. However, he told me that he had tried Solana’s official keygen command-line tool and found that the time gap wasn’t as large as with my tool.\n\nThis was interesting and interested me, so I took some time to find the reason for the problem. I was sure the ED25519 algorithm I used was correct, because otherwise the public key would not be the same as the result from Solana’s official command-line tool.\n\nI checked the source code of Solana keygen and found some details, but they were not what I expected. I thought it would use a different method to get the random seed, but it still gets random bytes from the system random number generator. However, it includes pruning behavior. When a user specifies some prefixes, pruning can filter out invalid addresses before matching the prefix patterns, reducing the time needed for prefix/suffix pattern matching. However, it still can’t skip the public key derivation process.\n\nFor example, when the user specifies the prefix character `a`, the length of the generated public key address is 44, so there’s no need to match the pattern—when the prefix is a, the public key address length will always be 43. It’s amazing, isn’t it? I will explain the details in this article, and you’ll see why the same character affects the prefix-matching probability.\n\n> Before we dive in, I want to list all the characters in the Base58 alphabet: 123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\n\n## An Invisible Rule for Public Keys\n\nThe length of an Ed25519 public key is 32 bytes, so its theoretical maximum value occurs when every byte equals 255:\n\n```python\n>>> from base58 import b58encode\n>>> max_bytes = (2**256 - 1).to_bytes(32, 'little')\n>>> b58encode(max_bytes)\nb'JEKNVnkbo3jma5nREBBJCDoXFVeKkD56V3xKrvRmWxFG'\n>>> len(b58encode(max_bytes))\n44\n```\nAfter Base58 encoding, the resulting address has length 44 and always starts with ‘J’. This means that for a 44-character address, the first character can never be any letter after ‘J’ (K, L, …, Z). If one of those letters appeared first, decoding the address would produce more than 43 bytes—impossible for a 32-byte public key.\n\nMeanwhile, for characters K, L, …, Z to appear as the first character, the address length must be 43.\n\n| **Base58 character length** | **Number range**             | **Probability (32-byte range)** |\n|-----------------------------|------------------------------|---------------------------------|\n| 44 characters               | $$58^{43} \\le N < 2^{256}$$  | ≈ 94.20%                        |\n| 43 characters               | $$58^{42} \\le N < 58^{43}$$  | ≈ 5.70%                         |\n| ≤ 42 characters             | $$N < 58^{42}$$              | ≈ 0.10%                         |\n\nThe 43-character address space accounts for about 6% of the 44-character space. As for ‘J’, which is the first character of the theoretical maximum 44-character address, its address space is larger than that of any 43-character address but smaller than that of other 44-character addresses. \n\nThe second character of this maximum address is ‘E’, so the second character cannot follow ‘E’ and can only be in the range 0–E (14 possibilities). Therefore, among 44-character addresses, the probability that the first character is ‘J’ is 14 / 58 = 24.1%.\n\n## Real Test\n\nI will use actual code to simulate the frequency of each character as the first character. Because the theoretical maximum coordinate is not on the Ed25519 curve, we need more real tests for analysis.\n\n```python\nfrom nacl.bindings import crypto_sign_seed_keypair\nimport base58, secrets, collections\n\ncounter_starts = collections.Counter()\ncounter_seconds = collections.Counter()\ncounter_both    = collections.Counter()\ncounter_ends    = collections.Counter()\n\ndef increase_key32(private_key) -> bytes:\n    current_number = int(bytes(private_key).hex(), 16)\n    next_number = current_number + 1\n    new_key32 = list(next_number.to_bytes(32, \"big\"))\n    return bytes(new_key32)\n\nprivate_key  = secrets.token_bytes(29) + b'\\x00' * 3\nfor _ in range(5_000_000):\n    pk, _ = crypto_sign_seed_keypair(private_key)\n    addr  = base58.b58encode(pk).decode()\n    counter_starts[addr[0]]  += 1\n    counter_seconds[addr[1]] += 1\n    counter_ends[addr[-1]]   += 1\n    if addr[0] == addr[1]:\n        counter_both[f'{addr[0]}{addr[1]}'] += 1\n    private_key = increase_key32(private_key)\n```\n\nFor 43-character addresses, before considering first characters K–Z, we must exclude first characters 1–J. The overall probability of a 43-character address is 5.7%, so the per-character probability is 5.7% / 58 = 0.10%.\n\nThere are two cases when the first character falls in the range 2–J:\n\n1. 44-character address space: the probability that the first character is ‘1’ is (1/256). For the other characters, the average probability is $$\\frac{0.942 - \\tfrac{1}{256}}{16.241}$$\n\n2. 43-character addresses: each character’s probability is approximately (5.7%/58  = 0.10%).\n\nThus, the probability that the first character is in the K–Z range is about 1.7% of that in the 2–J range.\n\n```python\n>>> print(counter_starts)\nCounter({'9': 296710, 'C': 295743, ..., '2': 289724, 'J': 71823, '1': 19541, 'r': 5192,  ..., 'T': 4894})\n```\n\nIf we compare ‘r’ and ‘C’: $$ \\frac{5192}{295743}\\approx1.76\\%$$, which is very close to our calculation; If we compare ‘J’ and ‘C’: $$\\frac{71823}{295743}\\approx24.3\\%$$, also close to our expectation.\n\n## Remaining characters\n\n```python\n>>> print(counter_seconds)\nCounter({'3': 95358, ..., '1': 89821, ..., 'm': 83861})\n```\n\nFor the remaining characters (for example, the second character), they appear with approximately equal frequency, which indicates that the distribution of ED25519 public keys is uniform.\n\nIn other words, the difficulty of matching an address pattern depends only on the first character. The root reason is that the number of possible values represented by 32 bytes ($$2^{256}$$) is not equal to the number of possible 44-character Base58 strings ($$58^{44}$$). If these two numbers were equal, there would be no significant probability gap around character ‘J’.\n\nI will not print the result of counter_ends; you can test it yourself. The result is similar to counter_seconds: each character has the same frequency.\n\n## Is character '1' special?\n\nYou might notice that the number of times the first character is ‘1’ is greater than that for K–z but less than that for 2–H. if we compute the frequency of ‘1’: 19541 / 5000000 = 0.0039082, which is close to 1/256 (≈ 0.00390625). \n\nThis is a particular situation for base58: base58 encoding transfers bytes to characters. A byte ranges from 0 to 255, but after encoding there are only 58 possible characters. Therefore, some characters must occur more than once. However, the character ‘1’ appears as the first character only when the byte is 0. That is why the probability of ‘1’ as the first character is 1/256.\n\nNow let’s look at the case where the first character equals the second character:\n\n\n\n```python\n>>> print(counter_both)\nCounter({'BB': 5275, ..., '88': 4885, 'vv': 105, ..., '11': 65, 'ZZ': 65})\n```\n\nIn the first-character statistics, ‘1’ occurs more often than K–z, but in counter_both the occurrence of ‘11’ is much smaller. Calculating its frequency: 65 / 5000000 = 0.000013, which is close to 1/(256×256).\n\nTherefore, for prefixes consisting entirely of ‘1’s, the behavior is indeed different: each ‘1’ corresponds to byte 0, and if the prefix length exceeds 2, it has the minimum probability.\n\n## Final decision\n\nAssume the length of the prefix or suffix you want to match is $$L$$.\n\n### Suffix matching\n\nEach character is equally likely, so the probability of matching a suffix of length $$L$$ is $$(\\frac{1}{58})^L$$.\n\n### Prefix matching\n\nPrefix matching is more complex. First use the empirical probabilities from the table for the **first character**:\n\n| Range            | Characters          | Total Probability | Single-character probability $$p(C)$$ |\n| ---------------- | ------------------- | ----------------- | ------------------------------------- |\n| ‘1’              | only 1              | 0.39%             | 0.39%                                 |\n| ‘2’–‘9’, ‘A’–‘H’ | 16 characters total | 94.15%            | 5.88%                                 |\n| ‘J’              | only J              | 1.45%             | 1.45%                                 |\n| ‘K’–‘Z’, ‘a’–‘z’ | 40 characters total | 4.0%              | 0.1%                                  |\n\nThen the full-prefix probability by cases:\n\n1. **All ‘1’s** Every ‘1’ corresponds to byte 0, so $$P =(\\frac{1}{256}) ^{L}  $$;\n2. **First character not ‘1’**  $$P = p(C)\\frac{1} {58} ^{L - 1}$$.\n\n> **Disclaimer:** All of the above probability analyses assume that the integer corresponding to an **ED25519 public key is uniformly distributed** over $$[0,2^{256}-1]$$. Additionally, the values given are theoretical probabilities and do not guarantee that you will obtain a matching address within the expected number of trials."},{"title":"Solana 地址前缀字符概率分析","subtitle":"相同字符为何匹配难度不同","url":"/posts/solana-vanity-prefix-vs-suffix-probability/","date":"2025-05-10T14:11:23.000Z","updated":"2025-05-10T14:11:23.000Z","category":"分享境","tags":["Solana","Base58","Probability"],"content":"最近有人在我的 SolVantityCL 的项目里[提了一个 Issue](https://github.com/WincerChan/SolVanityCL/issues/52)，说了一个很有意思的问题：某字符串在分别作为前缀和后缀时，找到满足要求的地址耗费的时间是不一样的，差距还很大。\n\n我一开始没太把这个问题当一回事，只是简单回复了一下他，说这个是算法的问题，因为 Solana 即使私钥连续递增，但公钥的变化仍然是无序的，因此按照概率去预估耗费的时间可能会有误差。但是他又回复说他使用 Solana 的官方 Keygen 命令发现同样的字符串在前缀和后缀的难易程度的差距并没有使用我的工具表现的差距这么大。\n\n<!--more-->\n\n这就有很有意思了，也引起了我的兴趣。所以我专门花了点时间研究了一下这个问题的背后原因。因为我很确认，我使用的 ED25519 密钥生成的算法是正确的，不然的话公钥也不会和 Solana 的 Cli 算出相同的结果了。正因如此，这才是我感觉到奇怪的地方。\n\n所以我去翻了一下 Solana-Keygen 的源码，有收获，但和我预想的并不一样。我以为是它的随机数种子获取的方式的和我不一样，但查看之后我发现它用的仍然是从系统的随机数种子取的字节（rand_os::OsRng）；不过我发现它还额外包括了[剪枝操作](https://github.com/solana-labs/solana/blob/master/keygen/src/keygen.rs#L661)。这个操作本身是在用户指定某些前缀的情况下，在匹配前缀前，就过滤掉某些非法的地址。这样能稍微省略掉一些前缀 / 后缀模式匹配的时间。但是，这仍然无法省略掉通过私钥派生出公钥的过程。\n\n举个例子：当用户指定的前缀是 `a` 时，那么如果私钥生成的公钥的地址是 44 位的，那么就意味着不需要进行后面的前缀匹配操作了，因为用户指定的前缀是 `a` 时，生成的公钥地址一定是 43 位的——很神奇对吧？接下来本文就深入分析一下，看看究竟是什么原因影响了不同字符前缀匹配的概率。\n\n> 在此之前，我想先列一下 base58 所用到的所有字符集合：123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\n\n## 公钥中隐藏的规则限制\n\nED25519 所使用的公钥是 32 字节的长度，那么它理论最大值就是所有字节全部都是 255 的情况：\n\n```python\n>>> from base58 import b58encode\n>>> max_bytes = (2**256-1).to_bytes(32, 'little')\n>>> b58encode(max_bytes)\nb'JEKNVnkbo3jma5nREBBJCDoXFVeKkD56V3xKrvRmWxFG'\n>>> len(b58encode(max_bytes))\n44\n```\n\n这个公钥坐标经过 base58 编码之后地址长度是 44 位，首字符是 J，这意味着在 44 位长度的地址里，不会出现 J 往后的字符了：K，L,...,Z。因为如果出现了 J 之后的字符，那么 44 地址的长度通过 base58 解码之后的字节数就要超过 32 了。\n\n这也意味着，在 K-Z，a-z 的字符里，如果你想要它在地址的首字符出现，那么只能是 43 位长度的地址。\n\n| **Base58 字符总长度** | **数值区间**               | **占 32 字节全集合的概率** |\n| --------------------- | -------------------------- | -------------------------- |\n| 44 字符               | $$58^{43} \\leq N < 2^{256}$$ | ≈ 94.20 %              |\n| 43 字符               | $$58^{42} \\le N < 58^{43}$$  | ≈ 5.70 %               |\n| ≤ 42 字符             | $$N < 58^{42}$$          | ≈ 0.10 %                   |\n\n而 43 位长度的地址空间，与 44 位的地址空间相比，占比只有 44 位的 6%。至于 J —— 理论最大值正好是 J 开头的，所以它会比 43 字符的地址多一部份的空间，但是又比 44 字符的地址少一部份空间，因为这个理论最大的地址第二位是 E，所以也不能取到 E 之后的字符空间，也就只能取 0 到 E 之间的 14 个字符，因为首字符 J 的概率是也就是其他的 44 字符空间的 14 / 58 = 24.1% 左右。\n\n## 实际的测试\n\n接下我会用代码实际模拟一下各字符的出现频率。毕竟刚刚所说的公钥理论最大值其实并不在椭圆曲线上，因此还是需要结合实际的测试结果来具体分析。\n\n```python\nfrom nacl.bindings import crypto_sign_seed_keypair\nimport base58, secrets, collections\n\ncounter_starts = collections.Counter()\ncounter_seconds = collections.Counter()\ncounter_both    = collections.Counter()\ncounter_ends    = collections.Counter()\n\ndef increase_key32(private_key) -> bytes:\n    current_number = int(bytes(private_key).hex(), 16)\n    next_number = current_number + 1\n    new_key32 = list(next_number.to_bytes(32, \"big\"))\n    return bytes(new_key32)\n\nprivate_key  = secrets.token_bytes(29) + b'\\x00' * 3\nfor _ in range(5_000_000):\n    pk, _ = crypto_sign_seed_keypair(private_key)\n    addr  = base58.b58encode(pk).decode()\n    counter_starts[addr[0]]  += 1\n    counter_seconds[addr[1]] += 1\n    counter_ends[addr[-1]]   += 1\n    if addr[0] == addr[1]:\n        counter_both[f'{addr[0]}{addr[1]}'] += 1\n    private_key = increase_key32(private_key)\n```\n\n至于在 43 的地址空间里，想要判断首字符落在 K - z 的概率也要先除开落在 1 - J 的里面的情况，首字符概率大概就是 5.7% / 58 = 0.1%， 而首字符在 2 - J 的概率分两种情况：\n\n1. 44 地址空间里，字符 1 的概率是固定的 1 / 256，那么其他字符的平均就是$$\\frac{0.942 - \\frac{1}{256}}{16.241}$$，分母是 16.241 是因为 J 开头的地址空间与其他的字符相比并不完整；\n2. 43 地址空间里，大概也是 5.7% / 58 = 0.1%。\n\n因此首字符落在 K - z 区间的概率理论上相当于是 2 - J 区间里的 1.70%。\n\n```python\n>>> print(counter_starts)\nCounter({'9': 296710, 'C': 295743, ..., '2': 289724, 'J': 71823, '1': 19541, 'r': 5192,  ..., 'T': 4894})\n```\n\n比如我们这里选用 r 和 C 做对比：5192 / 295743  = 1.76 %，非常接近我们对于概率的计算了。\n\n而对于 J 和 C 对比：71823 / 295743 = 24.3%，同样非常符合我们的期望。\n\n## 非首字符的情况\n\n```python\n>>> print(counter_seconds)\nCounter({'3': 95358, ..., '1': 89821, ..., 'm': 83861})\n```\n\n对于非首字符的情况，比如第二个字符，出现的频率都是近似相同的，这也说明了 ED25519 的公钥分布还是挺均匀的。\n\n也就是说，**地址前缀的碰撞难易程度只和首字符有关**——其实根本原因就是 32 字节能表达的数（$$2^{256}$$）和 44 位长度的 base58 编码能表达的数（$$58^{44}$$）不对等而已。如果这俩能表达的数正好相等的话，那么也不存在不同前缀的字符难易程度在 J 前后出现分水岭的情况了。\n\ncounter_ends 的结果我就不放出来了，大家可以自己测试一下看看，结果是和 counter_seconds 类似的，每个字符出现频率都是接近的。\n\n## 字符 1 不一样吗？\n\n你可能注意到了，首字符是 1 出现的次数其实远比 K - z 出现的次数要多，但是又远小于 2 - H。如果通过统计数据来计算频率的话 19541 / 5000000 = 0.0039082，正好是和 1 / 256 = 0.00391 的概率接近。\n\n这也是 base58 编码里的特殊情况，base58 编码就是把字节转化成字符，而一个字节对应的是 [0, 255] 一共 256 种情况，转化成字符之后只有 58 种情况了。所以对于单字节的 base58 编码结果的首字符来看，一定是有字符是会出现多次的。但是 1 不一样，1 只有当待编码的字节是 0 的时候，首字符才会是 1，这也是 1 的概率正好是 1 / 256 的原因。\n\n我们继续看首字符和第二个字符相等的情况：\n\n```python \n>>> print(counter_both)\nCounter({'BB': 5275, ..., '88': 4885, 'vv': 105, ..., '11': 65, 'ZZ': 65})\n```\n\n在首字符的统计数据里，1 是明显比 K - z 多的，但是前两位字符都是 1 的次数却突然变少了这么多。计算频率的话：65 / 5000000 = 0.000013，正好又是和 1 / (256 * 256) 接近。\n\n因此对于前缀是 1 的情况，确实与其他的字符不一样：前缀是 1，只能意味着待编码的字节前缀为 0，而如果相同字符的前缀长度大于 2 的话，那么它就是概率最小的情况。\n\n## 最终结论\n\n假设你想匹配的前缀或者后缀长度为 $$L$$。\n\n对于后缀匹配来说，不同字符理论上是均匀分配的，如果你只是想进行后缀匹配，那么整个后缀命中一次的概率是：$$(\\frac{1}{58}) ^ L$$。\n\n前缀匹配则更加复杂：\n\n| 区间  | 具体字符 | 区间总概率 | 区间内的单个字符的概率 $$p(C)$$ |\n| ----- | --- | ---------- | -------------------------- |\n| 1     | 只有 1 | 0.39%      | 0.39%                      |\n| 2 - H | 2…9 和 A…H 共 16 个 | 94.15%     | 5.88%                      |\n| J     | 只有 J | 1.45%      | 1.45%                      |\n| K - z | K…Z, a...z 共 40 个 | 4.0%       | 0.1%                       |\n\n整个前缀命中一次的概率需要分类讨论：\n\n1. 如果前缀全为字符 1，概率 $$P() =(\\frac{1}{256}) ^{L}  $$；\n2. 如果前缀首字符不为 1，概率 $$P() = p(C)\\frac{1} {58} ^{L - 1}$$；\n\n> **声明：**以上所有概率分析均建立在“ED25519 公钥对应的整数在 $$[0,2^{256}-1]$$ 上**均匀分布**”这一前提之上。此外，文中给出的数值均为**理论概率**，在实际运行中并不意味着只要尝试相应次数就一定能获得匹配结果。"},{"title":"升级，是与过去的自己重逢","subtitle":"记一次电脑配置升级","url":"/posts/upgrade-reunion-with-past-self/","date":"2025-05-06T04:48:18.000Z","updated":"2025-05-08T11:18:35.000Z","category":"实验室","tags":["硬件","主机","电脑","升级"],"content":"我的电脑主机是我 2019 年配的，那年我本科毕业，刚来武汉工作，记得刚上班的那段时间每天下班后最期待的就是下班，虽然下班时间很晚，但我也会抽出时间来研究电脑配置、装机教程等，当时的我花了很多时间最终敲定了[一套配置](/posts/7a2a84c6/#配置单)，算是我需求内最顶级的配置了，CPU 是 Intel 的 i7 9700KF，显卡是因为要装黑苹果所以选用的是 AMD 的 Vega 56。\n\n<!--more-->\n\n当时最期待的就是当时第一个月的工资到手的那天，那天我晚上下班后就把选定好的配件全都买了。我这个人虽然做事情比较爱折腾，但是折腾也是为了日后的使用能更加舒心，在配好电脑后的很长一段时间我用的都挺满意的，唯一的缺点就是，当时的我为了黑苹果、ARGB 灯光同步、ITX 机箱多花了不少的冤枉钱。\n\n不过也没什么办法，对于当时才工作配置第一台主机的我来说，macOS + Windows 双系统就是我的刚需，我需要用它来学习编程、写代码、看视频、玩游戏，以覆盖我对电脑的全方位需求；而对于装机新手来说，灯光同步就像是一个具有吸引力的魔咒一样，简直不知道怎么拒绝。\n\n不过现在的我，对于电脑主机的需求和之前有了明显的不同，因为我现在不仅有电脑主机，还有 macbook、NAS、云服务器等不同种类的设备来应对各方面的需求。\n\n从当时的武汉，到家乡的城市，再到深圳再到后来的广州，这台主机就相当于是我工作经历的见证者，是我成长过程中的伙伴，对我来说有特别意义。我在 23 年换了一块 2 T 的固态以及 24 年更换了一张 4070 Ti SUPER 显卡外，换下来的固态和显卡我也都保留着。只是最近我也在使用中愈发感觉到了这台主机的吃力，毕竟也是用了五年多了，于是我也想是时候再给它升级一下配置了。\n\n## 显示器升级\n\n这次显示器的选择我还挺纠结的：到底是新买一个 2K 240Hz 的显示器，还是 4K 160Hz 的显示器，我现在用的是 4K 60Hz 的 IPS 屏。平时在日常使用还能接受，但是玩一些竞技游戏这个刷新率就显然不太够了，毕竟现在很多手机和笔记本都上高刷屏幕了。网上有人说竞技游戏应该优先保帧率，越高越好，因此我一开始是比较偏向于 240Hz 的，但是随着进一步测试，我发现了和 CPU 有关的一个问题：**CPU 好像到瓶颈了**，平时还好，但是某些复杂场景时，甚至不能稳 240 帧，有时候还会掉到 160 帧左右——这些问题之前没有发现估计是因为我一直用的 60Hz 的显示器开着垂直同步，就算掉到一百多帧我也感觉不出来。\n\n我也尝试过降低分辨率，比如降低到 2K，但是帧数仍然没有什么变化，这也进一步佐证了我的推测—— CPU 确实到瓶颈了。加上 2K 显示器在日常使用肯定不如 4K 细腻，而我也已经习惯高分屏了，所以我最终还是选择了 4K 160Hz 的 Miniled 显示器。\n\n显示器到了之后接上电脑，第一感觉就是亮和通透，随后我就满心期待地打开了游戏——很可惜，仍然没有办法全程满足 160 帧，甚至最低帧会跌倒 130 左右。\n\n这就很尴尬了，对于 160Hz 刷新率的显示器来说，如果平时显卡输出的画面都是在 160 帧以上，但是突然帧数掉到 130 左右，这种卡顿是很难受的。于是我打开了任务管理器想看看具体的 CPU 占用情况，发现了帧数的下降往往都是伴随着 CPU 频率的下降。\n\n我开始觉得或许是 CPU 出了一些什么问题，导致不能按照较高的频率运行。\n\n## CPU 的降频？\n\nCPU 降频的问题定位起来还比较复杂，因为 CPU 是作为电脑主机的核心，有很多其他组件出现的问题最终都有可能会通过 CPU 的行为表现出来。因此我需要首先确认是什么配件出的问题，如果最终排查出真的是 CPU 坏了，我得考虑是否直接换平台，这样的话成本就比较大了，因为 CPU 的更新换代往往意味着主板以及内存全部需要更新换代。\n\n我拿 CPU-Z 跑 CPU 稳定性测试的时候，大概是十秒左右就会降频，我以为是频率不稳，所以去 BIOS 里面锁了 46 的倍频，没啥用，10s 之后还是缓慢降频；然后我又发现 CPU 的频率和电压是一起降低的，我又以为是电压不稳的问题，于是我又在 BIOS 里面把防掉压开到最高，仍然没啥用；最后用 AIDA 64 测了一下温度，总算是找到问题所在了。果然，根本原因和 CPU 没啥关系，也不是 BIOS 或者主板、电源供电的问题，是水冷散热器罢工了，导致 CPU 稍微工作一下就直逼 100 度撞了温度墙然后直接降频，摸了下冷排发现确实没有热风往外吹。\n\n## 向水冷告别\n\n简单排查了一下，首先冷排风扇是正常工作的，两条水管也是一冷一热，推测应该是水泵出了问题，水冷使用到现在也有快 6 年了，已经是远超水冷的平均寿命了，加上我之前带着电脑做过几次高铁，可能不小心磕碰到了。我就不纠结到底是什么原因了，反正一体式水冷也修不好，直接新买了一个。\n\n2019 年装这套水冷时，我并不期待它能陪我这么久，因为水冷算是当时随便买的，花的钱也是所有配件里最少的，但它确实又完美胜任了它的本职工作，虽然只有它在高铁的颠簸中出了问题。\n\n换上的新水冷我测试了一下温度甚至还没有之前的低，或许可能也和 CPU 内部电路老化有关吧。无论如何，我决定为它写一行「告别信」：\n\n> ID-COOLING CHROMAFLOW 240 一体式水冷，2019.09-2025.05，见证了数座城市与穿州过省的搬家。后继有人，一路走好 😇\n\n\n\n## 内存升级\n\n内存的升级也算刚需，我开着游戏 + 浏览网页的时候，任务管理器显示内存占用率已经达到了 94%，此时再点击浏览器页面就感觉响应速度非常慢。\n\n内存的问题其实好解决，无非就是换两根内存条而已，不过因为我使用的 Z390 ITX 的主板只有 2 个 DDR4 的内存插槽，所以只能把他们全部替换掉了。现在我舍弃掉了黑苹果以及光污染，所以也不用考虑软件兼容以及外观适配问题了。但是我纠结的点是把现在使用的 3000MHz 16g 内存条，升级成 32g，还是直接一步到位升级成 64g。\n\n我仔细思考了下平时的使用场景，以及现在我面临的问题，频率我倒没怎么在意，主要是容量，想了想，还是买了 3600 MHz C16 的 32g 套条。有几个考量，首先是单条 32g 的选择比较少，以及目前的 CPU 其实和显卡相比已经是到达瓶颈了，我估计最多再用个两三年，到时候平台一换，内存也不得不换成 DDR5 的，所以现在就过渡一下使用 32g 的内存了。\n\n> 避雷一下⚠️：我买的铭瑄 3600MHz C16 海力士颗粒的内存条，非常便宜，32g 套条才 300 块不到，和水冷一块安装上去开启 XMP 之后，烤机没问题，但是游戏一会就会出现频繁闪退。我排查了所有的方面：包括 CPU 超频、CPU 温度、杀毒软件、游戏完整性扫描修复、网络波动丢包等等，结果发现是这个鸡毛内存条的问题，把 XMP 关掉之后就没事了，直接退货了换成了其他品牌的 3600MHz C18 内存条，贵了几十块，但游戏没有闪退的问题了。\n\n2019 年的我把内存条的钱花在了 RGB 灯条上，如今我更关注于内存的具体性能表现。这是一种「想要」和「必要」的区分。阶段性的需求，只能阶段性地满足，留一些余地，好让下次换平台时，又能和未来的自己坐下来谈谈。\n\n## 结尾\n\n每次我升级这台主机时，看着换下来的配件，都会让我回想起来当时的我是什么样的，以及我在安装他们的瞬间，换下来的核心配件我会永远把他们保留下来，等到所有的配件都全部换完一次之后，我会把旧配件再次组装成最初的那台电脑，让它以最初的模样，陪在我身边长久守护那段时光。"},{"title":"读《拖延心理学》有感","subtitle":"我们应该如何应对拖延","url":"/posts/overcoming-procrastination-and-self-acceptance/","date":"2025-03-06T06:06:09.000Z","updated":"2025-03-06T06:06:09.000Z","category":"文字阁","tags":["拖延","笔记","感想","自省"],"content":"好久没在[文字阁](/category/文字阁/)分类里发文了~~这当然不是因为我好久没读书了~~。最近这段时间因为意识到了内心深处的冲突与迷茫，我开始不断看书，试图从书中寻找答案。倒不是说最近我的内心才有冲突与迷茫，而是我最近才从我的一些行为意识到原来这是我内心冲突与迷茫的外在表现。我在 [2024 年终总结](/posts/2024-year-end-reflection/#结尾)里写道：「今年我浪费了好多时间在刷 B 站、抖音上面，我觉得这样并不好，短视频刷多了会让我明显感觉到自己变得浮躁了起来」。其实我当时弄错了因果关系，并不是因为刷短视频让我变得浮躁了。而是因为我的内心本身就是浮躁的，所以才会去看刷很多视频。\n\n言归正传，我最近看的一些书的确能缓解一些我内心的冲突与迷茫。本文的标题提到的《拖延心理学》就是其中之一。\n\n## 拖延的心理问题\n\n曾几何时，我对于心理学相关的内容都不怎么感冒的，我还记得在上大学时看圆桌派，有一期心理学家武志红来当嘉宾，他说世界上只有两种人：一种人是承认自己心理有问题的，另一种是不承认自己心理有问题的。我当时对于这句话是嗤之以鼻的，想着这不过是他一个心理学家屁股决定脑袋才能说出来的话，我也不认为自己的心理会有什么问题。可几年来，我自己也在改变，我不得不承认：也许我真的有一些心理方面的问题。就比如，我目前能意识到的最明显的问题——拖延。\n\n我想很多人或多或少都经历过拖延：也许是在生活中早就给自己定下目标，却迟迟不愿开始；或者习惯在工作里卡着 deadline 前才匆忙交付。有一些意识到自己有一些拖延的人会采用时间管理等方法去制定工作和学习的计划来改变这种状况，可制定计划的时候总是理想化地把时间安排地满满当当，好像时间和精力都是无限的，可实际执行起来却发现困难重重。作者提到，从本质上讲，**拖延并不是一个时间管理方面的问题**，并不是说人们不知道什么时候该做什么事情，而是在用各种方法去逃避需要做这件事情，这是一个复杂的心理问题。\n\n## 逃避与内心冲突\n\n比如我，在从[上家公司离职](/posts/company-departure-after-3-years/)之后，有好几个月时间一直没有给自己缴纳社保和医保，当时家里人也一直在劝我说让我尽快去缴纳，不然退休的时候，拿不到钱。但是我当时就是心里有些抗拒，嫌麻烦，加上我觉得我自己还年轻，退休离我还远。\n\n这件事情上其实我就是在用自己还年轻，短期自己还用不上等理由去拖延，但其实它对我之后的未来是很重要的，对于当下的我来说，不那么重要，所以我下意识地忽略了这件事的重要性。这在书里被总结成「未来折扣」：我们对眼前没那么重要、但长期有价值的事情容易打折扣。作者提到，这是人类的天性。\n\n后面我好不容易下定决心打电话给政务服务中心咨询，但是他们告知现在必须要本人去线下办理就业创业证，然后才能用灵活就业方式缴纳；但我当时身在其他城市，不便线下，于是好不容易迈出的第一步就又收回了脚。于是这下我又有一个新理由来回应家人对我这件事情的催促了。\n\n这一拖又是好几个月，后面我实际跑了一趟线下的服务中心，给自己成功办理了就业创业证，然后也成功缴纳上了社保，其实这件事情本身并不麻烦，我只花了差不多一个小时就完成了。之所以拖这么久，是因为每次想到这件事都会让我感到焦虑——意识到自己正处于失业的状态，我也一直羞于对其他人提出这件事，因为这对当时的我来说可能并不是那么容易接受，导致我从心里对做这件事产生了反感，想要躲避。\n\n## 接受自己\n\n那么如何才能改善拖延的情况呢？作者提到，首要的就是我们要接受自己。接受自己真实的样子，而不是自己希望的样子。这意味着我们需要承认自己的在某些方面的不完美，在做某些事情时的失败，即使这些失败是有可能会让自己伤心和失望，但一件事情的成功或者失败并不能决定一个人本身的好坏，更不能因此来说你是一个成功者或者失败者。\n\n我们要以成长的心态去面对失败：能力是可以发展的，通过努力，我们可以随着时间推移而变得更聪明、更优秀。努力可以激发自己的能力并成就自己。这样我们在做一件事情的时候就不再盯着「我表现得好不好」，而是会思考「我学到了什么」「我提升了什么」。\n\n这就会让我们对一些内心感到恐惧的事情不那么恐惧了，因为就算失败了也没什么，我们从中汲取教训，然后在下一次继续努力去做就行了。更何况其实有些惧怕的事情并不意味着它在当下里是真实存在的，换句话说，恐惧可能只是存在自己的心里，可能是因为这件事情让你联想到了过去的一些类似的经历，这是潜意识在作祟。**我们所恐惧的事情是那些早已发生过的事情**。我们需要重新去审视一下自己的内心，思考一下究竟自己在惧怕什么，把原因写下来，仔细分析这个原因到底存不存在，这样我们会对真实的自己更加的了解，也更容易去接受真实的自己。\n\n## 拆解的有效策略\n\n当然，在我们下定决心克服了内心的恐惧真正开始做事情时。也还是要注意方法。不可否认，有些事情对我们来说确实是比较难的，如果找不对方法直接下手很容易造成挫败感。\n\n书里写到，我们可以为要做的事情（尤其是难事）竖立几个不同阶段的「可操作」目标。「可操作」的目标意味着：首先它是可以被明确感知到是否完成的，其次，它可以被分解成几个不同小的步骤独立完成，最后，第一个步骤只需要很短的时间比如 5 分钟或者 10 分钟就可以完成。这很重要，很容易就能完成的第一步可以让我们真实感受到我们的确是开始朝着完成这个事情的目标前进了。\n\n就还是拿我自己举例吧，我最近在看了《富爸爸穷爸爸》、《聪明的投资者》、《金钱心理学》等好几本金融相关的书，书里不约而同地都提到了同一个投资方法：美元成本平均法。思考了一段时间，我就决定也开立一个美股的账户进行定投标普 500 指数。不过，不管是从主观还是客观层面来说，投资美股对于大部分人来说就是一个很难的事情——之前支付宝部分美股的 ETF 基金是可以开放买入，现在不行了。\n\n> 这个事情本身其实可以展开说说，对于大部分人来说不碰自己不了解的投资领域是主观的想法，加上周围或多或少可能都有买 A 股被套然后割肉的朋友，所以不能说这个想法不对，因为人的想法都是通过对自己过去的成长环境、社会经历总结而形成的。但更好的想法应该是：我不了解投资，所以我需要去学习让我自己了解，这样或许我能减少风险，因此受益。\n>\n> 在客观现实来看，因为国家严格的外汇管控（限制资本外流，审查境外投资资质等），导致了境内投资者进行海外证券投资的难度增加。而境外的券商因为合规风险，主动提高对境内投资者的开户要求（存量资金证明，审查开户资质等）。于是部分的投资者就可能转向了一些其他的灰色渠道，导致了资本外流的风险增加。于是国家又会进一步收紧政策。政策制定者、境外券商和投资者的行为互相影响，形成反馈循环，加剧政策与市场之间的紧张关系。这其实就是索罗斯经常说的「反身性」。\n\n对于这件难事，我设置了 2 个可操作目标（这个目标只是我自己的划分，可能不适用于同情景下的其他人）：\n\n- 开立境外券商账户；\n- 以合法的方式汇出资金到券商户头；\n\n对于每一个可操作目标又可以进一步细化，比如：开立境外券商账户可以分成：\n\n1. 了解有哪些境外的券商；\n2. 大家都推荐用什么券商，为什么；\n3. 选定券商后，网上搜开户教程，看看自己是否满足开户条件；\n4. 对着教程逐步操作等等。\n\n汇出资金也是可以采用类似的方案，可以细化成：\n\n1. 了解看看有哪些境外的银行卡；\n2. 办理条件如何，是否可以直接线上办理；\n3. 如果还是觉得出境稳妥一些，那么就安排一下去香港旅游顺便开户。\n\n很重要的一点是，对于每一个目标的第一步我都设置的很简单，这意味着无论你处于什么状态，是否有时间完成剩下的步骤，都不影响你花在 5 分钟完成这第一步。不要小看我们迈出的第一步，拖延最最致命的危险就是完全地放弃。只要开始了，即使这一步很小，那也是朝着自己的目标前进。\n\n## 即时奖励\n\n另外，在朝着目标前进的路上，对自己即时的激励措施也是必要的。比如吃一顿大餐或者看部电影放松一下。注意，不要把顺序弄反了，奖赏应该是在预期的行为完成之后，而不是「我先去看部电影，然后再去做事」。即时的激励对我们做事情来说是一种正反馈，它会加大我们对类似行为重复的可能行。\n\n## 总结\n\n这本书的干货很多，但是读起来稍微有点枯燥，需要耐着点性子去读。对我来说，我觉得本书的作用还是挺大的。能够让我更加容易审视自己的内心，坦然接受自己的优点和缺点，与自己更好地相处。能够接受自己的不完美、分解目标、正面激励，才是与拖延和解的关键。\n\n当然，我也并没有因为一本书就彻底和拖延说再见，生活里总会有在想做事情的时候遇到的各种各样的突发状况，但我在心里已经能够坦然面对，人力有时尽，只要我在朝着目标的路上前进，偶尔停下脚步或者走一些岔路其实无关紧要，这种心态上的转变才是最宝贵的。"},{"title":"我是如何看待 DeepSeek R1 的","subtitle":"R1 的发布意味着什么","url":"/posts/china-ai-breakthrough-deepseek-r1-showdown/","date":"2025-02-01T13:28:33.000Z","updated":"2025-02-01T13:28:33.000Z","category":"分享境","tags":["OpenAI","DeepSeek","ChatGPT"],"content":"最近 DeepSeek 可谓是出尽了风头。从 1 月 20 日发布了 R1 开始，DeepSeek 这家公司就逐步迈上了舆论的「风口浪尖」，几天时间冲上 App Store 与 Play Store 多地区榜单第一，各大平台热搜也是不断。加上最近正好属于过年放假期间，大家都有时间去体验、探讨这样一款国产的 AI 大语言模型。\n\n<!--more-->\n\n## 我使用 AI 了多久\n\n\n自从 OpenAI 在 22 年底的时候发布了 ChatGPT 3.5 开始，我便一直在使用。后面出了 Plus 之后，我也一直在续费使用到现在。\n\n中间我也尝试过 Anthropic 出品的 Claude 以及 Google 出品的 Gemini，其中 Claude 在写代码层面应该是最好的，但是在产品等方面并不如 ChatGPT，因此我在好好体验了几个月的 Claude Pro 之后，还是放弃了续费 Claude。\n\n24 年 11 月，我也在本地跑过 qwen，phi，DeepSeek v2 等模型，因为电脑是笔记本加上我本来也只想用它来当个 LLM 翻译后端，所以参数选择的 7b 的也够用。整体测试来看，DeepSeek v2 算还不错的（V3，R1 那时候还没发布）。\n\n自 ChatGPT 3.5 → GPT 4（更智能） → GPT 4o（多模态） → ChatGPT o1（强化推理能力），每一个新版本的发布都意味着 ChatGPT 更加聪明、好用，但是在技术圈内造成的影响却一次比一次小。这很容易理解，毕竟什么事情都是从 0 到 1 是最难的。\n\n## R1 到底是什么水平？\n\n从本次 DeepSeek R1 官方 Readme 发布的 benchmark 可以看到，R1 严格上其实并不算一个划时代的产品，因为他的问答准确性与 o1 模型处于伯仲之间。不过需要说明的是，这个基准测试虽然涵盖了 AIME 2024, CODEFORCES, MATH 500, MMLU 等，但本质上其实测试的方面还是逻辑推理能力。这也是可以理解的，毕竟诸如表达与理解能力的评判实际上并不具有唯一标准。\n\n而表达与理解能力才是普通人感受最直接的方面。毕竟不是每个人都会整天问 DeepSeek 数学题或者写代码。\n\n我个人感觉体验来看，DeepSeek 在中文的表达与理解能力是要比 o1 强的。因为 DeepSeek 并未公开模型训练的具体细节，只能猜测是因为 R1 的训练语料里中文方面涵盖的更广，或者针对中文专门做了优化。\n\n## 为什么突然就火了\n\n\n不论是国内，国外，圈内，圈外，为什么 DeepSeek R1 全方位都火了起来呢？\n\n我仔细思考了一下，它火起来应该是有以下原因：\n\n\n1. DeepSeek 官方声称其训练成本很低，但是性能却是业界顶尖水平——让国外的很多花了几千万研发费用的公司感到恐慌；\n2. 它是开源的，用其蒸馏其他的小模型相比原模型极大提升了推理能力——推特上有不少人上传了在手机本地运行 DeepSeek R1 的视频；\n3. 它是中国的一家 23 年才成立的小公司开发的——以弱胜强，自古以来都是很有话题性，大家都爱看；\n4. 与 OpenAI o1 的对比：\n\t- 免费使用，而 OpenAI Plus 用户每周也仅可使用 50 次 o1 对话——非常大气；\n\t- 不需要科学上网——使用门槛比较低；\n\t- 中文方面的表达理解能力要更强——网上有许多DeepSeek R1 饱含人文关怀、富含情感以及生命力，当然也有富含攻击性的回答。\n\n前两点决定了它在技术圈的影响力。而后面几点导致在非技术圈也非常易于传播、使用，让每个使用过它的人都自觉成为了「水军」帮忙宣传。\n\n另外还有一些优点比如 API 收费相比 o1 价格只有几十分之一，R1 相比 o1 还具备网络搜索功能。不过这些我觉得只算是锦上添花而已。\n\n## 谁急了？\n\n\nAnthropic 的 CEO 在 1 月 29 日在[其博客上](https://darioamodei.com/on-deepseek-and-export-controls)提倡加强限制显卡出口禁令、以维护美国 AI 霸权地位。其文中对于 R1 的技术创新点一笔带过，反倒是花更多的笔墨来展示他的傲慢：声称 DeepSeek R1 的模型性能只是美国 AI 公司 7 - 10 个月前的水平。\n\n无独有偶，金融时报在 29 日发表的[一篇报道](https://www.ft.com/content/a0dfedd1-5255-4fa9-8ccc-1fe01de87ea6)：OpenAI 声称已经有证据证明 DeepSeek 使用了 OpenAI 的模型进行训练。有趣的是，Microsoft 拒绝对此事发表评论，并在当日迅速将 DeepSeek R1 上架 Azure 和 GitHub copilot。\n\n毕竟二者是商业公司，必要时候需要给投资人信心，我们观察商业公司的真实想法不能看他说了什么，而是要看他做了什么。25 日，AMD 在[社交平台宣布](https://x.com/AMD/status/1882851449991737473)整合 DeepSeek-V3 到旗下最新款 MI300X GPU；NVIDIA 也在 30 日[宣布 R1 可在 NVIDIA NIM 使用](https://blogs.nvidia.com/blog/deepseek-r1-nim-microservice/)。\n\n我们自然无从得知 Anthropic 和 OpenAI 的真实心理，但显然有人比他更坐不住：正如黑神话悟空发售时，steam 平台被僵尸网络进行 DDoS 攻击导致无法统计在线人数一样，DeepSeek 同样在最近被僵尸网络进行 DDoS 攻击：从一开始新用户注册报错，随后演变成了数次对话只有一次能成功，到 30 日的深度思考已经完全用不了。\n\n这一场由 DeepSeek 掀起的 AI 飓风，已经慢慢让美国的科技霸权裂开第一道缝隙——**他们越急，我们越该笑。**\n\n## 我的想法\n\n\n自从 20 年美国对华为芯片断供之后，中国许多科技产业就开始走上了国产化之路。我其实不太擅长站在国家或者民族这种大的层面去说一些话，尤其是我之前工作接触过一些所谓的国产化项目，其不过是一些领导要求的面子工程。加上这几年国产 CPU、显卡不断更新迭代，我其实没什么感觉——龙芯、摩尔线程毕竟性能相比旗舰产品差距太远，我们普通消费者并不会因为国产化标签就去买。\n\n当然，他们都需要时间，正因如此，DeepSeek 才显得与众不同。因为 R1 就是业界目前顶尖的 LLM 能达到的水准，其中文的表达、理解能力特别适合国内用户使用。作为一家成立不过一年半的公司，有这样的成熟度的产品，更是令人惊叹：它也意味着中国已经能自主完成科技创新，并走在世界的领先水平。\n\n我个人非常期待后续 DeepSeek 能加入图片识别、语音助手、代码实时预览等功能，让更多人感受到 AI 带来的价值。"},{"title":"2024 年终总结","subtitle":"正式成为一名自由 / 独立开发者","url":"/posts/2024-year-end-reflection/","date":"2025-01-01T03:29:15.000Z","updated":"2025-01-01T03:29:15.000Z","category":"碎碎念","tags":["年终总结","2024","感想"],"content":"说来也奇怪，本来年终的这段时间我没有很强烈想要写年终总结的想法，但就在 2024 年的最后一天吃完午饭，我走在路上，就只穿了一件薄外套，感受着穿过楼栋间隔的阳光撒在身上，今年广东的冬天好像尤其不冷。脑海思绪翻涌着，忽然一种想表达的欲望涌了上来，今年对我来说是有些不同，我也的确是应该要写一些什么东西来纪念一下。\n\n<!--more-->\n\n在路上的时候我还想着，好像已经好几年都没有写年终总结了，结果回到酒店打开博客一看发现也就是间隔了 2023 年的年终总结没写。人啊，在年纪大了之后似乎对于这种没啥记忆点的事物都比较容易忘记 :)\n\n## 职业转型\n\n之前提过，今年对我来说是有些不同，而这些不同也就是我写下这篇文章的驱动力所在。因此在最开始我想说一下最大的不同。\n\n今年是我完整地脱离传统工作岗位的一年，如果说去年的我因为刚离职，对职业这方面的话题会下意识地有些回避的话，今年的我已经可以坦率承认：我就是一名自由 / 独立开发者，我能够在脱离企业提供的工作岗位外，独立地创造价值，并做出一些人们需要的东西。\n\n今年六月份，我加入了一个小型的「创业」团队，我们一起做了一个项目，拿到了我们在区块链的第一笔空投，小赚了一笔。这一桶金，也成为了我之前那句话的底气。\n\n> 那段时间我学会了在质疑里自证，也学会了为自己的选择负责。\n\n## 技术\n\n今年在技术深度上的提升并不多，主要是脱离了传统的工作岗位后，写代码不再是我每天的主要工作了，深入研究代码原理的机会少了，反而是遇见了一些之前未接触过的新技术，还好，我本人没有对于技术的深度或广度有明显偏好，只是一如既往地对技术抱有热忱。\n\n值得说道的一点技术是我自学了 OpenCL，并且用它实现了一个[寻找 Solana 虚荣地址的工具](/posts/generating-solana-vanity-addresses-using-opencl/)，相比官方的 `solana-keygen grind` 在性能上有了几十倍的提升。这个工具我做完了之后就开源了，一开始也并没有想它会为我创造什么收益，没想到随着 star 的数量越来越多，两个有定制需求的用户也找上了我，这倒是我所没有想到的。\n\n另外就是我最喜欢的 SolidStart 框架终于发布了正式版，虽然相比我之前使用的版本引入了不少 breaking changes，最大的一点是底层的 web server 部分变成了由 vinxi 提供，包括处理部署和编译，但总体来说算是更好用了些。研究了一下他的文档，为博客的适配花了一些时间。我今年的几个前端项目都是用它来搭建的，不出意外后面很长一段时间 SolidStart 都会是我的首选前端框架。\n\n剩下的多是一些与 web3 相关的技术，没有多少深度，不值得拿出来单独说了。\n\n## 健身\n\n另外很大的一点不同就是我从六月份开始系统性的健身了。开始的过程并不顺利，我发现每次我的左足内踝下方跑步完之后就疼痛，右足就没问题，但是歇一两天不跑又不疼了。后面找了半天原因才发现其实因为我有轻微的足外翻情况，加上左脚力量弱一些，跑步时发力不均，导致了胫后肌功能出现了问题。后面买了支撑系的跑鞋，跑了一段时间后就没这个问题了。\n\n在开始的三个月里，我的训练方案还是减脂为主（当时肚子上的「游泳圈」还是比较大），大概是先力量训练 20 - 30 分钟，然后开始爬楼 50 分钟，最后再来 120 个卷腹收尾。三个月下来，效果非常不错，眼看着肚子上方的两块腹肌都隐约可见了，心里还是挺有成就感的。\n\n而从 11 月份开始，我的训练方案侧重点放在了增肌上。采用的是五分化训练：周一到周五分别训练背部、肩部、胸部、手臂还有腿部。然后会在肩部和手臂训练的两天加上腹肌训练。每天先跑步热身 8 分钟，然后活动拉伸 5 分钟，40 分钟的力量训练，最后再进行 20 分钟有氧。\n\n同时饮食方面采用 16 + 8，不特意忌口。不过最近两周发现体重没明显变化，我开始加餐了，晚餐后一小时再多吃小半碗燕麦片或者一根香蕉。\n\n## 生活\n\n今年一共在三个不同的地方居住过：青岛、西安、广州。\n\n从 23 年开始就在青岛呆着，所以在青岛呆的时间最久，也是目前呆过最舒服的北方城市（虽然好像我也没呆过几个北方的城市），有山又有海，冬天下雪可以堆雪人，而且因为是海滨城市，空气质量非常好。而且青岛吃的也真不错，虽然都说正宗的鲁菜在青岛吃不到，但有各种新鲜的海鲜呀，好吃的小店（面馆、炸鸡、寿司）也很多。\n\n在西安呆了 4 个多月，一去就明显感觉到空气质量的差距，而且刚到西安的时候正好是旅游旺季，各个旅游景点完全是扎堆的人，体验不是很好，至于吃的东西嘛，羊肉面、烤串店还不错，如果人少的话，我觉得可以一试。另外西安的一些古建筑倒是不少，但感觉只从「古都」这一点来说，游玩体验来说并不如京都，像是大雁塔或者不夜城周围总让我感觉有些过度开发了。\n\n十一的时候，全家一起去顺德玩了一趟，吃到了传说中的「鱼生」，用的是脆肉鲩，口感有些微韧劲、微微甜，不像三文鱼的绵密口感，不过没啥味道，得加调料拌着吃。\n\n从 11 月中旬开始在广州住着了，虽然居住在珠江边，但很可惜是周围并没有什么好逛的地方，周末的时候又因为要回家的缘故，也没有时间去到处逛逛。暂时写不出来多少感受。\n\n## 娱乐\n\n影视剧方面看得比较少，今年也就看了三十来部，我个人印象较深的有《因果报应》、《边水往事》，可惜边水往事 8 集后就走下坡路了，另外点名两部很垃圾的续集：《白夜破晓》、《庆余年 第二季》，正是因为很喜欢前作，所以看完才感觉像被喂💩一样难受。反之，《唐朝诡事录之西行》就是一部合格的续集，虽然我个人看来案子设计得不如第一季精致，但至少没有把观众当傻子糊弄。\n\n更多的时间我是花在了看网文上，今年看了 4 本网文：《神秘复苏》、《超级惊悚直播》、《一世之尊》、《十日终焉》，都还不错，硬要排名的话大概是 1 > 3 > 2 > 4。\n\n从《黑神话：悟空》发布之后，我用着 Vega 56 打通了第一轮回，卡得要死，于是我换了一张 4070 Ti SUPER 的显卡开始沉浸式体验风景。可惜我是人菜瘾大，总是卡关，所以花了很久时间才通关。在通关之后，我又玩类似的游戏：《战神：诸神黄昏》、《对马岛之魂》。对比来看，《黑神话：悟空》的战斗系统绝对是这三个里面最流畅的，对战视角锁定、跟随做的非常流畅，加上各种不同的套装搭配打法，很难相信游戏科学推出的第一款游戏就有这样的完成度。\n\n玩游戏给我带来的体验和书影音完全不同，书影音是一种客观的沉浸，后续情节发展不已个人的意志为转移，更像是一个旁观者；而游戏，则是一种主观的沉浸，你所做的各种操作都会有即时的反馈，更像是一场梦，沉浸感更强一些。\n\n## 结尾\n\n今年我浪费了好多时间在刷 B 站、抖音上面，我觉得这样并不好，短视频刷多了会让我明显感觉到自己变得浮躁了起来，很多需要静下心去看的书以及影视剧看不下去了，甚至长一点的视频也看不进去，这也是我今年影视剧只看了三十多部的原因，我觉得我需要控制一下了。\n\n短视频可以作为调味剂，但不应该是主菜。\n\n---\n\n2025，一愿家人朋友平安幸福，二愿健身卓有成效，三愿多多赚钱。"},{"title":"个人网络相册搭建方案","subtitle":"终究还是走上了自建的路","url":"/posts/building-my-moments/","date":"2024-11-10T07:53:00.000Z","updated":"2024-11-10T14:39:00.000Z","category":"分享境","tags":["自建服务","网络相册","R2"],"content":"早有搭建一个自己的网络相册的想法，只是之前我一直没有找到合适的方案。最先开始想的是一些正经的方案：比如用公共的图床，但是国内公共的图床其实 90% 都不稳定，号称永久免费没多久就倒闭了，而且管理起来也不是很方便；再比如对象存储吧，各种乱七八糟的计费规则：存储空间要收费、读取写入操作要收费、请求也要收费，于是还是放弃了。\n\n<!--more-->\n\n正经的路不通，我也考虑过一些邪路：最开始是想用国内大厂泄漏的 API 当图床用，这也是我博客的封面图一直使用的方案，虽然速度挺快，不过这玩意实在有些不稳定，但是万一被人家发现了轻则修复漏洞，重则之前存的图片都会被删掉；还有就是最近发现的用 Webdav 协议把阿里云盘挂载当图床，不稳定的同时，用国外的 VPS 访问速度更慢，还有被阿里封号的风险……\n\n于是这个想法就一直搁置了，就在我以为这个想法就要「胎死腹中」的时候，偶然登录 Cloudflare 发现左侧菜单多了好多新功能（Images，Stream，R2），点进这些新功能看了一下就让我发现了一个可行的方案——R2 对象存储。R2 相比于友商的对象存储定价是真的良心：存储空间每月免费 **10GB**，此外的每 GB 需要 **0.015** 美元，改变状态（新增、修改、删除）有 **100 万**次额度，读取现有状态有 **1000 万**次额度——最重要的是，它是 0 带宽费的。而通过配置 Cloudflare 的缓存策略，能直接把上一次访问的对象缓存下来，后续直接从边缘节点响应，而不是每次需要都从 R2 读取状态！这样访问操作基本可以算是无限次额度的（白嫖使我快乐。\n\n> 需要指出的是，Images 本身的功能（自由裁切、调整大小等）其实更适合当图床，但是 Images 的价格会更高一些：读取现有图片是要收费的，而且它的转化功能针对 AVIF 格式的图像[限制非常大](https://developers.cloudflare.com/images/transform-images/#limits-per-format)。因此我还是使用了 R2，无非就是我自己来处理一下格式转换以及裁切的工作。\n\n## 功能设想\n\n我把网络相册分成了两个较为独立的模块：\n\n1. 网络浏览：此模块直接在互联网上供用户访问，有浏览图片详情、以及按相册过滤的功能；\n2. 后台管理：此模块包含的功能较为复杂，需密码认证用户方可访问：\n   - 处理图片：在浏览器端裁切原图，并添加水印后转换成 AVIF 格式和缩略图（纯浏览端完成\n   - 上传图片：处理后的图片上传到 R2、图片包含的 EXIF 信息保存在数据库里\n   - 查看图片：能查看历史上传的所有图片\n   - 编辑图片：对图片的信息进行更新：给图片添加拍摄地、归类到指定相册等\n   - 删除图片\n\n## 技术选型\n\n自从一年多前我在博客的项目中使用 SolidStart 之后，后续我的前端项目就都是用 SolidStart 框架了：Solidjs 函数式的写法和 react 很接近，性能又仅比纯 JavaScript 慢一些而已。\n\n此外，因为 Solidstart 是一个全栈框架，在这次项目中，我也破天荒的没有使用 REST API 来交互数据，而是使用了 [Server Functions](https://docs.solidjs.com/solid-router/concepts/actions)。简单来说，就是当浏览器端需要展示数据时，直接向服务端发送一个 RPC 调用，包含了调用函数的名称以及参数——当然，是以 HTTP 请求的形式。这么做的好处是不再需要去专门定义 REST API 路由了，极大简化了交互的流程，坏处就是和服务器端本身绑定地太死，跨平台是个问题，但是好在我的网络相册并不用考虑其他的平台。\n\n## 处理图片\n\n因为想着能尽可能存储多的照片在 R2 上，我决定所有的照片都选用 AVIF 格式存储，同时处理图片的操作也需在浏览器端完成（和 [Squoosh](https://squoosh.app/) 类似）。本想直接用 libSquoosh，不过这个库已经被废弃了，于是我只好选择了 [jSquash](https://github.com/jamsinclair/jSquash)。\n\n好在使用起来并不复杂，唯二需要注意的就是在 Vite 的 optimizeDeps.exclude 里把它加上；再就是启用多线程时处理时，需要[设置指定的 HTTP Headers](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/SharedArrayBuffer)。\n\n我把处理图片的逻辑放在了 Web Worker 里，然后由 Worker 再去创建多线程处理。以免阻塞主线程的运作造成浏览器标签页崩溃的现象。\n\n## 状态管理\n\n我实在没想到，状态管理会让我花费超过两天的时间。主要耗费了太多时间在「我以为」的问题上了。\n\n```jsx\nconst limit = 12;\nlet firstLoad = true;\nconst album = createMemo(() =>\n    new URLSearchParams(location.search).get(\"album\"),\n);  \nconst [offset, setOffset] = createSignal(0);\nconst [allImages, setAllImages] = createSignal([]);\nconst [currentImages] = createResource(\n  () => ({ album: album(), offset: offset() }),\n  async ({ album, offset }) => {\n    firstLoad = false\n    setState(\"first\", false);\n    const newImages = await getImages(album, offset);\n\n    setAllImages((allImages) => [...allImages, ...newImages]);\n    if (newImages.length < limit) {\n      setHasMore(false);\n    }\n\n    return newImages;\n  },\n);\n```\n\n我以为是 offset 和 album 状态更新的顺序不一致导致的 createResource 重复请求进而导致页面渲染出现了混乱，但是实际上并不是，只是单纯因为 offset 在短时间更新两次造成的问题。因为在切换 album 并加载请求的时候，控制瀑布流加载的元素又一次在视窗内部被观测到了，所以再次改变了 offset 的状态又触发了 createResource 的请求。后面在控制瀑布流加载的 Intersection Observer API 内部加一个判断 loading 的状态就行了。\n\n另外，因为 SSR 的原因，页面首次进入的 createResource 是在服务器端请求并渲染的，所以需要额外创建一个函数来确保服务端和浏览器端的 allImages 状态的一致性：\n\n```jsx\ncreateEffect(() => {\n  const images = currentImages();\n  if (!images) return;\n\n  // 只在页面首次渲染时更新 allImages，避免 SSR 渲染不一致\n  if (firstLoad) {\n    setallImages(images);\n    if (images.length < limit) {\n      setHasMore(false);\n    }\n  }\n})\n```\n\n## 浏览页面的优化\n\n针对浏览页面做了一些优化以提升用户体验：\n\n### 缩略图\n\n在电脑端的左侧区域展示的是图片的缩略图，由服务器端直接通过 Server Functions 直接返回 BASE64 格式的结果，点击缩略图后，右侧首先会展示缩略图以及加载的图标，同时会用 createResource 对大图发起请求，请求完成后，缩略图会被直接替换成大图：\n\n```jsx\n  <Suspense>\n    <div class=\"relative h-full\">\n      <div\n        class=\"absolute inset-0 bg-contain bg-center bg-no-repeat h-full w-full transition-opacity duration-200\"\n        style={{\n          \"background-image\": \"url(thumbnail_url)\"\"\n        }}\n      />\n\n      <Show when={data.loading}>\n        <i class=\"w-8 h-8 text-[#F5F3F2] i-svg-spinners-90-ring absolute left-1/2 top-1/2 -translate-x-1/2 -translate-y-1/2 z-20\" />\n      </Show>\n      <Show when={!data.loading}>\n        <img\n          src={imgURI}\n          class=\"absolute inset-0 h-full w-full object-contain transition-opacity duration-300\"\n          style={{\n            opacity: 1,\n          }}\n        />\n      </Show>\n\n    </div>\n  </Suspense>\n\n```\n\n### 控制图片切换\n\n目前手机端和电脑端各有 3 种方式来切换图片：\n\n1. 直接点击缩略图；\n2. 电脑端的键盘左右键以及手机端的左滑右滑；\n3. 在大图的边缘位置点击下一张或者上一张。\n\n---\n\n## 一点想法\n\n我没有把我的网络相册做成博客的一个子页面，除了我想保持博客内容的纯粹外，我也希望它能成为我的另一个具有我个人风格的作品集。\n\n所以，我将网络相册挂在了 [moments 子域](https://moments.itswincer.com/)下，之所以选择的是 moments 这个单词而不是 photos 或者 gallery，也是想传达我对于摄影的看法，正如我在网站的描述写下的「Some moments to remember」，我觉得摄影就是为了留着值得铭记的瞬间，让这些瞬间不会随着记忆而褪色。\n\n网络相册里的照片均为本人拍摄。\n\n## 结语\n\n有段时间没写代码了，看了看 Wakatime 发送的提醒邮件，有差不多有接近 2 个月了。之前在写日本游记的时候都有些感觉思维没有之前那么敏捷了，有一种像放了很久的毛笔想在纸上书写却只能留下四处飞散的墨屑的感觉，因此上一篇日本游记我写的并不满意。这种感觉并不好，连带着让我觉得[修个 bug](#状态管理) 都有点费劲了。\n\n好在本文写的还算流畅。"},{"title":"关西见闻","subtitle":"日本关西 6 晚游记录","url":"/posts/kansai-insights/","date":"2024-10-18T08:15:00.000Z","updated":"2024-10-18T08:15:00.000Z","category":"行走记","tags":["旅行","日本","出国"],"content":"坦白说，之前在韩国的游玩体验并不是很好，其中固然有首次出国经验不足的原因，但我感觉首尔这个城市本身也占据了很大的因素，它并不是一个适合「游玩」的城市，所幸我们在韩国不止玩了一个地方——后面到济州岛之后的游玩体验就直线上升了。也是在韩国旅行结束后，让我认定了旅行最重要的是让身心得到充分地舒缓，以最真实的自己去体验一种不同的生活方式。有了上次旅行的经验，本次的目的地我们选择的是以传统、历史以及风景闻名的日本关西地区。\n\n<!--more-->\n\n原定在国庆前一周的出游，因为女朋友工作的原因改成了国庆假期的末尾，本来还沾沾自喜以为这样应该能更大程度避开人流一些。不过一到日本的景点才知道还是我们有些乐观了……\n\n## 准备\n\n本次旅行没有做比较详细的旅行规划，只是定了几个宽泛一点的目标：去京都看古建筑、去大阪环球影城玩、去奈良喂鹿。\n\n因为时间安排的问题，我们本次出行稍显匆忙——签证是出发前三周才下发，机票和酒店是出发前两周才订下，这也导致了一部分额外的支出。\n\n### 签证\n\n我选择的是单次电子签，花费 200，资料纯电子版提供即可。不过因为我目前没有正式工作，所以商家要求额外手写一份资金来源证明，以及一份资金存款证明。七个工作日出签，还挺顺利。\n\n### 支付方式\n\n因为之前听说过日本有不少店铺只支持现金支付，考虑到我们两人呆 6 晚，于是一共去银行取了 12 万的日元现金。去了之后才发现其实带多了……我们一共只花费了 2 万日元，其实大部分的店都是支持支付宝以及微信的，而且支付宝和微信的汇率远比刷信用卡以及现金划算，我们是优先使用微信、支付宝，不支持的话就使用现金，虽然带了信用卡，但没有使用的机会。\n\n根据我们在关西去的这些店铺总结，电子支付方式里，信用卡的覆盖范围是最广的；支付宝因为和 PayPay 有合作，所以支持的店铺比微信更多；现金基本上就是在一些很小的饭馆使用，一般只接受现金的店铺大概率也不用收税。\n\n### 注意事项\n\n有些东西出发前需要备好：\n\n- 日元现金\n- 购买 Softbank 流量卡\n\n- Visit Japan Web 提前填好，保存二维码\n- 手机添加 Suica 交通卡\n\n> 注意：转化插头可以不用带，因为日本的 **2 孔插座**和国内是通用的，只是电压不同，对于普通的电子设备充电没影响，但是电吹风之类的家用电器因为电压原因（不兼容 110V），是没办法使用的。\n\n## 落地\n\n飞机在起飞前因为有几个乘客跑错登机口了，没上飞机，把他们的行李搬下去才重新排队起飞，耽误了半小时，所幸落地还是挺顺利的。我们在大阪关西机场入境，可能因为是国庆假期快结束了，入境的人也不多，下飞机后半个小时就出关了。\n\n出关之后在机场取 Haruka 车票（提前在 Klook 购买），80 分钟就从机场到京都站了，转了地铁就到京都的酒店了。\n\n## 京都\n\n我们在京都一共住了 2 晚，体验感是拉满的。很大一部分原因是京都下榻的酒店非常不错，在宝池附近，因为女朋友是万豪白金卡，我们订的基础房型也直接给我们升级了套房。不过可惜早餐没有专门的餐厅，而是在 Club Lounge 里，种类也比较少，不过后面换到大阪的酒店之后发现也一样，或许是日本早餐品类本身就比较少。\n\n### City Walk\n\n我们在抵达京都的第二天去了五重塔附近溜达，游客是真的多：中国人、外国人还有日本人都有，午餐也是在二年坂附近找了个店铺解决的。店铺很小，是个夫妻店，只接受现金支付，店里很干净但很小，点了两份金枪鱼的饭，味道一般（吃不太惯。\n\n![雨中的清水寺](https://img10.360buyimg.com/ddimg/jfs/t1/221309/7/45631/131492/6712172cFb6adc323/95e54f4c2e743d18.jpg)\n\n吃饭的时候正巧下雨了，我们就在店铺里等雨停，然后溜达到了清水寺的时候又下雨了，在清水寺屋檐下等了二十多分钟，雨停了又继续往清水寺里面逛了一会，阳光突破雨后云层的「丁达尔效应」非常漂亮；然后沿着八坂神社、花见小路、鸭川继续逛。\n\n![雨后的阳光](https://img13.360buyimg.com/ddimg/jfs/t1/106644/39/53340/67138/67121759Fbb1329dd/9437b04bab1bb651.jpg)\n\n京都市中心的好多店铺在晚餐时段是要预约的，对于游客来说，预约未免太过费事，逛到哪里的景点尚且还不一定，吃饭就更不确定了。所以可以赶在店铺晚上刚开始营业的时候碰运气，遇到预约没有满的店铺就可以用餐了，我们在京都找的第一家店已经预约满了，随即在谷歌地图又找了一家就可以了，在我们用餐的时候，又陆续有两对游客来用餐，店家就告知已经没有位置了。\n\n### 宝池公园\n\n在京都的第三天时间比较割裂：因为晚上我们就要出发去大阪，而且酒店要求 13:00 退房（话说日本的酒店退房真的好早，如果不是白金卡的话，酒店要求上午 11:00 就要退房），导致我们白天也无法去稍远一点的地方，于是我们早上就在酒店的茶室逛了逛。收拾行李的时候在地图上看到酒店附近有一个很大的公园——宝池公园，于是打算待会退房后就在公园里走走。却没想到这个临时起意的决定给了我们不小的惊喜。\n\n这个公园占地面积很大，人却很少，我们沿着中间的湖边走，湖里有很多鸭子。走了半小时，在路过一个小亭子时，发现有一只鸽子停在亭子的围栏上。我们就打算在亭子里歇息一会。\n\n> 我在京都遇到的动物好像都不是很怕人，经常会在路边看到鸟类，走得很近他们也不会飞走\n\n这时女朋友突发奇想，从包里拿出一袋饼干打算去喂一下鸽子。一开始就一个鸽子，结果没喂几口，就不断有鸽子飞来，最后七八只鸽子都开始抢吃饼干了，实在太欢乐了。有几只大胆一点的鸽子还飞到我们的手里吃饼干，我们就一直很快乐地喂了半个多小时，才恋恋不舍地离开了亭子继续往公园深处走。\n\n![喂鸽子](https://img10.360buyimg.com/ddimg/jfs/t1/109861/29/49819/171141/6712178aFe4d87439/3cace6e9a3ec9056.jpg)\n\n随后我们走到了野鸟之森，这里的岸边有一块向湖中心延伸出来的土地，已经有一个身穿黑衣头戴黑帽的小哥在岸边的石凳上，他的黑色的包也在石桌上放着。这里的岸边有很多鸭子在岸边戏水，于是我们停了下来，准备也在这喂一下鸭子，正当我们准备喂的时候，这个身穿黑色衣服的小哥突然起身了，随后往空中撒了一把碎面包，众多鸭子、鲤鱼还有乌龟就开始疯狂抢食。我们才发现原来他一直在喂这些鸭子，我们也掏出了一袋饼干准备像刚刚喂鸽子一样来喂鸭子和鱼，却发现压根无法吸引鸭子前来——饼干碎太小了，撒在水里鸭子和鱼根本注意不到，于是我们只能站在一旁摄影了。\n\n这小哥应当是个做事很仔细的人，切面包很慢，十分钟才切好一次面包。在切面包的期间，鸭子倒也不走，就在岸边晃荡。这小哥或许是看到我们在岸边拍照，于是他突然走到我们的后面，然后把随面包撒在我们附近的水里，我们向他投以感谢的微笑，他已经回头走到石凳旁准备继续切面包了。\n\n![P1011617](https://img11.360buyimg.com/ddimg/jfs/t1/5827/28/26595/205733/671217acF32b09b7d/99e2ffb4a8241570.jpg)\n\n我们也在这里也耗费了半个多小时，走的时候和小哥打了声招呼，道了一声谢，他也没有说话，就点了两下头，感觉也是个很腼腆的人。\n\n我们又继续沿着湖边走到了出口，找了附近的一家中餐用过了午饭，此时已经三点半了。回到酒店后，我们就准备出发去大阪了。\n\n## 大阪\n\n坐了一个半小时的地铁，我们抵达了大阪。大阪的酒店相比京都的就差了不少，而且并没有给我们升级到套房，不过地理位置不错，是个比较繁华的地段，附近有很多吃饭的地方。\n\n但我们似乎是下午在湖边吹了冷风，有点感冒，于是到了酒店就直接点了客房送餐，吃完洗漱了一下就睡觉了。毕竟第二天还要去大阪环球影城。我们购买的门票是 1.5 日的，而且专门选择的是 B 等级，想借此来避开人流。\n\n第二天早上我们就先去心斋桥打卡了一下道顿堀格力高广告牌，并在这里购买了一些送给弟弟妹妹们的纪念品——话说小八的玩偶是真的贵啊。\n\n### 大阪环球影城\n\n一开始我们其实是对这个影城抱有很大的期待的，结果由于人流量实在太多太多了，让我们的游玩体验直线下降。\n\n我们买票的时间已经比较晚，当日的速通票已经卖完了。于是只能硬着头皮排队了，好在我们是 1.5 日的票，时间比较充裕，很难想象，有好几个热门的项目我们排队都花了 2 - 3 小时。\n\n我们共计游玩了比较知名的项目如下：\n\n1. 鬼灭之刃 XR 乘车游（4.5🌟）：会给你佩戴 VR 头盔，然后坐在过山车上，跟随着剧情体验主角在车头砍杀怪物，为我们保驾护航的感觉；\n2. 哈利波特禁忌之旅（4.5🌟）：和鬼灭之刃类似，不过提供沉浸式体验的不是 VR 头盔，而是使用一块很大的曲面屏幕以及过山车来营造裸眼 4D 的效果，有比较吓人的实景怪物出现；\n3. 好莱坞美梦乘车游（4🌟）：相当于在椅子上可以选择游玩时 BGM 的过山车，真的超级刺激，一趟下来都给我喊缺氧了，脑子嗡嗡的；\n4. 小黄人调皮闹剧乘车游（4🌟）：和哈利波特类似，在小黄人的世界里弹来弹去，不过刺激程度稍逊一筹。\n5. 名侦探柯南 4-D 现场表演秀（3.5🌟）：小兰和园子是全程真人来扮演的，基德也会在剧场中出现，不过只是坐着不动看，沉浸感不如乘车游。而且全是日文，没有字幕，完全听不懂。\n\n还看了两场 4D 的表演秀，就不怎么推荐了——都是日文，没有字幕，完全听不懂。可能是入场晚了，马里奥园区我们也没有抽到入场券～\n\n万圣节期间，晚上会有各种 COS 队伍在路上游走，不过游客太多了，没啥恐怖感。\n\n总结一下，如果是对日本的 IP 比如（鬼灭之刃、马里奥、柯南）特别感兴趣，想来体验一下，还是提前买速通票，虽然速通在一些特别热门的项目也会排队，但是体验会好不少。如果不是以上情况，感觉没必要来了，人太多了，游玩时获得的满足感相比排队时耗费的时间感觉不值一提。\n\n> 后面几天回国后还在小红书刷到大阪环球影城门票售罄的情况，真的是有点夸张。\n\n### 轨道交通\n\n日本的轨道交通真的是值得单独拿出来说说，我们使用的 Suica 交通卡覆盖面很广，包括铁路也是可以刷卡进站的，不过一些「特急」的列车需要单独买座位票。\n\n或许是在国内坐地铁久了，来到大阪的地铁站非常不适应，因为有些站是同时具备铁路站和地铁的站，比如难波站和大阪站。而且有些换乘车辆的标志并不会在闸机出口处显示，比如我们要在西梅田换乘大阪站的大阪环状线，在西梅田出口是没有大阪环状线的标识的，只有 JR 线路的标识，就很迷惑。\n\n> 后来才知道，大阪环状线就是 JR 线路的其中一条。\n\n不过也有解决办法，遇到不知道怎么走的，拿着手机问一下工作人员就行，他们会指路的。\n\n### 居酒屋\n\n我们在大阪一共去了两个不同的居酒屋。\n\n第一个是第一天从大阪环球影城回来，当时已经九点多了，就随便找了一家酒店附近的居酒屋，这家居酒屋很小，只有不到 10 个座位，我们一进去坐下就刚好满座。这家居酒屋的老板看起来有点像巴西人，提供英文菜单。\n\n坐在我们右手边的是一位四十岁左右的日本女士，很热情，还帮助我们和老板交流。交谈之中聊到她和老板是多年的朋友，经常来这家居酒屋，还热情地分享她点的菜品给我们吃；相谈甚欢，最后我们合影并且相互留了联系方式。\n\n第二个居酒屋是第二天从大阪环球影城回来，也是九点多，我们同样找了一家附近的居酒屋，这家居酒屋稍微大一点，不过不提供英文菜单，而且服务员不懂英文，所以点单稍微花了点时间。\n\n我们点了 14 串烧鸟、一份鸡汤泡饭、两杯酒，味道那是相当不错～相当于广深这边人均 400+ 的水平了。而我们才花了 4800 日元，折合人民币才 230 元。\n\n## 奈良\n\n在刚落地关西机场的时候，走出飞机时，有两名机组成员就在讨论，说前两天天气不错，好多朋友都跑去奈良喂鹿了。于是呀，这几天就不断在心里累积对奈良之行的期待。\n\n出了近铁奈良站后走几分钟就到了奈良公园，不过这并不是我们此行的目的地，我们打算直接略过奈良公园，逛逛春日大社然后去若草山喂鹿。\n\n### 春日社\n\n沿着马路边走都能看到沿途的鹿，有的坐在花坛里，有的就直接站在人行道上等待人投喂。\n\n从路边向春日大社的路口拐进去，走进森林，不过可惜这里的树叶暂时还是绿色， 还没有变成红色。沿着小路走，拐过一个弯，看到了春日大社标志——一座鲜红的鸟居，与森林背景的绿色产生强烈的反差却显得相得益彰。\n\n![P1011690](https://img10.360buyimg.com/ddimg/jfs/t1/161031/11/49979/285493/671217daF79a3cca9/855d81150f5f54be.jpg)\n\n\n\n### 呦呦鹿鸣\n\n继续穿过春日大社，向着若草山的方向走，是一条石子小路，路上走着能听到鹿的叫声，一开始还没意识到是鹿鸣，因为这叫声和诗经里写的「呦呦」相去甚远，有点嘶哑、短促，并不是想象中的柔和，有点像老式的木门开门发出的声音。\n\n![P1011735](https://img13.360buyimg.com/ddimg/jfs/t1/178645/16/47462/337208/67121800Ffdf89897/64c8a57da9b5c9e0.jpg)\n\n### 若草山\n\n若草山是收门票的，150 日元一个人，但是因为是在山上，相比奈良公园的平地视野会好不少。\n\n![P1011802](https://img12.360buyimg.com/ddimg/jfs/t1/198752/34/47046/230884/67121828Fd1607a6e/92946e75fd453e0e.jpg)\n\n我们刚到若草山的时候顶着太阳还有点晒，喂了半盒鹿饼找个地方坐着太阳就已经快落山了，阳光的照射下，绿色的草地也开始变得有些泛黄。\n\n若草山的鹿很「外向」，喂了一块饼干还会继续跟着你索要饼干（感觉是饼干太香了），有时候还会拿头顶你或者咬你的衣服。在拍照喂鹿的时候，一个没注意，我放在一旁装鹿饼的包因为沾了一些鹿饼的碎屑，被一只鹿舔了又舔。\n\n今天夕阳很美，不过很可惜的是，没有看到晚霞。\n\n## 花费\n\n其实花费的比想象中要少：\n\n|         分类          |   金额    |\n| :-------------------: | :-------: |\n|         住宿          | ¥ 6030.70 |\n|         门票          | ¥ 1383.71 |\n|         吃饭          | ¥ 1606.24 |\n|         出行          | ¥ 8961.01 |\n| 购物（零食 + 纪念品） | ¥ 1619.30 |\n| 杂项（签证 + 流量卡） | ¥ 997.92  |\n\n二人共计花费：20598.88。\n\n主要花费在出行 + 住宿，这也没办法，广州飞关西的航班每天就一班，死贵死贵的。\n\n## 总结\n\n之前脑海中的日本形象都来自于网友的只言片语（其中负面的言语居多），实在有些片面，与之相比，亲身来日本旅游的体验显得更加生动，极大丰富了脑海中的日本形象，也为日本加分不少。\n\n**旅行的意义，或许就在打破固有印象，去发现一个更真实的自己与世界。**\n\n这或许是本次旅行带给我最大的收获。"},{"title":"又一次博客优化记录","subtitle":"不知道干什么我就折腾博客","url":"/posts/blog-optimization-again/","date":"2024-07-22T11:46:00.000Z","updated":"2024-08-01T06:58:00.000Z","category":"博客栈","tags":["SolidJS","博客","优化"],"content":"好久没写博客了，每当我有些想写代码的情绪无处发泄的时候，我就会开始折腾之前写的老项目，而我的博客又是一个稍微有一点复杂的项目（Hugo + SolidStart），项目的复杂度一旦升高，难免会在不同需求之间做权衡，难以做到尽善尽美，所以博客一般是我折腾次数最多的。这次折腾的起因是我发现 SolidStart 在前段时间发布了 1.0 版本，相比之前的 beta 版本有不少改动，借着更新博客的机会，正好水一篇文章:)\n\n<!--more-->\n\n## SolidStart 的升级\n\n除开 URL 路径终于支持 UTF-8 字符外，本次服务端渲染方式相比之前变化是最大的，花了点时间做了相关的适配。\n\n目前博客改成了使用 Hugo 输出 JSX 格式的内容文件，本质上还是 JS 的 Object，只是在内容开头加上了 `export default` ，这样 SolidStart 就会根据文件的 [.jsx] 后缀把它当成页面去渲染，而不需要我再指定文件后缀去渲染页面；然后我再通过自定义的 Vite 插件把 JSON 内容都渲染成 JSX 内容。这样的构建流程会相比之前的更直观一点，也方便排查问题。\n\nSolidStart 1.0 版本页面的加载顺序变成和 RemixJS、NextJS 一样了，即页面所有的 JS 文件，无论是动态导入还是静态导入都会同时加载。在之前的版本，有一些动态导入的文件，要等它的依赖项（比如 entry-client.js）全部加载完成之后才会发出请求。\n\n但是现在版本打包的静态资源大小会相比之前更大一些，主要是包含了完整的 vite manifest（这一点我不太喜欢，因为我阅读源码之后发现是可以避免的），而且这个 manifest 映射是直接插入在 HTML 文件的 script 标签里的！虽说 gzip 后也就几 KB 的差距，但是会让 DOMContentLoaded 的耗时加长，等看后续 SolidStart 版本更新看看是否会有改进。\n\n不过我手动测试了好几次 DOMContentLoaded 和 Load 的耗时，测试结果上来看和之前倒没啥差别，终究还是我有点强迫症了……\n\n## i18n 的逻辑调整\n\n我博客目前的英文文章是通过 URL 来区分的，而 SolidStart 现在只有在 `Route` 内部才能使用 `useLocation` 判断当前渲染的页面是什么，这让我有点犯难：\n\n1. 我的博客页面的 Header 部分和 Footer 部分也是需要参与页面的中英文切换，而它们在所有页面都是不变的，因此它们不应该放在 `Route` 内部，而应该和作为 `Route` 同级的元素；\n2. 我使用的 typesafe-i18n 如果在 `Route` 内部使用在服务端渲染的时候会报错；\n\n所以我不得不使用了一个有点别扭的办法：通过渲染页面的数量来判断当前的页面是否是英文页面。但是这也有一个前提，就是需要确保所有英文页面是先被渲染的。好在 SolidStart 的页面预渲染顺序可以通过 `prerender.routes` 来指定，所以我目前是把英文的页面以及自定义 404 的页面在该参数里指定，然后剩余的页面让程序构建时自动爬取即可。\n\n## 去掉标签详情页面\n\n在上次更新博客时，我就去掉了标签云页面改成了在页面底部随机展示其中一部分标签。而我最近在查看博客统计时，发现标签详情页面的访问数还是少得可怜——近半年来，超过 10 次访问的标签页面都寥寥无几。\n\n因此这次更新我就直接把标签详情页面去掉了，底部的随机标签展示部分也去掉了，文章详情页的标签倒是还留着，不过点进去已经不是标签详情页面了，而是[搜索页面](/search/)根据标签过滤的结果。我很满意搜索功能的实现，但是发现搜索页面的访问量还是很低，干脆给它引流一下。\n\n## ServiceWorker 骚操作\n\nService Worker 最广泛的应用应该是根据不同规则缓存页面的静态资源，以便在不发生 HTTP 请求的情况下返回缓存的资源，来提高网页的性能。\n\n这个骚操作就用到了 Service Worker 最关键的两点功能：拦截和返回。具体来说，Service Worker 会拦截本站除图片外所有的静态资源的 HTTP 请求，然后在 Service Worker 内部根据请求的资源名同时去不同的 CDN 取数据，其中有任意一个 CDN 节点先返回完整的资源即代表本次请求成功。同时把其他正在等待返回的请求 abort。如果不 abort 的话，当同时请求的资源比较多的时候，浏览器可能会限制住后续的请求发送。\n\n> Chrome 是限制同一个 tab 每个 host 只能最多有 6 个 tcp 链接。\n\n以下是代码实现：\n\n```typescript\nconst ASSETS_PREFIXES = [\n    `CDN_HOST_1`,\n    `CDN_HOST_2`,\n    `CDN_HOST_3`,\n    ``\n]\n\nconst fetchAsset = (url: string, signal: AbortSignal) => {\n    return new Promise((resolve, reject) => {\n        fetch(url, { signal })\n            .then(async res => res.ok ? resolve(res) : reject())\n            .catch(() => reject())\n    })\n}\n\nconst catchAssets = async (pathname: string) => {\n    const controller = new AbortController(),\n        signal = controller.signal;\n    return Promise.any(ASSETS_PREFIXES.map(prefix => fetchAsset(`${prefix}${pathname}`, signal)))\n        .then(async res => {\n            const body = await res.text();\n            controller.abort();\n            return { headers: res.headers, body: body, status: res.status }\n        })\n        .catch(err => console.log(err))\n\n}\n\nregisterRoute(({ request }) => (request.destination === 'script' || request.destination === 'style'),\n    async ({ event }) => {\n        const parsedUrl = new URL(event.request.url);\n        const { body, ...rest } = await catchAssets(parsedUrl.pathname)\n        return new Response(body, rest)\n    }\n);\n```\n\n这个功能之前在饿了么的 NPM 镜像网站还没有下架的时候挺好用的，因为饿了么用的是阿里云的 CDN，在国内的访问速度非常快，后来饿了么的镜像失效后，其他的一些公益镜像速度就不太行了。也导致了我也一直没写文章介绍这个功能，感觉确实在如今有些鸡肋了。\n\n## 文章大纲自动滚动\n\n现在电脑端右边侧栏的文章大纲会自动跟随阅读的进度聚焦。如果大纲也可以滚动的话，那么大纲的滚动条会调整至当前页面正在阅读的次级标题正好为顶部的位置。\n\n之前一直觉得这个可能有点麻烦就没做，现在实现了发现确实有点麻烦，关键点在于边界情况：\n\n当网页设置了 `scroll-behavior: smooth` 属性时，且页面存在 A，B，C，……，J，K 等多个次级标题，导致文章大纲高度超过了容器高度限制，出现了滚动条。目前我已经看到文章末尾，此时大纲元素的顶部不再是 A 标题了；但当我通过大纲滚动条滑动到进度条最上面，并点击了 A 标题的链接，A 标题的链接此时在大纲容器里属于未溢出状态，同时由于 `scroll-behavior: smooth` 的存在，页面会逐渐从 K -> J -> ... -> C -> B 然后到达 A。而页面在向上滚动经过 C 标题的一瞬间，大纲也应该要随之聚焦到 C 标题，并将大纲滚动条调整至 C 标题为顶部的位置，而此时 A 已经向上溢出了，但当页面继续滚动到 A 标题时，大纲滚动条又回到了 A 为顶部的位置，这就会造成一种大纲进度条「反复横跳」的现象。\n\n有个比较简单的方法解决：~~不要设置这么多次级标题~~去掉 `scroll-behavior: smooth` 属性。去掉之后，页面会瞬间从结尾切换到 A 标题的位置。\n\n复杂的解决办法，设置一个信号跟踪自动滚动状态，：\n\n```jsx\nconst [isScrolling, setIsScrolling] = createSignal(false)\nconst [activeId, setActiveId] = createSignal('');\n\ncreateEffect(() => {\n    if (hash()) {\n        setIsScrolling(true) // 页面 hash 出现变化，设置自动滚动\n        setTimeout(() => setIsScrolling(false), 1000) // 一秒之后解除自动滚动\n    }\n})\n\nconst handleIntersect = (entries) => {\n    entries.forEach(entry => {\n        if (entry.isIntersecting && !isScrolling()) { // 当页面处于自动滚动状态的时候，不要激活对应的大纲 id\n            setActiveId(entry.target.id);\n        }\n    });\n}\n```\n\n## 一些微调\n\n另外还做了一些小的调整，没啥技术含量，统一在这里说一下：\n\n### 搜索页面\n\n现在点击搜索页面搜索的结果跳转也是增量更新了，不再需要请求完整的 HTML 页面了。这一点改动其实就是把搜索接口 API 返回的 URL 从绝对路径改成了相对路径。\n\n### 字体\n\n标题和正文的字体家族相较之前做了交换，标题改成了使用衬线体而正文改成了使用非衬线体，这样在文章详情的页面会显得没有那么锐利，阅读长文的时候眼睛不会那么累。\n\n### 构建参数\n\nvite 的构建参数加上了 minifyInternalExports 和 experimentalMinChunkSize，这让打包成的静态资源文件进一步减少。\n\n博客首页加载的必要静态资源（HTML、CSS 和 JS）只有 48 KB！全部请求也只有 12 个！强迫症表示很满意。"},{"title":"Generating Solana Vanity Addresses Using OpenCL","subtitle":"Faster Creation of Custom Solana Addresses","url":"/posts/generating-solana-vanity-addresses-using-opencl-en/","date":"2024-03-04T04:28:59.000Z","updated":"2024-03-04T05:46:12.000Z","category":"实验室","tags":["Web3","Solana","Vanity","OpenCL"],"content":"I have been researching Web3 related technologies recently. The first threshold to entering the Web3 digital world is owning a digital wallet. Wallet addresses can be understood as bank card numbers in the real world. Many people pursue numbers with good meanings (such as having as many 6s or 8s as possible at the end, or having unique meanings to themselves). The difference is that desirable bank card numbers usually require paying the bank to issue them, while wallet addresses only require you to spend time collision searching to generate them. These kinds of collided addresses are generally called vanity addresses, which are generated to satisfy one's vanity. In essence and functionality, vanity addresses are no different from other addresses for ordinary users.\n\n<!--more-->\n\nWhen running the address generation algorithm, GPUs have a huge advantage over CPUs: GPU stream processors have orders of magnitude advantages over CPUs, so using GPUs to generate vanity addresses will be much faster. After searching around, although Solana also has a tool called [solanity](https://github.com/mcf-rocks/solanity) written in CUDA, when I ran it on my RTX 3080, it did not perform much better than just using my CPU (someone also gave feedback that it did not achieve the expected performance at all). However, when I ran [profanity2](https://github.com/1inch/profanity2), an ETH vanity address generation tool written in OpenCL, the speed was orders of magnitude faster than just using CPU. So I started to study the encryption algorithms used to generate addresses, and decided to write one myself.\n\n\n## Implementation of Wallet Address Generation Algorithms\n\nFor different types of Web3 wallets, the steps to generate addresses are actually very similar. The biggest difference lies in the choice of encryption algorithms:\n\n1. Generate a private key, usually generating 32 random bytes;\n2. Convert the random bytes into a large number and then multiply it by the G point on the elliptic curve to get the public key coordinate point. This process is called derivation;\n3. Convert this coordinate point back into bytes, and perform some encoding or hash processing on the bytes as the wallet address.\n\nFor ETH addresses, the selected elliptic curve is secp256k1, and for Sol addresses, the selected elliptic curve is ed25519. After finding the corresponding coordinate point, ETH will hash the public key with keccak, and take the last 20 bytes and convert to hex as the address; Sol will directly base58 encode the public key as the address.\n\nSo, implementing the ed25519 and base58 two algorithms with OpenCL would get the job done.\n\nSince OpenCL syntax itself is based on C99 extensions, implementing cryptographic algorithms from scratch is not the preferred approach. Finding a C language implementation, verifying there are no issues, and then porting to OpenCL is a safer and more convenient approach.\n\nThere are many choices available online. I chose：[ed25519](https://github.com/orlp/ed25519) and [base58](https://github.com/chaika2013/base58)。\n\n## How GPUs Can Accelerate Computations\n\nBefore when I didn't really understand OpenCL, I copied some OpenCL code for calculating hashes online as a starting point. But when running 100,000 iterations, it was even much slower than just using the CPU. So I asked an expert in game rendering: \"How should GPU accelerated hash calculations be done? Why is my batch calculation slower than CPU?\" However, his answer did not resolve my confusion. He believed hash calculations could not be divided into blocks for computation, so using GPUs did not have any advantages. Only computations like image processing that could be divided into fine-grained fragments could demonstrate the superiority of GPUs. His answer made sense to some extent. For a single hash calculation, the GPU would not be faster than the CPU. What I actually needed was batch parallel computing of multiple inputs. Later I figured out that my input and calling method was problematic. I wanted to run 100,000 hash calculations. I should not have called the OpenCL kernel code 100,000 times, but should have called the OpenCL kernel code once, and then set 100,000 workers, and then computed 100,000 times in the kernel code.\n\n> Workers can be understood as threads. Their quantity is specified by the global worker size parameter passed when calling the kernel.\n\nSpecifically for the address generation algorithm, my approach was: randomly generate 32 bytes as the seed, then set the global worker size to `256 ** 4`. Each OpenCL thread gets the current thread id respectively, converts it to big endian byte format, and then overwrites the last four bytes. Each thread calculates once. If an address meeting the criteria is found, record it in the output. Then each round of OpenCL invocation, add 1 to the fifth last byte of the seed (carry over if max), to do iterative computation until an address meeting criteria is found.\n\n## Migration to OpenCL\n\nOpenCL programs are not like C programs that compile and directly run. Instead they are divided into two parts:\n\n1. Kernel code running on the compute device (i.e. GPU);\n2. Host code managing kernel compilation, execution, and data transfers.\n\nThe ed25519 algorithm and base58 algorithm are placed in the kernel code, and then an entry function is exposed for the host code to call and do subsequent processing of results.\n\nThe max obstacle I ran into during migration was the entry function problem. The OpenCL I was using which comes with macOS is version 1.2. Compared to standard C, OpenCL has the additional concept of address spaces, especially for parameters of kernel functions, where the address space has to be specified as global, private, or local.\n\nWhen I moved to Nvidia devices, I ran into more troublesome issues, because since OpenCL 2.0, function parameters with unspecified address spaces default to generic. If a private address space variable is passed into this function, it causes compile errors. Variables declared by default are private address space, so I had to manually change every called function parameter to generic address space, over 100 places in total (wtf...).\n\n## Differences with profanity2\n\nProfanity2 itself actually fixed the vulnerability in profanity where private key seeds were not generated randomly enough. But additionally it also had a major improvement - it does not generate private key seeds. Instead, it uses public key offsets to calculate different vanity addresses. Even if the public key is leaked, due to properties of elliptic curves, it is still infeasible to reverse derive the private key, maximizing private key security.\n\nWhen I first learned of this design, I felt it was really cool. So I researched the technical principles behind it in depth, and also wanted Solana addresses to use this method:\n\n1. Assume the original private key is `k`, offset is `delta`，then the new private key can be expressed as `k' = k + delta`. Due to properties of elliptic curves, this additive operation corresponds to point addition on the curve;\n2. The new private key `k'` will generate a new public key `P'`. Since public keys are private keys multiplied by the G point, `P' = (k + delta) * G = k * G + delta * G = P + (delta * G)` where P is the original public key, `P'` is the new public key, and `delta * G` is the offset multiplied by G, representing the effect of moving on the elliptic curve.\n\nTherefore, when profanity2 finds a delta that meets the target, adding delta to the original seed gives the target private key.\n\nHowever, Solana addresses cannot use the public key + offset method to generate. This is because ed25519 public keys are generated slightly differently: the original private key seed needs to first go through a SHA512 operation to get result H, then use the first 32 bytes of H converted to a large number to multiply by G to get the public key. This also means that even if I offset the public key by delta to get the target address, the input is actually H + delta. We do not know what changes to the original seed will result in SHA512 giving exactly an offset by delta, since SHA512 is also irreversible.\n\n## Result Comparison\n\nI am using an M1 MacBook Air. The hash speed using the official `solana-keygen grind` command is 0.3 Mh/s.\n\n| GPU                           | Memory Clock | TFLOPS      | Hash Speed |\n| ----------------------------- | ------------ | ----------- | ---------- |\n| Apple Silicon M1 | -            | 2.3 TFLOPS  | 1.2 MH/s   |\n| RTX 3080                      | 1188 MHz     | 29.2 TFLOPS | 23.1 Mh/s  |\n| RTX 4090                      | 1313 MHz     | 81.9 TFLOPS | 67.8 Mh/s  |\n\nAdditionally, tools for generating these Vanity Addresses eat GPU compute performance (not graphics or VRAM), so estimating performance of different GPUs using the TFLOPS metric will be closer to real world.\n\n> [The code](https://github.com/WincerChan/SolVanityCL) has been open sourced, feel free to compare."},{"title":"基于 OpenCL 生成 Solana 虚荣地址","subtitle":"更快创建自定义 Solana 地址","url":"/posts/generating-solana-vanity-addresses-using-opencl/","date":"2024-03-04T04:28:59.000Z","updated":"2024-03-04T05:46:12.000Z","category":"实验室","tags":["Web3","Solana","Vanity","OpenCL"],"content":"最近这段时间一直在研究 Web3 相关的技术，而迈向 Web3 数字世界的遇到的第一个门槛就是拥有一个数字钱包。数字钱包地址可以理解成现实世界的银行卡号，不少人会去追求号码有好的寓意（比如尾号尽可能多的 6 或 8，或者是对自己有独特含义的号），不同的是，银行卡号的靓号往往需要去银行花钱办理；钱包地址则只需要你花时间去碰撞生成即可。这种去不断碰撞得到的地址一般称为虚荣地址（Vanity Address），也就是满足自己的虚荣心而生成的，Solana 也形象地将这种行为称作 Grinding（磨），虚荣地址其本质以及功能性与其他的地址对普通用户来说没有太大区别。\n\n<!--more-->\n\n在运行生成地址的算法时，显卡相比 CPU 有很大的优势：显卡的流处理器相比 CPU 有数量级别的优势，因此使用 GPU 来生成虚荣地址会更快速。网上找了一圈，虽然 Solana 也有 [solanity](https://github.com/mcf-rocks/solanity) 这款使用 CUDA 编写的工具，但是我使用 RTX 3080 运行的生成其实和我用 CPU 跑不出什么多大的区别（issue 也有人反馈根本达不到预期的性能），而我在使用 [profanity2](https://github.com/1inch/profanity2) 这款 OpenCL 编写的 ETH 虚荣地址生成工具运行速度是相比 CPU 有数量级的差距。因此我便开始研究生成地址用到的加密算法，打算自己写一个出来。\n\n## 钱包地址生成算法的实现\n\n对于不同的 Web3 钱包种类而言，其实生成地址的步骤都是大同小异的，最大的区别在于选择的加密算法不同：\n\n1. 生成私钥，一般来说是生成 32 个随机字节；\n2. 将随机字节转化成大数然后乘以椭圆曲线上的 G 点，得到公钥的坐标点，这个过程称为派生；\n3. 将这个坐标点重新转化字节，对字节进行某些编码或者哈希处理作为钱包地址。\n\n对于 ETH 地址选择的椭圆曲线是 secp256k1，Sol 地址选择的椭圆曲线是 ed25519；找到对应坐标点后，ETH 会对公钥进行 keccak 哈希，然后取最后 20 个字节转 hex 后作为地址；而 Sol 则是直接对公钥进行 base58 编码作为地址。\n\n也就是说，用 OpenCL 实现 ed25519 和 base58 这两个算法就大功告成了。\n\n因为 OpenCL 本身的语法是基于 C99 的扩展，因此从 0 开始实现加密算法并不是首选的方案。找一个 C 语言的实现，验证没问题后移植到 OpenCL 是更安全、方便的做法。\n\n网上有很多选择，我选择的是：[ed25519](https://github.com/orlp/ed25519) 和 [base58](https://github.com/chaika2013/base58)。\n\n## 显卡是如何能加速计算的\n\n之前在不太了解 OpenCL 的时候，我在网上 copy 了一份使用 OpenCL 计算哈希的代码作为入手代码，但是在批量运行 10w 次时，甚至相比单纯 CPU 算慢了非常多。因此托朋友问了一个游戏渲染方面的大佬「显卡加速哈希运算应该怎么做，为什么我批量计算比 CPU 还慢」，然而得到的回答并没有解答我的疑惑，他认为哈希运算并不能分块计算，因此使用 GPU 并没有优势可言，而是像图像那样可以细粒度计算才能体现 GPU 的优势。他的回答某种程度上没问题，对于单次的哈希运算而言，GPU 不会比 CPU 更快，而我其实需要的是批量输入的并行计算，在后来我明白了，其实是我输入或者说调用方式有问题，我要运行 10w 次哈希，不应该是调用 10w 次 OpenCL 内核代码，而应该是调用 1 次 OpenCL 内核代码，然后设置 10w 个 worker，然后在内核代码里计算 10w 次。\n\n> worker 可以理解成 thread，其数量是通过调用内核时传入的 global worker size 参数来指定的。\n\n具体到地址生成算法，我的做法是：随机生成 32 个字节作为 seed，然后将 global worker size 设置为 `256 ** 4`，每一个 OpenCL 线程分别去获取当前 thread id，然后转化成字节的大端序格式，然后覆盖的末尾四个字节，每个线程计算一次。如果找到符合条件的地址，就记录在输出中。然后每一轮 OpenCL 调用，都会把 seed 倒数第五个字节 + 1（满则进位），这样来做迭代计算，直到找到满足条件的地址为止。\n\n## 迁移到 OpenCL\n\nOpenCL 程序并不像 C 程序一样，代码编译后直接运行，而是分成了两部分：\n\n1. 运行在计算设备（也就是 GPU）上的内核代码；\n2. 管理内核编译、执行以及传输数据的主机端代码。\n\n其中 ed25519 算法以及 base58 算法都放在内核代码里，然后暴露一个入口函数，由主机端代码调用，并对结果进行后续处理。\n\n我使用的 mac 系统自带的 OpenCL 版本是 1.2，在迁移的过程遇到的最大阻力就是入口函数的问题，OpenCL 相比标准 C 多了地址空间的概念，尤其是在内核函数的参数里，需要指定空间为 global、private、local 三者其一。\n\n而我在把程序迁移到 Nvidia 设备的生活，遇到的问题就比较麻烦了，因为自 OpenCL 2.0 开始函数的参数未指定地址空间默认为 generic，如果调用这个函数传入的是 private 地址空间的变量就会编译错误，而默认声明的变量都是 private 地址空间的，因此需要逐个把调用函数的参数都改成 generic 的空间，一共一百多个地方（掀桌子...\n\n## 与 profanity2 的区别\n\nprofanity2 本身其实是修复了 profanity 私钥 seed 生成不够随机的漏洞，但是此外它还有一个很大的改进，就是它不生成私钥 seed，由用户提供公钥，然后利用对公钥的偏移量来计算不同的虚荣地址，就算公钥被泄漏，但因为椭圆曲线的特性，也无法从公钥逆推出私钥，最大化地确保私钥的安全性。\n\n我初次了解这种设计时，感觉真的很酷，于是深入了解了一下这样做的技术原理，并且也想让 Solana 地址也采用这种方式生成：\n\n1. 假设原始私钥为 `k`，偏移量为 `delta`，那么新的私钥可以表示为 `k' = k + delta`。由于椭圆曲线的性质，这种加法操作对应于曲线上点的加法；\n2. 新的私钥 `k'` 将生成一个新的公钥 `P'`。由于公钥是私钥乘以 G 点，因此 `P' = (k + delta) * G = k * G + delta * G = P + (delta * G)`，其中`P`是原始公钥，`P'` 是新公钥，`delta * G` 是偏移量乘以 G 点，表示在椭圆曲线上移动的效果。\n\n因此，当使用 profanity2 找到满足目标的 delta 时，将 delta 加上原本的 seed 就是目标的私钥了。\n\n不过 Solana 的地址并不能使用公钥 + 偏移量这种方式生产，因为 ed25519 的公钥生成略有不同：需要对原始私钥 seed 进行一次 SHA512 运算得到结果 H，然后用 H 前 32 字节转化成大数去乘以 G 点，才得到公钥。这也就意味着，即使我对公钥偏移了 delta 得到了目标的地址，但是得到的输入其实是 H + delta，我们并不知道对原始 seed 进行什么样的变化才能让 SHA512 之后会得到刚好偏移 delta 的值，SHA512 同样是不可逆的。\n\n## 结果对比\n\n我使用的是 M1 版本的 MacBook Air，使用官方的 `solana-keygen grind` 命令计算的哈希速度是 0.3 Mh/s。\n\n| GPU              | Memory Clock | TFLOPS      | Hash Speed |\n| ---------------- | ------------ | ----------- | ---------- |\n| Apple Silicon M1 | -            | 2.3 TFLOPS  | 1.2 MH/s   |\n| RTX 3080         | 1188 MHz     | 29.2 TFLOPS | 23.1 Mh/s  |\n| RTX 4090         | 1313 MHz     | 81.9 TFLOPS | 67.8 Mh/s  |\n\n另外说一点，这种 Vanity Address 的工具吃的是 GPU 的计算性能（而非图形性能、显存），预估不同 GPU 的速度，使用 TFLOPS 指标会更接近真实情况。\t\n\n> [项目的代码](https://github.com/WincerChan/SolVanityCL)已开源，欢迎自行对比。\n\n## 一点感想\n\n两年前的我，自认为本身的技术已经达到了一个比较高的水平，再加上对搜索引擎使用的也比较熟练，我想我对软件开发领域的大部分技术已经信手拈来，就算真的遇到了没有接触过的领域或者技术（比如：计算机图形学），上手也无非是需要一个熟悉的过程罢了，而在过去工作的几年时间，我也没有遇到什么无法解决的难题。而这段时间学习 OpenCL 的编程其实是给我上了一课。\n\n虽然本文写的过程很轻松，但主要原因在于这不是我第一个接触的 OpenCL 的项目了，加上地址生成算法比较简单，只是涉及到椭圆曲线的点乘运算，完成这个项目也就花了十来个小时。回想起一个多月前，首次接触 OpenCL 项目时，遭遇的困难远比我想象的多得多，途中我也曾数次想过放弃——因为如果完全不了解一个领域时，你甚至都不知道如何下手，对 ChatGPT 提问也问不到点子上，那么自然也得不到想要的回答，但我终究还是坚持过来了。\n\n只是经过这次之后，我不再会那么「狂妄」的认为我已经熟悉了大部分技术了，计算机终究还是一个非常大的领域，我所了解的技术大部分也只不过是限定在 Web 开发领域而已。"},{"title":"Quantumult X 的链式代理配置","subtitle":"避免机场审计的一种方案","url":"/posts/quantumult-x-chain-proxy-setup/","date":"2023-11-12T02:50:12.000Z","updated":"2025-06-07T11:35:12.000Z","category":"实验室","tags":["科学上网","链式代理"],"content":"最近因为 Clash for Windows 作者被请喝茶的缘故，Clash 从内核到各平台客户端的仓库大部分都删库或者归档了，这也不能怪开发者太过风声鹤唳，毕竟还身在国内，写开源而已，犯不上和自己的人身安全作对。之前我一直都是使用 Clash 作为主要的科学上网工具，不过经此一役后我也在考虑是否应该放弃 Clash，于是我仔细梳理了一下目前对科学上网的需求，最终决定将 Clash 切换成 Quantumult X。\n\n<!--more-->\n\n## Clash 的缺点\n\n其实我很早就觉得 Clash 在 macOS 上使用有一些不便：\n\n1. 如果想要修改订阅加上分流规则或者自定义的服务器，需要更改机场的配置文件，但是机场的订阅一般又会定时更新去覆盖掉；使用第三方的工具转化或者合并机场的订阅文件算是一个解决方案，但是机场一般出于隐私考虑都会禁止使用第三方工具转换订阅；\n2. 本质上 Clash 只是一个代理工具，无法确保在电脑上运行的各个程序的流量都由代理转发——很多软件的网络设置是不经由系统代理的，尤其是在终端的应用：pnpm，go get，curl，brew，ssh，这在软件开发的时候其实还挺烦人的，还需要单独为每一个应用设置代理，不同应用的配置方式还不一样。Clash X Pro 提供的增强模式算是一个解决方案，不过同样也已经下架了。\n\n对于第一点，其实 Quantumult X 就做得很好，分流的规则以及机场的节点是分开配置的，而且无论你有多少不同机场的节点，你都可以通过新建一份分流规则来在所有节点之中切换，而且新建的分流规则并不会被机场本身定时更新的订阅所覆盖。\n\n对于第二点，其实是代理工具和 VPN 的区别，像是 Cisco Anyconnect 这种 VPN 工具，会新建一个虚拟网卡，并新增一条路由规则让所有应用的流量都流经此网卡，也就不再需要单独为不同的应用设置代理选项了。Clash X Pro 的增强模式也是使用这样的解决方案。\n\n> 注意，这种强制所有应用走代理与 Clash 提供的全局代理是不一样的概念，Clash 的全局代理意思是所有通过 Clash 的流量不经分流直接转发到机场节点。\n\n## 机场的审计\n\n对于稍微大一些的机场，都会添加各种各样的审计规则，也就是在服务条款里写的禁止访问政治敏感或者新闻等类型的网站。大部分的机场并不会写明具体是哪些网站被禁止访问，甚至也有些正常的网站会被「误伤」。\n\n对于机场的审计规则我在一开始时表示很不理解，毕竟科学上网就是为了突破 GFW 封锁，怎么机场还又给上了一道锁。后来我想明白了，这类机场一般都是在国内有中转入口的机场，而中转服务器架设在国内受到的监管会比家宽更加严格，本质上也只是机场主规避风险的一种手段。所以目前没有审计规则的机场，要么是直连境外的机场，要么是机场的规模不大，或者机场主愿意承担这种风险。对于前者，访问速度比不上中转机场，对于后者，我只能说：~~而你，我的朋友，你才是真正的英雄~~。\n\n不过，机场的审计规则对用户来说，也确实也有隐私泄露的风险存在。有审计规则，那必然就有记录审计日志，也就意味着你访问的浏览记录都会被机场所记录，最坏情况下，机场因为某些不可抗力的因素或者是被黑了，流出了所有用户的浏览记录……\n\n> **免责声明：本文并不是要教唆大家通过链式代理的方式去访问被机场封锁的网站，而是仅从技术的角度，探讨如何让自己的网络浏览更安全、隐私。**\n\n## 链式代理的原理\n\n那么，何为链式代理？\n\n其实和机场本身提供的中转类似，我们可以在机场线路外，再加上一层中转，也就是把机场的落地节点也当作是二次中转，而由我们自己的境外 VPS 提供真正的落地。网上有很多关于如何配置 Clash 的链式代理的教程，不过 Quantumult X 的却很少，所以我就来抛砖引玉了。\n\n以日常使用的中转机场来举例：\n\n![原理图](https://ae03.alicdn.com/kf/Sae910277fb994c92af9c418a36b1ea55y.jpg)\n\n先看不加上 VPS 的情况，我们的电脑到机场国内的中转服务器（Relay Proxy）是通过公网通信，中转服务器通常是国内的公有云（阿里云，华为云），然后再由中转服务器通过 IPLC/IEPL 等内网专线连接到海外落地服务器上，从而实现科学上网的功能。\n\n需要注意的是，虽然 IPLC/IEPL 不会被墙，但是因为它仍然有一端是处于国内，因此从你的所在地到中转服务器的线路也直接影响到了科学上网的使用体验。而当你请求被机场封锁的域名时，连接在中转服务器时就会被丢掉，根本不会再往专线另一端发了，因为中转服务器才是运行 Shadowsocks 的服务端，它可以直接拿到访问请求的域名。\n\n而在有 VPS 的情况下，我们就可以把机场线路的整体当成是中转服务器，由 VPS 来做落地（Final Proxy）。这样做的好处就是，流量会被加密两次，一次是中转机的加密，另一次是 VPS 的加密，而中转机拿到流量后，因此还存在一次加密，所以也根本看不到你具体的访问，只能看到是对 VPS 的访问，只有 VPS，才能看到你真正访问的域名。这样也能解决机场审计记录的隐私问题。\n\n经过了两次加密和转发，性能可能会有些损耗，不过这在浏览网页时一般是感知不到的（跑测速可能有细微差异。\n\n## 链式代理的配置\n\nQuantumult X 配置链式代理不复杂，而且配置完成后，并不会被机场的定时更新的规则所覆盖：\n\n### VPS 配置\n\nVPS 的服务端并不需要开启什么流量伪装或者混淆等复杂的配置，因为 VPS 与机场节点之间的连接并不过墙，设置一个稍微复杂一点的密码，选一个安全的加密方法即可，因此 Shadowsocks 就够用了，你可以参考[我的配置](https://github.com/WincerChan/QXRelayConv/blob/master/sample_shadowsocks.json)。\n\n### 添加 VPS 节点\n\n在 Quantumult X 点击设置 -> 节点 -> 添加，把以上配置填进去，标签可以随意，我填的是 hh-jp。\n\n或者在 Quantumult X 的 设置 -> 节点 -> 节点资源，这里可以加上 fast-open 和 udp-relay 参数：\n\n```ini\nshadowsocks=xx.xx.xxx.xxx:xxxxx, method=aes-256-gcm, password=xxxxxxxxx, fast-open=true, udp-relay=true, tag=hh-jp\n```\n\n### 修改分流配置\n\n在 Quantumult X 设置 -> 配置文件 -> 编辑，会弹出一个编辑框，在分流规则部分的尾部加入以下规则：\n\n```bash\nip-cidr, xx.xx.xxx.xxx/32, ♾️ Relay\n# 有两种选择，直接给 final 加上中转\nfinal, hh-jp, via-interface=%TUN%\n# 或者针对特定域名加上中转，我比较推荐这种\nhost-suffix, xxx.xxx, hh-jp, via-interface=%TUN%\n```\n\n其中第一行 ip-cidr 的规则，是为了让所有流经 VPS 的流量，都通过机场的节点进行中转，`♾️ Relay` 这个策略组是我新建的，你可以把它重命名为你目前现有的规则策略或者新增一个策略组来专门做转发。\n\n我比较推荐后者，选择新建一个策略组并把与 VPS 在同一个地区的节点都加进来，这样从中转节点到 VPS 的延迟就会更低。\n\n如果你觉得一个域名一个域名加比较麻烦，也可以直接针对 final 添加中转，需要注意如果已经存在 final 的规则，把原有的删掉。不过我并不推荐直接给 final 规则加上中转，因为我觉得 final 规则应该设置成距离自己最近、延迟最低的节点。\n\n> 我为此写了一个[简单的工具](https://github.com/WincerChan/QXRelayConv)，可以更方便的管理需要链式代理的域名，可自行部署在 VPS 上。\n\n## 如何确认配置成功\n\n有两种方式：\n\n### 在 Quantumult X 查看流量日志\n\n在 Quantumult X 的网络活动菜单栏，请求配置后的中转域名，应该会有两条流量记录产生：一条记录的目标服务器是 HH-JP，也就是我配置的 VPS 节点名称；另一条记录的目标服务器就是 JAPAN 17，也就是机场的节点。\n\n![流量日志](https://ae05.alicdn.com/kf/Sa9b8b3428d4a46b8b2527bb7e8daae74Q.jpg)\n\n### 在 VPS 节点查看\n\n在 VPS 运行命令：\n\n```bash\n$ lsof -i:[listen_port]\nCOMMAND    PID        USER   FD   TYPE SIZE/OFF NODE NAME\nssserver 21286 shadowsocks   11u  IPv4      0t0  TCP [listen_ip]:[listen_port] (LISTEN)\nssserver 21286 shadowsocks   13u  IPv4      0t0  UDP [listen_ip]:[listen_port]\nssserver 21286 shadowsocks   14u  IPv4      0t0  TCP [listen_ip]:[listen_port]->[relay_ip]:[port] (ESTABLISHED)\n```\n\n你需要查看，与 VPS 建立连接的这个 relay_ip 是否是你选择的中转策略的 IP，或者确认它不是你目前宽带的 IP 就行。\n\n## 机场的选择\n\n最后，还是谈谈机场的选择，我并不建议把机场是否有审计规则作为评价机场好坏的标准，因为可能科学上网 99% 的情况下都不会碰到被审计规则封锁的网站。而我在过去一年自费购买了差不多 10 家机场，其中只有一家规模不是很大的机场没有审计规则，这家机场的线路比较少但是流量又比较贵，因此我并不会推荐这家。\n\n如果你不知道机场有审计规则这回事，那你就继续安心用；如果你目前的机场用的挺满意但是带有审计规则有点膈应，所以想换一个没有审计规则的机场，请慎重考虑。\n\n目前的科学上网工具大部分都是支持链式代理的，我也比较推荐你用链式代理 + VPS 来绕过审计规则，如果你用的科学上网工具不支持链式代理，那么我更推荐你换掉工具而不是机场。\n\n## 合作推广\n\n如果你还在选机场，可以参考下面两家我近期合作体验的机场，均能确保晚间高峰时期的访问速度。\n\n另外，这两家机场经我测试没有对我在本文之前提到的常见政治、新闻等网站的屏蔽。\n\n### 青云梯\n\n2020 年成立，SS 协议 + IPLC 线路，80+ 全球节点，含印韩法德等冷门节点，全流媒媒体解锁，支持企业级定制线路。\n\n月付 ¥25 / 150 GB 流量起，另有少流量用户特惠：年付 ¥96，每月 60 GB流量，[点我注册](https://ponzicc.qytvipaff.cc/register?aff=noUz4H25)。\n\n### 银河云\n\n2024 年新成立， Trojan + IEPL 线路，30+ 常用地区节点。\n\n月付 ¥18 / 100GB 流量起，另有售价 ¥680 的 1000G 不限时套餐可选，[点我注册](https://ponzicc.galaxyvipaff01.cc/register?aff=v6mY636X)。\n\n可点击注册链接选择月付体验稳定性后，再考虑季付 / 年付。"},{"title":"世界与我的一次邂逅","subtitle":"年轻人的第一次出国旅行","url":"/posts/when-the-world-met-me/","date":"2023-10-13T02:36:23.000Z","updated":"2023-10-13T02:59:23.000Z","category":"行走记","tags":["旅行","韩国","出国"],"content":"我其实之前一直对旅行提不起什么兴趣，一开始觉得这只是因为我的性格比较内向、不愿同陌生人发生不必要接触，后来往深了想这其实是来自于我内心追求安逸、拒绝踏出舒适圈的映射。那么为什么我会想到来突破这个舒适圈呢，这很大程度归咎于我开始健身了。从三个月前跑两公里就累得要死，到现在已经可以比较轻松地跑完五公里，我的确成长了不少。因此我觉得适当突破一下舒适圈也许不是什么坏事情，于是就有了这次的韩国旅行。\n\n<!--more-->\n\n毕竟是第一次出国，选择目的地费了一些心思，不能太远，最好是个发达国家，加上女朋友之前一直都在青岛出差，离韩国最近，于是就选定了韩国。结果因为女朋友假期匆忙开始的原因，还是从广州出发了，也导致策划得有些不够充分，这些我都会在文章里注明，希望能给有需要的人带来帮助。\n\n\n## 必备物品\n\n### 签证\n\n淘宝找旅行社办的 5 年多次签，价格九百多一个人，一周多顺利出签。出签后把电子版打印，出发时带上就行，出境值机时和入境边检都会查验。\n\n网上看到说最好把行程单以及往返机票打印出来，出境时有人会询问，但我并没有遇到。\n\n### 电话卡\n\n国内能订购的韩国电话卡大致分为 3 种：\n\n1. 纯流量卡，不包含手机号，不用预先激活，到韩国插卡用，这类卡的价格也是最为便宜的；\n2. 邮寄的电话卡，包含手机号，在国内即可寄出实体 SIM 卡，需要联系客服提供护照等信息，到韩国后要联系客服发入境凭证才能激活，这类卡价格适中，但是激活步骤比较麻烦；\n3. 机场领取的电话卡，包含手机号，需要在韩国的机场柜台领取，不需要联系客服激活，在机场找柜台让他们帮忙插卡就行，这类卡价格一般是最贵的，但比较方便。\n\n如果是只在首尔等公众交通比较方便的地方玩耍且预算有限，我比较推荐第一种，而我们因为要去济州岛玩，济州岛没有地铁，基本上出行只能靠打车，打车软件 Kakao Taxi 需要韩国的号码才能注册，因此我们选择了购买两张 LG U+ 电话卡，语音通话额度可以在机场领取时充值，我们充了 40 分钟，不过完全没用到。\n\n> 不用考虑国内的电话卡开漫游了，价格贵太多，我是联通卡，打电话问了客服，他说日韩的流量是按 MB 来收费（5 元 / MB），每天封顶 25 元，每天首 1GB 是高速流量，超过后变为 2g 网，也就是十天一共会花费 250 元。\n\n### 转换插头\n\n建议提前在国内买个质量好一点的，办签证、电话卡送的插头质量很差，插上吹风机吹了几分钟就烧坏了…\n\n### 现金\n\n一线城市大部分银行应该都有提供韩币兑换，不过如果你所在的城市银行恰好没有韩元，可以选择兑换成美元，然后带美元去首尔的换钱所兑换，换钱所美元换韩元的汇率优于人民币换韩元。\n\n### T-Money 卡\n\n类似国内的交通卡，地铁、公交、便利店都可以用，可以在地铁站或者便利店用现金充值。因为我购买的电话卡自带 T-Money 的功能，所以就没有买，可以提前在网上买或者等到了机场便利店再买。\n\n### *WOWPASS\n\n在写这篇文章的时候，发现了韩国有为国外旅客专门提供付款、换汇、T-Money 功能的储蓄卡。不过我们在出游时还不知道这个，因此没用上，下次去就打算办一张了，有这个就不用专门带信用卡了。\n\n## 餐饮\n\n首尔的物价水平挺高的，比国内的一线城市还高不少。随便找个路边小店吃饭两个人基本上要花 16000 韩元以上，店的规模就是猪脚饭或者拉面店的级别。\n\n> 以可乐来对比衡量物价的话，500ML 的可乐在便利店的价格是 2000 韩元。\n\n韩国吃的种类很少，主食基本上就是烤肉、拌饭、面、酱汤等。餐馆一般比国内要早关门，大约 9 点就会关门，但是其实提前半小时就会停止接纳新客了。\n\n我们刚去首尔的前两天因为时差没倒过来，早上起来就十点多了，煮点泡面吃就十一点了，下午两点多才饿，而两点多大部分餐馆都是休息时间，午饭吃得晚就又会导致晚餐吃得晚，所以我们在首尔就经常出现饿肚子找饭店…炸鸡店、大排档之类的虽然开到深夜，但也不能当主食吃。\n\n济州岛的物价比首尔高（毕竟是离岛），不过可能是因为济州岛中国人很多，又或者是我们的作息调整过来了，在济州岛吃的反而觉得比首尔舒服一些。\n\n## 住宿\n\n我们在韩国一共住了 9 晚：首尔 6 晚，济州岛 3 晚。其中在选择首尔的住宿位置上犯了一个比较大的错误，一开始想的是住在明洞或者弘大附近，但是担心周围比较喧闹会影响睡眠，于是选择了住在了鹭梁津洞，它距离明洞、弘大，江南地铁都只需要 20 分钟左右的地铁路程。一开始我还因为选择了这个绝佳的地理位置沾沾自喜，但实际住了几天之后才发现完全不是这样。\n\n首先是吃饭不方便，楼下的店铺很少，基本上就是炸鸡店 + 便利店 + 大排档，没有早餐店，所以早餐只能在家煮泡面。晚上逛完也只能选择在外面吃完再回家而不是在楼下吃，这点真的很要命。\n\n其次，离三个热门商圈都很近其实也就是离任何一个商圈都不近，这对于逛街来说其实挺致命的，因为二十分钟地铁加上走路和等地铁的时间基本上就需要半个多小时了，而且我们去的那几天还正好赶上了韩国地铁的罢工，发车间隔十几分钟。\n\n所以如果再去首尔的话，我们肯定会选择住在热门的地方，这样下楼就是商圈，餐厅多，也不需要专门乘坐交通工具去逛，早上出门或者晚上回家抽点时间逛一下就行了，一次两次逛不完，住个三五天，逛个十次八次就熟悉了，白天的黄金时间去逛远一点的地方，这样在首尔会逛的比较惬意。\n\n济州岛的住宿是在 Sogil-ri，一个典型的济州乡村，有着很不错的自然风光，房东提供的早餐也很丰盛。\n\n## 交通\n\n首尔的地铁还是挺方便的，热门商圈基本全覆盖，下载一个 Naver Map 或者 Kakao Map 可以查看地铁运行情况。Google Map 或者别的导航在韩国基本处于半残状态。\n\n在首尔一般情况下是不用打车的，有需要的话可以试试 Uber 和 Kakao Taxi，其中 Uber 可以线上支付，不过车辆少一些，我在济州岛的各个地方都使用过 Uber 但是都叫不到车，首尔可能车辆会多一些。Kakao Taxi 本身是支持线上支付的，但是只支持 Kakao Pay，而且需要绑定韩国的银行卡，因此我们用不了，还是只能给司机现金。\n\n> 无论是 Kakao Taxi 还是 Uber，账户注册都需要本地的手机号接收验证码。\n\n第一次搭乘国外的航空——韩亚航空的航班从首尔飞到济州岛，价格很便宜，才两百出头（没有燃油基建费，这就是总价），类比国内大概就是广深飞海口，广深飞海口一天的最低价也是两百多，但是时间很阴间，不是大早上就是大半夜。下午时段最低也要五百多，加上燃油基建费，就要七百了。\n\n另外如果大家也需要在首尔飞韩国国内的话，尽量选择韩亚和大韩航空，其他的都属于廉价航空，虽然价格更便宜（一百多），但是值机时人很多、柜台很少，飞行体验也会比较差。\n\n去济州岛游玩的话，建议多备一些现金打车用，公交线路基本上只有环岛和从济州市到西归浦市的。\n\n## 景点\n\n首尔大部分景点都玩了，景福宫、明洞、弘大、江南、爱宝乐园等等。不过我对城市景观并没有多大兴趣，而且根据女朋友的对比，其实大部分商品在首尔免税后的价格还不如中免日上的价格低。\n\n这次在济州岛呆了两个完整的白天，第一天去了涯月海岸道路，沿着海边走了一会发现太阳太晒了，找了个风景很好、靠海的咖啡厅呆了一下午，傍晚在海边找了个皮划艇，价格是三万韩币，两个人可以划半小时。\n\n第二天去爬了汉拿山，从御里牧入口上山，然后从灵室入口下山。整个路程共花费了 5 个小时，因为之前已经跑步了一段时间，所以倒没感觉吃力。不过爬汉拿山的时候需要做好防晒，我们防晒霜漏擦了鼻子，结果爬完山下来被晒了个红鼻子……\n\n另外因为汉拿山的海拔接近两千米，气温会下降的比较厉害，山顶的紫外线也很强，所以最好穿长裤以及防晒服。我们就是穿短袖短裤爬山，上山的时候不冷，但是爬到山顶歇了一会突然起雾，风一吹就感觉好冷。\n\n## 吐槽\n\n在韩国遇到的大部分人其实都挺友好的，不会因为你不会韩文就歧视你——除了我在涯月海岸公路的一家名为（Team Blow）咖啡厅，这家我感觉歧视中国人：我们点了两杯饮品在窗前坐着看风景拍照，隔壁坐的是三个韩国人，占了两个小桌子。因为我们拿了一个大袋子，所以放在了一个单独的椅子上。然后等隔壁三个人走了之后，店员马上跑过来问我们是不是两个人，如果是的话需要把袋子拿走，不能放在椅子上。\n\n一开始我倒没有觉得这个事是歧视，就把袋子拿走放在小桌子上了，没过多久隔壁就又来了一对韩国情侣，他们喝完很快就走了，过了一会儿我们也准备走，走到门口的时候，店员跑过来拦着我们不让我们走，说什么 Return 之类的，我以为是问我们还回不回来，结果是让我们把咖啡盘送到回收台！可问题是，我明明看到之前走的一对韩国情侣走的时候也没有把餐具送到回收台，是店员收的！\n\n走出来后，和女朋友讨论了一下，越想越觉得被歧视了，另外抛开这些不谈，价格也挺离谱的，两杯果汁 16500 韩元（差不多 90 元人民币），还不如蜜雪冰城好喝。建议大家也避开这家咖啡店。\n\n## 感恩\n\n除了咖啡厅的店员歧视，我们也遇到了超级好的公交车司机——从汉拿山灵室出口到济州市中心的线路（忘记是几路公交了）。当时我们只有一张 5 万面额的纸币，并且忘记携带 T-Money 卡了，于是我们上车就问司机这个 5 万的纸币能不能用，司机不会说英文，我们沟通起来很困难，但是司机就一直在车站等着和我们沟通，后来有另一个热心的大姐，先是问我们的目的地是否在公交车行驶路线上，然后得到了肯定答案后，司机就让我们先坐下。然后让大姐把司机的钱包拿出来，给我们换了 5 张 1 万面额的纸币，然后投了 1 万的纸币，因为投币机只能找出 500 面额的硬币，所以司机是按了 17 次找零的按钮，才找了 7500 的零钱给我，真的太感谢司机了！\n\n## 花费\n\n花费的钱其实比我想象的多一些：\n\n| 分类 | 首尔                                                         | 济州                              | 小计     |\n| ---- | ------------------------------------------------------------ | --------------------------------- | -------- |\n| 住宿 | ¥3433.78（6 晚）                                             | ¥1704.58（3 晚）                  | ¥5138.36 |\n| 机票 | ¥3256（飞首尔）                                              | ¥429（飞济州岛）+ ¥1266（飞上海） | ¥4951    |\n| 餐饮 | ¥1507                                                        | ¥758.55                           | ¥2265.55 |\n| 购物 | ¥4788.54（衣服 + 化妆品 + 包）                               |                                   | ¥4788.54 |\n| 美妆 | ¥2320（色彩分析 + 骨骼诊断）                                 |                                   | ¥2320    |\n| 旅游 | ¥850（拍照）+ ¥446（爱宝乐园门票）+ ¥376（手机卡 + AREX 票） |                                   | ¥1672    |\n| 杂项 | ¥1096.3（纪念品，灵室，等）                                  | ¥871.7（皮划艇 + 家人礼物）       | ¥1968    |\n| 现金 | ¥1272（某一天的晚餐，交通卡充值，小商品）                    | ¥415（出租车）                    | ¥1687    |\n\n二人共计花费：¥24790.45。\n\n## 总结\n\n这次旅游现在回看其实是有不少缺点的，安排得匆忙了些、一开始打算在首尔住 4 晚，但是因为时间安排不过来又额外定了两天住宿，导致了一些额外支出，济州岛的东部以及南部没有去等等……不过，我对我的第一次出国旅行还挺满意的，见识到了不同的风土人情。让我意识到了之前想法的问题所在：性格内向和旅行并不是冲突的，主要是我不想迈出舒适圈。\n\n本次旅行给我的感受还是挺特殊的，**万般新奇，我亦新奇**。后续我也会在博客上继续分享我的旅行记录。"},{"title":"离职，三年未满","subtitle":"很不舍，但没有更好的选择","url":"/posts/company-departure-after-3-years/","date":"2023-05-31T15:59:59.000Z","updated":"2023-05-31T14:59:59.000Z","category":"碎碎念","tags":["离职","工作","感想","思考"],"content":"我曾在离开上家公司时[做过总结](/posts/ee6b678/#总结--打算)，离职的原因肯定是公司有些毛病你无法忍受却又无力改变，如今看来，这句话多少有些片面：因为我所在的部门同事和领导关系融洽、工作氛围还算轻松，可我依然决定了离开。这倒不是说公司没有毛病，只是说毛病还没有到让我无法忍受的地步，相比于有同事打小报告、工作氛围卷得要死的前公司来说，简直是小巫见大巫。\n\n<!--more-->\n\n而今，促使我决定离开的最重要原因则是工作内容：我已经无法对目前的工作内容提起兴趣了、甚至还感到了一丝厌恶。我在之前的文章多少提到过一些，现在我既已选择离开，倒可以好好说一下了。我会按照时间的顺序讲述我入职的三年的经历以及我心态上的变化。避免隐私泄漏，我会在叙述时故意模糊一些关键细节。\n\n> 简单介绍一下，我们产品的定位是对企业的流量进行检测和分析，结合云端的情报与本地的算法模型，定位企业网络内存在的各种威胁。\n\n## 入职前\n\n我在离开上家公司后思考自己的职业规划时，曾在博客的关于页面写下：*现在的理想是做一些真正为人所需要的软件或者产品，让人们的生活可以更舒心、高效，也借此来满足我内心的满足感*。因此当时在论坛上看到部门招聘的帖子时，我就动心了，面试时进一步了解到部门正是因为觉得当时的安全产品都同质化严重，想做出一款市场真正需要的安全产品，这正和我的未来职业规划不谋而合，于是我抱着很大的期待，加入了当前部门。\n\n## 理想的状态\n\n入职以来的 10 个月是我梦想的工作状态，也就是到 2021 年六月截止，我曾不止一次的怀念这段时光。我在这期间的工作很纯粹：只是做产品的研发，这也是我最享受的一段时光，我像海绵一样疯狂地吸收在这段时间里我接触到的知识，并将它们应用到产品里。包括学习 GraphQL，并对 Dataloader 异步改造、学习基于三重指数平滑方法，并设计异常流量监测系统等等。\n\n这期间学到的知识大多数都是我之前没有听过的，不过我本身就是十分乐于研究学习的，何况这也能够拓宽我的知识面，让知识体系更加完整，本质上也是我自己受益。虽然我那段时间还是按时下班，不过回到家后我也会继续研究工作上的东西。虽然有些累、但是我非常满足。\n\n这里也挺感谢当时领导的支持。\n\n## 过渡\n\n在产品本身的主体功能开发完成后，我接下了另一项重担——产品的部署工作：即如何把各个组件用自动化的方式在一台裸机上安装并运行。最终我花了两个月的时间敲定使用 Kickstart + Ansible 的方式来完成产品的部署工作。我将这两个月定义为理想到现实的过渡阶段。\n\n这期间我遇到了很多问题：包括对 Ansible 的不熟悉、U 盘引导怎么都无法识别 Kickstart 文件、不同硬件的设备兼容性考虑等等。我在这期间的工作与其说是一名开发，到不如说是一名运维。当然我对运维工作倒没有什么偏见，我最终还是完美地完成了这项任务。\n\n只是，我没想到产品部署这件事情所带来的影响，会超乎我的想象。\n\n## 平台期\n\n2021 年九月底，产品正式发布，我也步入了为期 1 年的平台期。由于产品的部署都是由我主导的，因此每一个申请试用产品的客户，都需要我来负责产品在客户提供的设备上的部署工作。这其实是一件很费力的事情，这也是我对工作内容感到厌恶的开始：\n\n1. 客户提供的设备配置大相径庭，有的设备配置很差，我提前让销售告知了客户大概率是无法成功部署的，不过客户还是坚持试试；\n2. 因为疫情的原因，出差是很难的（我更讨厌出差），因此公司会派客户所在地的实施人员去客户的现场，然后由我来远程指导他怎么做，而实施人员大部分的计算机基础都很差，而且大部分的客户机房管理都比较严格，只能用手机拍电脑屏幕，然后得到答案后再输入电脑，沟通、解决问题的成本非常高；\n3. 客户公司不让联网，必须让我们的产品在离线状态下运行；这一点在很多银行或者国企是普遍存在的，但是我就感到很奇怪，断网的情况下用我们产品的意义显然是不大的。而且产品的设计之初就是需要结合云端情报分析，所以为了挽留住客户又不得不针对离线情况做移植。也就是从这开始，让我觉得似乎和我职业规划的目标有些出入了。\n\n你可能注意到了，这三个问题都是由客户方带来的。这也是我认为目前 toB 的网络安全行业的困境：\n\n## 行业的困境\n\n在这个行业里，网络安全公司就是典型的吃力不讨好，企业客户就是又吃又拿：我们这边出人（开发、实施、销售、项目经理）又出力，客户那边提供个机器就行（有时甚至连机器都需要我们提供），使用几个月之后还不买，摆明了就是想白嫖，但是又不得不维系客户关系。所以你很难能见到赚钱的网络安全公司，基本都是营收越高，亏的越多。\n\n中国的网络安全行业其实是一个「畸形」发展的行业，因为这个行业的需求并不是由市场决定的，而是很大程度上由那句「没有网络安全就没有国家安全」的话创造出来的。所以这个行业 99% 的客户都是国企或事业单位，为了要响应国家的号召，从而购买一些安全产品，至于有没有用——who cares。网络都物理隔离了，还有比这更安全的方法吗？\n\n中国的非国企单位就没有网络安全的需求吗？当然有，而且这些公司大多是真正的有这方面的需求，但是这些公司不会选择用其他的公司开发的安全产品，因为使用了安全产品反而引入了不安定因素，不安定因素来自安全产品本身可能存在的漏洞，以及与现有架构集成后系统复杂度增加的风险，所以通常自己来做解决方案，自然也不是 toB 网络安全公司的目标客户了。\n\n## 心态的变化\n\n如今回想看来，自进入平台期开始，我的心态就已经出现了变化，只是这当时心态的变化并没有被我所察觉，却也潜移默化影响到了其他的地方。比如，我在 2021 年九月到 2022 年九月，只写了 2 篇博客，因为工作上的焦头烂额已经侵入了我的正常生活，下班后我只想着放松（甚至捡起了我许久没碰过的网络小说），对学习提不起兴趣了。\n\n这一年里我也并非没有想过解决这个问题，我在 2022 年新年时就和领导提过，我不喜欢目前的工作内容，第一次提时，可能是因为我措辞比较委婉，领导没有太在乎以为我只是发牢骚；直到过了两三个月我再次提起时，领导才重视起来，开始让我把部署相关的事情给公司的安服团队以及另一位同事分担。一开始我确实以为这样能解决这个问题，后来发现是我想的简单了。\n\n在平台期里，我们不到几个月的时间又发布了新产品。很奇怪对吧，上一个产品发布才不到半年，怎么又开始了发布新的产品，当时的我们也都很奇怪。领导是这么解释的：市场部的同事研究发现，现在的安全市场对某方面有很强的需求，于是我们做出一款产品专门抢占这部分市场。也就是说新产品完全是为了「迎合市场」来做出来的，考虑到埋头苦干两年多的产品因为对市场需求的错误判断导致销量惨淡，那么新产品肯定能一举挽回销量的颓势……吗？\n\n不过在新产品开发的阶段，我也的确短暂地找回了刚入职时的感觉，不过没多久又回到了这种状态中，我才知道，有些事情是没办法的。\n\n焦头烂额的事情还包括产品运行时 bug 的定位与排查，网络安全产品的核心流程其实差不多：无非是监听流量、解析流量并入库、匹配情报、产生告警。在客户环境里，表面现象往往都是无法产生告警，但是深层次的原因是因为情报还是解析流量的问题，还是需要由「我」来排查，因为我主导了产品的部署，最熟悉产品各个组件的作用。由我定位到问题后，再找组件具体的开发人员解决。\n\n所以我说，有些事情是没办法的。\n\n## 动荡期\n\n紧接着平台期，在 2022 年九月，公司的组织架构进行了剧烈的调整，字面意义上进入了动荡期。当时正在和我对接部署工作的安服团队，被一锅端了，不过还好当时的部署工作已经基本上都交给同事了，只有在问题排查的时候才需要我来处理。之后没过多久，我们小组就被裁了一个，当时剩下的我们都处于一种因为动荡衍生出的不安状态，做事肯定是没心思了，整天担心自己会不会被裁。\n\n浑浑噩噩地过了两个月，到了年底时，领导居然还没有沟通绩效。于是脉脉上也开始有人爆料出今年不发年终奖了，可毕竟也只是爆料，这时，最应该出来稳定人心的时候，公司却选择了任风言风语愈演愈烈。\n\n年后，部门裁员了一批后，相比去年打对折还要少的年终奖终于到手。紧接着公司又开始了一批批的裁员，而我，也在这时最终决定了离开。\n\n> 在这之后，我开始慢慢理解了：~~一个人的命运啊，当然要靠自我奋斗，但是也要考虑到历史的行程~~社会整体经济处于下行时，个人的力量是非常渺小的，公司的一轮又一轮裁员只是一个小的缩影，没有人能独善其身。\n\n## 无奈\n\n世事无常，难免无奈。我不愿再陷入这双重情绪的挤压之中了：一方面是公司动荡的不确定性；另一方面是对工作内容的不喜。因此，就算同事关系再融洽、氛围再轻松（现在其实也不存在什么氛围了，部门裁得只剩下一小半了），我也唯有选择离开了。\n\n在公司的三年时光，给我的感觉和念书时很类似：第一年是雄心壮志，第二年是平淡无奇到乏味再到反感，第三年则是无奈、不安，快离开时则是怀念，我也的确从这份工作学到了很多东西。这次离职，没有不忿，只有不舍，毕竟我所不喜的工作内容领导已经尽力帮我摆脱了，只是无法全部摆脱，我想究其原因是身在 toB 的网络安全行业，下份工作我会考虑换个行业试试。\n\n很幸运与部门同事一起度过三年的时光，我会永远怀念这段职业生涯。\n\n前路漫漫亦灿烂，往事堪堪亦波澜，江湖相见。"},{"title":"使用 Hugo + SolidStart 重构博客","subtitle":"今年度的重构博客，比以往来的更早一些","url":"/posts/reconstruct-my-blog-with-hugo-solidstart/","date":"2023-05-07T06:01:23.000Z","updated":"2023-05-10T15:15:23.000Z","category":"博客栈","tags":["SolidJS","博客","Hugo"],"content":"在去年年底时，我[重新设计](/posts/about-recent-blog-updates/)了一版博客的主题，不过此版主题主要是针对 UI 样式方面的调整，底层的架构没有变化：静态内容还是 Hugo 生成，动态内容如：搜索、消遣页面，暗色模式、评论等功能则是由 Svelte 提供支持。这个技术栈使用起来其实挺搭的：Svelte 打包后的结果很小，生成的 JavaScript 文件直接在 Hugo 模板中用一个 script 标签引入就行了。\n\n那么，是什么原因让我仅仅时隔半年的时间就再次重构博客呢？让我先卖一个关子，先说一下 Hugo 的一些问题。\n\n<!--more-->\n\n## Hugo的缺点\n\n\nHugo 其实本身的集成度很高了：模板生成、静态资源打包、自定义的输出格式等功能都有。但有两点我用着不是特别舒服。\n\n### 开发体验\n\nHugo 主题的开发体验太差了，差的体验其实都和它的生态相关。\n\n1. VSCode 的插件本身提供的功能非常有限：文件跳转不行、语法高亮残废、代码补全仅限于一些基础的 snippet。而且因为 Hugo 的 template 是扩展的 HTML 语法，如果写了稍微复杂一点的 Hugo 表达式，在保存自动格式化时有时候会按照 HTML 的语法缩进，导致表达式的出现语法错误，这时候只能在右下角将语法切换为 Plain Text，然后再保存。\n\n2. Hugo 本身本身虽然具备 JavaScript 和 Sass、SCSS 文件的打包功能，但其实支持都比较有限:\n   - JavaScript 的打包是由 ESBuild 提供支持，但是你不能在 Hugo 中添加 ESBuild 的插件；\n   - Sass、SCSS 的支持需要通过 npm 来安装 PostCSS、Bable 的支持同样需要通过 npm 安装 Babel.js 依赖。\n\n\nHugo 在很努力地支持这些现代化前端构建工具，这些是开发组的努力，但只能说任重而道远啊。\n\n### 黑盒\n\n\nHugo 内部具备了非常多的功能，但是就像一个黑盒一样是集成在它内部的，我三年前从 Hexo 切换过来的时候，正是看中了它这一点，但直到我自己开发起来我才发现这其实并不是什么好事。因为有些功能你总会需要自己来定制实现的，比如博文加密、构建前后的 Hook、针对某些元素自定义渲染等，这种功能可能并不是每个人都会用到，开发组不做也很正常，但是我觉得 Hugo 的开发组对此的态度也有一点奇怪。\n\n很早之前我在寻找 Hugo 博客加密的方案时，曾经想过一个方法就是在 Hugo 渲染的时候调用外部的可执行文件或者脚本（Shell 或者 .go 文件），于是我就搜了一下，发现早在 2015 年就有人提了 Issue，开发者一开始也认为这个想法很赞，不过还是出于安全（？）以及兼容性的考虑放弃了这个做法，并把这个 Issue locked 了。开发组对不同平台的兼容性有顾虑这一点还是有道理的，不过说出于安全的考虑我真的是没搞懂，开发组似乎是担心有人在主题文件里的可执行的脚本加入了恶意代码，执行起来就会导致设备中毒或者删除数据之类的，乍一看好像还挺有道理的，可仔细一想完全不通啊。哪个语言的包管理器都支持从网上下载代码啊，怎么难道他们都不担心下载的是恶意代码吗？\n\n另一个让我不喜开发组的例子是 Markdown 元素的自定义渲染，目前仅支持有限的渲染：标题标签、超链接标签、图片标签、代码块标签（这个还是最近加上的），当询问到为什么不支持更多的标签自定义渲染的时候，开发组说因为担心渲染的性能问题，所以只开放了这几个，可 Hugo 的渲染速度真的很快很快了，我博客的近三百个页面，只需要 120 ms 的时间就可以全部生成，就算加上所有的标签的自定义渲染会牺牲 50% 的性能，我认为大多数的人都是可以接受的，甚至他们根本感受不到区别。\n\n开发组的态度，加上 Hugo 本身像是一个黑盒，所以 Hugo 的生态其实很差，仅仅是包括一些主题而已，任何针对 Hugo 本身功能上的扩展都没有。\n\nAnyway，吐槽归吐槽，用还是得继续用下去。（几年前迁移到 Hugo 时都说了 Hexo 再也不见了，难道还能删文自己打脸不成？\n\n### 让 Hugo 回归本质\n\n> “什么是 Hugo 的本质？”\n>\n> “内容生成和模板渲染。”\n\n因此本次重构我只使用 Hugo 生成文章的内容，不包含任何样式、脚本等，输出格式我选择了 JSON，包含渲染后文章的主体内容，还包含了文章的元信息以及下一篇、上一篇等额外字段。\n\n这些 JSON 文件，就是后续网站构建的内容核心。\n\n## 为什么重构？\n\n\n扯了这么久 Hugo 的缺点，其实本次的重构的缘由并不是我完全无法忍受这些缺点了，只是单纯想吐槽一下，又觉得为了吐槽单独写一篇文章有点没必要，于是就在这里写了。本次重构的主要原因是我想稍微系统地学一下前端目前的主流框架，并且利用现代的 Web 开发技术来提升一下博客的用户体验。\n\n我之前的博客就已经很注重用户体验了：CSS 和 JS 文件都只有一个，且 JS 还使用了 async defer 属性加载，完全不阻塞页面的渲染。不过虽然目前 CSS 和 JS 文件都只有一个，但是在页面切换浏览器重新渲染页面的时候，同样的 CSS 文件和 JS 文件都会再请求一次，对于用户来说，再次请求的 CSS 和 JS 文件其实没什么必要，因为它们俩每个页面都是一样的，不同的只是 HTML。因此本次重构的核心目的就是在切换页面时支持增量同步内容，而不用完整地重新渲染整个页面；同时在浏览器首次访问页面的时候，能够渲染出的是 HTML 内容，而不是要通过 JavaScript 来生成 DOM，虽然现在搜索引擎抓取时都支持了 JavaScript 的运行，但在 JavaScript 加载之前就能渲染出页面内容对用户的体验也会更好。\n\n接下来对框架的选择，我便会以支持增量同步内容 + 预渲染 HTML 的功能作为最重要的考量标准。\n\n## 框架的选择\n\n\n### SvelteKit\n\n因为我之前的博客就是使用的 Hugo + Svelte，Svelte 给我的开发体验还可以（比 Hugo 是要强不少的），因此本次重构我第一想法就是选择 SvelteKit，不过简单的尝试后我还是放弃了，相比于 Svelte 的模板语法我还是更喜欢 JSX。而之所以在两年半前迁移到 Hugo 时候选择和 Svelte 搭配使用，无非就是因为 Svelte 的性能以及打包后的脚本最小（因为没有 runtime）；这对当时以静态内容为主、动态内容为辅的博客来说无疑是更合适的。\n\n而现在我的重构目标则是要把博客变成以动态内容为主，这样的话选择 Svelte 的理由似乎不是那么充分了。\n\n### Gatsby\n\n我的[表情包网站](https://meme.itswincer.com/)正是基于的 Gatsby v2 写的，现在都迭代到 v5 了，可惜 Gatsby 的缺点是太重，依赖太多，而且不支持 pnpm。\n\n连 React 的官方文档都从 Gatsby 跑路到 Next.js 了，你还有什么理由用它呢？\n\n### Astro\n\n这个框架也是最近才冒出来的，我的个人主页在前段时间就用了这个框架重构，不过它只能当 SSG 来使用，不同页面的切换无法通过异步刷新来解决。因此还是放弃了。\n\n### Next.js\n\nNext.js 可以算是前端圈最大名鼎鼎的一个框架了，我简单使用了一会之后发现开发体验真的很顺畅：文档完善、社区繁荣、功能齐全，还有商业公司在背后支撑。而且 Next.js 还可以使用 getStaticProps 和 getStaticPaths 函数来可以生成纯静态的资源，不需要借助 Node.js 的运行时，似乎和我的 Hugo 方案完美契合。\n\n于是我就愉快地使用 Next.js 重构起了我的博客。\n\n## Next.js 的局限性\n\n你可能注意到了，如果 Next.js 真的这么美好，那么本文的标题就应该是「使用 Hugo + Next.js 重构博客」了。\n\n### getStaticProps\n\n一般来说，如果要使用 Next.js 的 SSG（Static Site Generator）模式，会在 getStaticPaths 函数返回所有静态页面，然后用 getStaticProps 来把静态页面的属性传递给组件。\n\n对应到我的博客上，getStaticPaths 需要返回所有博客的列表，然后 getStaticProps 会去找寻每一篇博客对应的 JSON 文件，读取内容并把它通过 props 传递给组件。我一开始就是按照这样的思路来写的，没遇到什么问题。可就在编译完成后，我发现生成的结果除了包含了渲染后的 HTML，居然包含了传入的 props 内容！这也就意味着我的文章信息在渲染后的 HTML 中存了两份。我一开始以为是我的使用方式有问题，后来我发现[React 官方文档](https://react.dev/learn)也有这个问题。\n\n这个问题其实让我有点膈应，因为它对于越长的文章，影响越大，尤其是我的博客放在 Cloudflare Pages 上运行，本来国内用户与 Cloudflare 之间的带宽就小，这样一来就更影响用户首次打开页面的体验了。\n\n好在这个问题其实是有解决方案的。那就是写一个 Webpack 的插件，来自定义解析 JSONX 格式的文件（注意这里不能使用 JSON 格式了，需要把 JSON 格式改一个后缀，不然会和 Webpack 默认的 JSON 解析器冲突），把文件读取后返回一个定义了 React 组件的字符串，Next.js 会直接以这个包含着组件定义的字符串来作为正常页面渲染。而且这么做有一个好处，就是自定义的组件也可以正常渲染。\n\n> 我为博客文章内部的图片都写了一个 LazyImg 的组件（图片出现在视窗里才加载）并通过 Hugo 的自定义渲染 Hook 来将 img 标签都替换成 LazyImg 的标签。如果是通过 dangerouslySetInnerHTML 来设置的话，LazyImg 组件的内容是不会被正常渲染的，只会当成纯文本来显示。\n\n这个问题得到了妥善的解决，这也是我在本次重构博客耗费最多时间的地方。\n\n### URL 路径不支持中文\n\n是的，Next.js 的 URL 是不支持中文的，不光不支持中文，所有的非 Ascii 字符都不支持。而且几年前有人提到了这个问题，但是官方一直没有修复。\n\n虽然通过 getStaticProps 是可以支持中文的，不过因为重复包含 props 的问题，我不是特别想用这个方式。不过也没有其他更好的解决方式，中文的标签几百个，改起来是在太费事了。\n\n于是，我只好针对文章目录，使用 Webpack 的自定义插件载入页面；针对标签和分类目录，还是通过 getStaticPaths 和 getStaticProps 来生成页面。虽然这样标签和分类目录会包含两份 props，不过好在这两种页面的内容都比较少：只包含文章的元信息的内容，这样影响到也不是很大——我是这样安慰自己的。\n\n问题基本得到了解决，以一种不完美的方式。\n\n### pages 内的文件夹不支持软链接\n\n这个问题其实还挺奇怪的，因为经过我的测试，其他支持 file-based 路由的框架遇到文件夹是软链接时，文件夹内的文件也都是可以正常被路由的。这个问题我懒得去研究了，索性直接在构建完成后，把 Hugo 输出的 posts 目录拷贝到了 routes 内。\n\n### 渲染性能\n\nNext.js 本身打包生成的 JavaScript 文件挺多的，而且挺大的，这其实是很影响渲染性能的。\n\n在我配置稍差一点的设备上运行 Lighthouse，使用 Next.js 重构后的移动页面性能评分是 85 分，其中 Total Blocking Time 是 300 ms，Largest Contentful Paint 是 3.4 s。\n\n老实说，看到这个结果我还挺失望的……我能做到的优化已经做得足够了：图片全都懒加载，React 的组件也都是懒加载，文章内容也都是静态 HTML、没有借助 JavaScript 渲染，我只能把这个锅甩给 Next.js 和 React 本身了。\n\n于是，我不得不忍痛放弃了 Next.js。\n\n\n## 终于还是 SolidStart\n\n那么，有没有一个框架写法上是接近于 JSX，但是打包的结果比 Next.js 更小、性能又更强的呢？\n\n其实还真有，而且还不只一个：\n\n1. 用 preact 来代替 react：preact 本身是一个轻量化的 react 替代品，对于 react v17 版本之前的 API 是完全兼容的，不过可惜 v18 版本的 renderToReadableStream 不兼容了。而 Next.js 13 版本正是基于 react v18 开发的，因此也不能直接用 preact 来代替 react 了。\n2. [wmr](https://github.com/preactjs/wmr) 和 [fresh](https://github.com/denoland/fresh)：这两个都是基于 preact 的框架，性能本身是比 react 强不少，也更为轻量化。不过我觉得 preact 标榜自己是 react 的轻量化替代，这样是走不远的，一开始就是靠着和 react 一样的 API 来吸引用户，现在还和 react 不兼容了，又能怎么吸引用户呢？\n3. [SolidStart](https://github.com/solidjs/solid-start)：基于 Solid.JS 的框架（我的个人主页是使用的 Astro + Solid.JS），还处于起步的阶段，我在深入使用中也发现了一些 bug，但是它的确是我能找到的最合适的 Next.js 替代品了：支持 JSX 语法，性能比 Svelte 更强，打包后的文件也足够小，支持增量刷新页面。\n\n于是，我就决定使用 SolidStart 了。之前提到，Next.js 是通过写一个 Webpack 的插件来自定义 JSONX 文件的解析渲染和渲染，SolidStart 自然也是支持的，写一个类似功能的 Vite 的插件即可。而且 Vite 打包的速度比 Webpack 快太多了。\n\n下面列一下我针对本次博客重构所做得一些优化和调整。\n\n## 深色模式调整\n\n这次我给深色模式加上了一个点击弹出的菜单项，不再是之前点击一下直接切换了：\n\n1. 浅色模式：此模式会永远保持浅色\n2. 深色模式：此模式会永远保持深色\n3. 跟随系统：此模式会跟随系统的模式来自动切换网站的模式\n\n为此，需要有两个状态来分别表示用户的选择以及网站的实际模式。为什么需要两个状态呢？因为用户的选择（userSelected）和网站的实际模式（theme）并不是完全对应的：用户选择跟随系统选项的时候，网站的模式是不固定的，可能是深色也可能是浅色。\n\n- userSelected 可能值为三个：light、dark 和 auto，会存放在 localStorage 中；\n- theme 的可能值为两个：light 和 dark，这个值也是直接和当前网站模式对应的。\n\n```tsx\nconst ThemeMenu = ({ show, toggleShow }: ThemeMenuProps) => {\n    const [selected, setSelected] = createSignal(isBrowser ? window.lt() : \"auto\")\n    const handleClick = (e: MouseEvent, key: string) => {\n        toggleShow(e)\n        setSelected(key)\n        let systemMode = key;\n        if (key === \"\")\n            systemMode = window.mt();\n        setGlobal({ theme: systemMode })\n        localStorage.setItem(\"customer-theme\", key)\n    };\n\n\n    onMount(() => {\n        window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', e => {\n            if (selected() !== 'auto') return\n            const newColorScheme = e.matches ? 'dark' : 'light';\n            setGlobal({ theme: newColorScheme })\n        })\n    })\n\n\t\t...\n}\n```\n\n梳理一下深色模式生效的流程：\n\n当用户初次进入网站或点击刷新的时候，首先会从 localStorage 中载入用户的选择，如果不是 auto，那么就直接把 html 标签的 class 设置成对应的值；如果是 auto，就用当前系统的模式。这部分的逻辑，是我单独抽出来的放在 head 标签里的，并没有和 JSX 组件放在一起：因为组件是在 DOM 加载完成后才渲染，如果这部分也放在组件逻辑中，那么页面可能会在组件渲染时出现闪烁的情况。\n\n等到 JSX 组件加载完成后，theme 相关的逻辑会首先执行，它会直接使用 html 的 className 来作为初始值。\n\n接着是切换模式按钮的渲染，这时 userSelected 会读取 localStorage 中的值，作为初始值。同时，在模式切换按钮的内部，我加上了一个 onMount 的函数，为系统的模式切换加上了一个 EventListener，当检测到系统模式发生改变且用户选择的是跟随系统时，会根据系统的模式来设置 theme 的值。\n\n最后，当用户点击了切换按钮的时候，userSelected 会直接修改成用户选项所对应的值，同时存入 localStorage；而 theme 会复杂一点，需要判断一下：\n\n1. 用户选择的是跟随系统：先获取系统的模式，然后设置成 theme；\n2. 用户选择的不是跟随系统：将用户的选择设置成 theme。\n\nuserSelected 我使用的是 createSignal 存放，毕竟生命周期只是在按钮组件里；而 theme 我使用了 createStore 存放，因为跨了多层，而且使用的地方是最外层的 HTML 标签，无法使用 ContextProvider 包裹了。\n\n## 加载状态的反馈\n\n切换成现有架构后我发现了在页面切换时存在的一个问题，当用户点击页面时，会有几百毫秒的停顿时间，这期间是在等待加载渲染新页面所需的资源，而在当前页面也没有任何变化，这会让用户怀疑是不是没有点击或者网络出问题了。对比传统的静态页面，点击 a 标签时，左上角的刷新图标和标签 tab 会转圈给用户反馈表示新页面正在加载。\n\n我首先考虑使用 Skeleton Screens，但是我发现它应用在全页面加载的时候会很怪，只适合在页面的部分区域加载时使用，于是我放弃了这个方案，转而使用了大部分的网站都用的顶部进度条来表示加载状态。顶部加载进度条其实就是两个状态，当页面切换的时候设置进度条开始，然后页面切换完成设置进度条结束；控制进度条结束比较简单，放在 onMount Hook 中即可。\n\n控制进度条的开始则稍微复杂一点：SolidStart 有两个 Hook 可以设置成进度条的开始：分别是 useIsRouting 和 useBeforeLeave，经过实验我发现 useIsRouting 有一个 bug（feature？），当点击的是同页面的锚点时，useIsRouting 也会被触发，而点击同页面的锚点并不会造成 onMount Hook 的重复执行，所以如果使用了 useIsRouting 那么在点击锚点就会导致进度条开始了但一直不结束。\n\n因此，我还是使用了 useBeforeLeave 这个 Hook 来设置成进度条的开始。不过 useBeforeLeave 也有一个 bug（feature？），虽然页面的锚点切换不会导致 useBeforeLeave 触发，但是页面的 SearchParams 的改变会导致 useBeforeLeave 的触发，我的博客在[搜索页面](/search/)会把搜索内容映射到 SearchParams 中，因此需要在 useBeforeLeave 中做一个判断：如果当前页面和目标页面的 pathname 一致，那么就不设置进度条开始：\n\n```tsx\nconst ContentLayout = (...) => {\n  \n    useBeforeLeave(e => {\n        if (!(e.to.toString().startsWith(e.from.pathname) && e.from.pathname !== \"/\")) nProgress.start()\n    })\n    onMount(() => {\n        nProgress.done()\n    })\n  \n  \t...\n};\n```\n\n这里还需要额外判断一下源页面不是首页，否则首页跳转到任何页面都不会有进度条开始。\n\n## 代码高亮调整\n\n之前有提到过，我的页面是由 Loader 读取 JSONX 文件并将其内容包含在组件定义中返回，这样做的好处之前已经说了，可以让自定义的组件也可以正常渲染。但是也有坏处：渲染内容必须是合法的 JSX 组件。Hugo 生成的内容自然是标准的 HTML 组件，可却不一定是合法的 JSX 组件。比如`<hr>`就是一个标准的 HTML 组件，但是它没有闭合，所以不能算是一个 JSX 组件，如果直接丢在组件定义中返回，那么页面渲染就会出错。\n\n当然，代码块中不存在未闭合组件的问题，却有`{}`的问题，在 JSX 组件中，花括号包含的内容会被认为是 JavaScript 表达式，而代码块中出现的大括号基本上是不可避免的。如果在 Hugo 的自定义 render-codeblock Hook 中对花括号进行转义，那么又会影响到 RSS 的输出。\n\n所以我只能放弃了 Hugo 提供的代码高亮，render-codeblock Hook 我是这么写：\n\n```go\n{{- $lang := .Attributes.lang | default .Type -}}\n<Pre lang=\"{{ $lang }}\"><code>{{ .Inner }}</code></Pre>\n```\n\nPre 大写是为了标识它是一个自定义组件。接着在自定义 Loader 里，解析 Hugo 生成的字符串，并通过设置 xmlMode，这样 cheerio 会把所有 HTML 标签转化成自闭合的，然后不断调用 hljs 去渲染，然后把 base64 编码后的值返回，这里如果不使用 base64 的话，花括号仍然会导致 JSX 渲染错误。\n\n```tsx\nimport { load } from \"cheerio\";\nimport hljs from \"highlight.js\";\nimport { encode } from \"js-base64\";\n\nconst renderHighlight = (content: string) => {\n    const $ = load(content, { xmlMode: true, decodeEntities: false });\n    $('Pre').each((index, element) => {\n        const lang = $(element).attr('lang')\n        if (!lang || lang.includes(\"$lang\")) return\n        const code = $(element).find(\"code\").html() || \"\"\n        const highlightedCode = hljs.highlight(code, { language: lang }).value\n        $(element).html(encode(highlightedCode))\n    })\n    return $.html()\n}\n\nexport default renderHighlight;\n```\n\nPre 组件就比较简单了，把传入的 children 用 base64 decode 一下然后塞到 innerHTML 中，确保以文本方式渲染就行了：\n\n```tsx\nimport { decode } from \"js-base64\"\n\nconst Pre = ({ children, lang }) => {\n    const code = decode(children)\n    return (\n        <pre class=\"relative\">\n            <code class=\"hljs rounded\" data-lang={lang} innerHTML={code} />\n        </pre>\n    )\n}\n\nexport default Pre\n```\n\n## 所有图片懒加载\n\n之前的博客因为担心懒加载的图片到 RSS 输出中就看不到了，所以文章内的图片没有做懒加载。本次本次重构中，我用了一种比较巧妙的方式让文章内的图片懒加载的同时，又可以能让 RSS 输出能正常看到图片。首先是 Hugo 定义的 render-image Hook：\n\n```go\n<Img src=\"{{ $dest | safeURL }}\" alt=\"{{ $text }}\" />\n```\n\n这里的 Img 同样是我定义的组件，我用它覆盖掉了原生的 img 组件，这是它的定义：\n\n```tsx\nimport { createEffect, createSignal } from \"solid-js\";\n\nconst LazyImg = ({ src, ...rest }) => {\n    const [visible, setVisible] = createSignal(false)\n    const SVGFallback = '...'\n    let self: HTMLImageElement;\n    createEffect(() => {\n        const observer = new IntersectionObserver(entries => {\n            if (entries[0].isIntersecting) {\n                setVisible(true)\n                observer.unobserve(entries[0].target)\n            }\n        })\n        observer.observe(self as HTMLImageElement)\n    })\n\n    return (\n        <img ref={self!} {...rest} src={visible() ? src : SVGFallback} />\n    )\n}\n\nexport default LazyImg;\n```\n\n初始情况下，图片展示的是 SVGFallback 的内容（是一个 1x1 像素的图片的 base64 编码），当组件出现在视窗内的时候，将 src 设置成真实的 URL。\n\n同时，因为我在 render-image Hook 中针对 Img 组件的写法和原生 img 组件的写法是一致的，只是名称大小写不同，所以它输出到 RSS 中的就是普通的 img 标签，能够被 RSS 阅读器展示。\n\n## 中文路由的支持\n\n之前提到，SolidStart 是一个刚起步的框架，因此存在一些小 bug，除了之前提到的 useIsRouting 外，还有不支持中文路由的问题。\n\n我很确定这个是一个 bug 而不是 feature，bug 的原因在于包含了非 Ascii 字符的文件路径与 URL 的路径存在一层 URL 编码的转换，而 SolidStart 没有做这一层转换。知道了原因，修复起来就很简单了，在路由前给路径参数返回的值 Encode 一下，在 build 阶段的时候，根据 URL 路径写入文件前，再将路径 Decode 一次，it works like a charm。\n\n> 我还就此问题给 SolidStart 提了一个 issue，不过他们还没回复我。\n\n题外话，我试了好几个 file-based 路由的框架，只有 Svelte 是对中文的路由支持的。其他的框架都有这个 URL 编码的问题，不过 Next.js 貌似并不是因为这个问题。\n\n## 其它的一些小调整\n\n以下是一些没那么重要的调整，放在一起说一下：\n\n### 推荐相关文章\n\n在本次重构中，我还在文章页面的侧栏新增了一个区域，用于列出与当前文章相关的其他文章。相关度是根据文章标签计算的，如果找不到同标签的其它文章，那么就展示同分类的其它文章。\n\n### 移动端的目录展示\n\n之前移动端在文章页面是不展示侧边栏的，不过现在我感觉随着我的文章越写越长，为了移动端的阅读体验还是加上一个目录展示更合适一些。现在移动端文章页面会在右下角展示一个目录的按钮，点击就会弹出目录。\n\n### 搜索页面\n\n搜索页面现在会把用户的输入映射到 URL 中的 SearchParams 上面，反过来 SearchParams 中的输入也会映射到搜索框中。\n\n## 尾声\n\n> 本文算是我目前写的最长的一篇文章了，写长文的感觉还挺好的，能够把自己对一个项目完整地思考展现出来，写文的过程自己也能重新梳理自己的思路。\n\n本次重构博客耗费的时间与精力远远超过了我的预估。我一开始预估也就一周内就可以完成，毕竟样式什么的都不用调整，直接复用就行了，没想到居然耗费了我将近一个月的时间，看来项目实际的开发时间起码是预估开发时间 x3，只多不少。\n\n虽然过程稍微长了点，不过这次重构我也学到了不少东西，我挺满意的。"},{"title":"OpenCore 引导安装 macOS Ventura 教程","subtitle":"从零开始安装黑苹果记录","url":"/posts/open-core-boot-macos-ventura-tutorial/","date":"2023-04-05T03:51:31.000Z","updated":"2023-04-05T03:51:31.000Z","category":"分享境","tags":["黑苹果","OpenCore","Hackintosh","Ventura"],"content":"几年前，我专门组过一台电脑折腾黑苹果与 Windows 双系统，之后便一直稳定用到现在（没有手贱乱升级）。最近发现硬盘已经快占满了，500G 的空间还要分一半给 Windows 用，也真是难为它了。正赶上固态价格大幅跳水，于是我买了一块 2T 的固态来升级硬件配置，正好心里也想顺便升级一下软件来体验最新版的 macOS Ventura，是以写下这篇文章作为记录。\n\n<!--more-->\n\n我的黑苹果配置见[之前的文章](/posts/7a2a84c6/#%E9%85%8D%E7%BD%AE%E5%8D%95)，只有固态更新成了梵想 2T PCIe 4.0。\n\n## 准备工作\n\n\n### BIOS 配置\n\n\n请按照 [OpenCore 官方教程](https://dortania.github.io/OpenCore-Install-Guide/config.plist/coffee-lake.html#intel-bios-settings)推荐的设置来更新你的 BIOS，如果 BIOS 缺失上述某项，可以忽略。比如我的主板就缺失 CFG Lock 这一项，不过使用下来也没有遇到什么问题。\n\n### 下载 macOS 镜像\n\n这一步可以直接从 App Store 下载最新版操作系统，比如我这里需要安装 Ventura 就直接打开搜索 macOS Ventura 即可。\n\n> 如果你手头没有 macOS 设备，可以参考 OpenCore 官方文档：[如何使用 Windows 来刻录启动盘](https://dortania.github.io/OpenCore-Install-Guide/installer-guide/windows-install.html)。\n\n不过有的驱动或者补丁与最新版系统可能会有兼容性问题，因此可以选择下载稍微早一点的系统。不过早一点的系统就不能从 App Store 下载来，只能用其他方式了，在终端运行：\n\n```bash\n>>> softwareupdate --list-full-installers\nFinding available software\nSoftware Update found the following full installers:\n* Title: macOS Ventura, Version: 13.3, Size: 11776013236K\n* Title: macOS Ventura, Version: 13.2.1, Size: 12555992911K\n* Title: macOS Ventura, Version: 13.2, Size: 12555703258K\n.\n```\n\n这里会列出所有可下载的macOS 版本，如果你不想使用 Ventura，可以选择 Monterey 或者 BigSur。\n\n选定版本之后，比如我这里选择的是 13.1：\n\n```bash\nsoftwareupdate --fetch-full-installer --full-installer-version 13.1\n```\n\n\n命令执行完成之后，应用程序的文件夹里就能看到 Install macOS Ventura 安装程序了。\n\n### 刻录启动盘\n\n\n插入 U 盘，打开磁盘工具，定位到 U 盘的物理磁盘（而不是宗卷）选择抹除：名称随便设置（我设置的是 Ventura），一会刻录的时候安装程序会重新命名。格式必须选择 macOS 扩展格式（日志），方案选择 GUID 分区图。\n> 注意，如果这里的抹除弹窗中没有出现分区方案的选择，请在磁盘工具顶部的 `显示` 菜单栏中选择显示所有设备。因为如果没有分区方案的选择，证明你格式化的是分区而不是整块设备！\n\n\n随后将刚下载的操作系统刻录到此 U 盘中：\n\n```bash\nsudo /Applications/Install\\ macOS\\ Ventura.app/Contents/Resources/createinstallmedia --volume /Volumes/Ventura\n```\n\n\n这条命令有两个需要根据具体情况修改的地方：\n\n\n1. 如果你这里不是安装的 Ventura 版本，请将路径名称替换成你安装的版本；\n2. volume 参数是你刚刚抹掉的磁盘是设置的名字\n\n这个过程会比用其他软件的刻录镜像慢一些，耐心等待完成。\n\n刻录完成后，我们正式开始进行 OpenCore 相关的配置。\n\n## 挂载 EFI 分区\n\n\n我们接下来的所有动作都是在 U 盘的 EFI 分区上进行，目的就是为了让刚刚刻录的系统能正确地从 EFI 分区引导。\n\n使用 diskutil 命令来查看 EFI 分区和挂载，如果你觉得太麻烦，可以试下 [MountEFI](https://github.com/corpnewt/MountEFI) 这个更方便一点的方案：\n\n```bash\n  #######################################################\n #                      MountEFI                       #\n#######################################################\n\n1. EFI                   | 209.7 MB | EFI                         | disk0s1\n2. Core                  | 249.3 GB | Microsoft basic data        | disk0s3\n3. macOS                 |   250 GB | APFS                        | disk1s5s1\n4. Install macOS Ventura |  15.8 GB | Mac OS Extended (Journaled) | disk2s1\n5. Shared Support        |  12.2 GB | Apple HFS+                  | disk3s2\n\nS. Switch to Full Output\nB. Mount the Boot Drive's EFI\nL. Show diskutil list Output\n\nD. Pick Default Disk (None Set)\nM. After Mounting: None\nR. Toggle Window Resizing (Currently Enabled)\nQ. Quit\n\nPick the drive containing your EFI:  4\n```\n\n\n我这里选择 4，代表刚刚刻录了 macOS 的 U 盘，可以看到 U 盘名字被安装程序自动更改成了 Install macOS Ventura。随后打开 Finde 就能看到 EFI 分区被挂载上了。\n\n然后下载 OpenCore 的[最新版](https://github.com/acidanthera/OpenCorePkg/releases/)，建议下载 DEBUG 版本。解压后，进入 X64 文件夹，然后把文件夹中的 EFI 目录，整个拷贝到刚刚挂载 EFI 分区内，注意这里的目录结构：EFI 分区里存在 EFI 目录：\n\n```bash\n>>> pwd                          \n/Volumes/EFI\n>>> tree -L 3\n.\n└── EFI\n    ├── BOOT\n    │   └── BOOTx64.efi\n    └── OC\n        ├── ACPI\n        ├── Drivers\n        ├── Kexts\n        ├── OpenCore.efi\n        ├── Resources\n        └── Tools\n\n9 directories, 2 files\n```\n\n\n虽然 EFI 分区已经建立，但是还有许多东西需要针对我们自己的情况作出调整。\n\n## Drivers 相关\n\n\n打开 EFI/OC/Drives 目录，可以看到 OpenCore 自带了很多 .efi 文件，这些大部分对于黑苹果友好的硬件都是多余的，只需要两个 .efi 文件就行；\n\n\n1. HfsPlus.efi：从[这里下载](https://github.com/acidanthera/OcBinaryData/blob/master/Drivers/HfsPlus.efi)，可以从 HFS+ 格式的宗卷引导操作系统启动。这里的 HFS+ 格式也就是我们的刻录 U 盘时选择的 macOS 扩展格式。\n2. OpenRuntime.efi：OpenCore 自带，看名字就知道很重要，主要是对 boot.efi 的补丁，修补 NVRAM 和内存管理。\n\n其他的都删掉。\n\n### Kexts 相关\n\n\nOpenCore 的 kexts 文件夹（ EFI/OC/Drives）是空的，需要自己添加以下这些：\n\n\n1. [Lilu](https://github.com/acidanthera/Lilu)：这应该是黑苹果最重要的内核驱动了，很多其他的 patch 或者 Kext 都依赖于它\n2. [SMC 相关](https://github.com/acidanthera/VirtualSMC/releases)：可以虚拟出一块 SMC 芯片，启动系统时需要，它自带了很多扩展，只需要用到其中几个就行：\n\t1. VirtualSMC.kext\n\t2. SMCProcessor.kext\n\t3. SMCSuperIO.kext\n3. ~~[显卡相关](https://github.com/aluveitie/RadeonSensor)：OpenCore 官方称可以用来获取 Raedon 系显卡温度，不过我的 Vega56 没有用也可以显示温度：~~\n\t1. ~~RadeonSensor.kext~~\n\t2. ~~SMCRadeonGPU.kext~~\n4. [WhateverGreen](https://github.com/acidanthera/WhateverGreen/releases)：显示 Kext\n5. [AppleALC](https://github.com/acidanthera/AppleALC)：音频 Kext\n6. [IntelMausi](https://github.com/acidanthera/IntelMausi)：网卡 Kext\n7. USBPorts：我根据 OpenCore 最新的官方教程发现他们推荐使用 USBToolBox 这个工具来定制接口，但是我几年前用 Hackintool 定制的 USBPorts 也是仍然可用的，就没有再使用 USBToolBox 折腾了，如果没有可用的 USBPorts，需要自己定制的话，可以参考我文末的国光黑苹果教程。\n\n### 无线网卡 Kexts\n\n\n我在几年前安装黑苹果的时候没有配置无线网卡相关的 Kexts，因为当时 Intel 的网卡没办法在macOS 上驱动，现在发现居然有大佬移植了 Intel 网卡的驱动（终于不用去买不知道转了多少手性能还差的拆机网卡了）。这种造福大家的 kexts 值得单独列一下：\n\n\n1. AirportItlwm：这个是用来驱动 Wi-Fi 的，从[这里下载](https://github.com/OpenIntelWireless/itlwm)；\n2. IntelBTPatcher、IntelBluetoothFirmware：这两个是用来驱动蓝牙的，在[这里下载](https://github.com/OpenIntelWireless/IntelBluetoothFirmware)；\n3. BlueToolFixup：这个需要搭配前两个一起使用，在[这里下载](https://BlueToolFixup.kext)。\n\n## ACPI 相关\n\n\n很多 OpenCore 的初接触者对 ACPI、SSDT、DSDT 等名词不太了解，简单来说：\n\n\n- ACPI 是一套开放接口标准，为操作系统提供电源管理和硬件设备配置的一致接口；\n- DSDT 是这个接口标准的一部分，描述了计算机基础硬件设备的配置以及电源管理等设定；\n- SSDT 也是这个接口标准的一部分，会比 DSDT 更加细致地补充或者修改 DSDT 中的描述设定。\n\n在我们日常使用的 Windows，其实也是遵循 ACPI 标准的，在 Windows 安装的过程中，会自动向 BIOS 请求获取 ACPI 文件并加载。而因为黑苹果是在非苹果硬件设备下运行，BIOS 并不会向苹果的安装程序提供 ACPI 文件，因此需要自己手动来提取并在引导时加载。\n\n对于我的硬件配置来说， EFI/OC/ACPI 中需要至少两个 SSDT 文件：\n\n\n1. SSDT-PLUG：给 macOS 操作系统内核提供电源管理\n2. SSDT-PMC：给 macOS 提供 NVRAM 支持\n\n虽然 OpenCore 官方文档声称还需要 SSDT-AWAC（使用主板上的实时时钟）、SSDT-EC/USBX （虚拟嵌入控制器），不过我觉得这两个影响不大，加上我的 Windows 系统也是用的 OpenCore 引导，所以就没有加载这两个文件。\n\n## Tools 文件夹\n\n\n保留 OpenShell.efi 就行，在 OpenCore 引导菜单中添加命令行选项，在出现问题时调试能方便点（不过我从来没用过）。\n\n## Resources 文件夹\n\n\nOpenCore 图形化引导界面所需要的资源，如果你想以命令行方式引导，那就没啥用。\n\n## 整合 config.plist\n\n\n刚刚我们做的所有修改，都需要在 config.plist 文件中体现，它相当于启动引导的入口文件。\n\n把 OpenCore 仓库里Docs文件夹下面的 Sample.plist 拷贝一份到 EFI 分区的 EFI/OC 文件夹并重命名为 config.plist。\n\n用 [ProperTree](https://github.com/corpnewt/ProperTree) 加载这个 config.plist 文件，然后按 Cmd/Ctrl + Shift + R（OC Clean Snapshot），在弹窗选择 OC 文件夹，会自动把 ACPI 目录的文件以及 kexts 目录的文件在 config.plist 里对应位置填充好。\n\n此外，针对我的 9700KF CPU（Coffee Lake），还需要修改如下项，如果你是其他的 CPU，请参考[这个文档](https://dortania.github.io/OpenCore-Install-Guide/config.plist/#intel-desktop)：\n\n### Booter\n\n\nQuirks 子项中：\n\n\n- DevirtualiseMmio：改为 true\n- EnableWriteUnprotector：改为 false\n- ProtectUefiServices：改为 true\n- RebuildAppleMemoryMap：改为 true\n- SyncRuntimePermissions: 改为 true\n\n### DeviceProperties\n\n\nAdd 子项：\n\n如果你的 CPU有 iGPU，也就是 CPU 带有内置的 GPU 芯片，需要在 Add 子项中添加 PciRoot(0x0)/Pci(0x2,0x0) 子项，具体添加内容可以[参考这里](https://dortania.github.io/OpenCore-Install-Guide/config.plist/coffee-lake.html#add-2)。\n\n我的 9700KF 处理器不带 iGPU，所以这部分保持不变只需要有 PciRoot(0x0)/Pci(0x1b,0x0) 子项（默认）即可。\n\n```bash\nPciRoot(0x0)/Pci(0x2,0x0)\n\tAAPL,ig-platform-id\n```\n\n\n### Kernel\n\n\nQuirks 子项中：\n\n\n- AppleXcpmCfgLock：改为 true\n- AppleCpuPmCfgLock：改为 true\n- DisableIoMapper：改为 true\n- PanicNoKextDump：改为 true\n- PowerTimeoutKernelPanic：改为 true\n- XhciPortLimit：改为 false，使用 USBToolBox 或者 USBPorts的方式来解决 USB 问题\n\n### Misc\n\n\nBoot 子项中：\n\n\n- HideAuxiliary：改为 false，可以显示其他的启动项，比如恢复模式、ResetNVRAM 等\n- PickerMode：我不想用图形界面，所以保持 builtin\n\nDebug 子项中：\n\n\n- AppleDebug：改为 true\n- ApplePanic：改为 true\n- Target：改为 6\n\nSecurity 子项中：\n\n\n- ScanPolicy：改为0，\n- Vault：改成 Optional\n\n### NVRAM\n\n\nAdd - 7C436110-AB2A-4BBB-A880-FE41995C9F82 子项：\n\n\n- boot-args：改为 -v keepsyms=1 debug=0x100 alcid=1，[参数的释义](https://dortania.github.io/OpenCore-Install-Guide/config.plist/coffee-lake.html#nvram)\n- prev-lang:kbd：改为空\n\n### PlatformInfo\n\n\n修改 MLB、SystemProductName、SystemSerialNumber、SystemUUID 这四项，可以用[这个工具](https://github.com/corpnewt/GenSMBIOS)来生成。\n\n### UEFI\n\n\nDrivers 子项中：\n\n分别添加 HfsPlus.efi 和 OpenRuntime.efi。\n\n## 调试\n\n\n无论是升级黑苹果还是首次安装，重做 EFI 都是一件麻烦事，难免会犯一些错误。我们需要开启一些调试的功能，能更好地帮助我们解决问题。\n\n\n1. 使用 DEBUG 版本的 OpenCore，虽然启动会比 RELEASE 版本的慢不少，不过附带的调试信息更多，在调试完成后，再切换成 RELEASE 版本即可；\n2. 在 boot-args 参数中，加上 -v 参数，会显示启动时具体的执行步骤，而不是一个 Logo + 进度条；\n3. Debug - Target 改为 67\n\n### 验证\n\n\n在根据我们的具体需求修改完 config.plist 之后，如果直接重启大概率是无法引导的，我们可以用工具来验证一下。进入下载的 OpenCore 源码的 Utilities/ocvalidate 文件夹，我们使用它来验证我们的 config.plist 是否是正确的：\n\n```bash\n>>> ./ocvalidate /Volumes/EFI/EFI/OC/config.plist\n```\n\n\n然后按照给出的错误信息进行修改即可。\n\n## 更新 macOS\n\n\n后续如果想要通过自带的软件更新来安装新版的 macOS，请一定一定要先更新 EFI 分区的内容：\n\n\n1. 下载新版本的 OpenCore Debug 版，替换这三个文件：\n\t1. EFI/BOOT/BOOTx64.efi\n\t2. EFI/OC/OpenCore.efi\n\t3. EFI/OC/Drivers/OpenRuntime.efi\n2. 用工具（可以使用 diff 或者 [OCConfigCompare](https://github.com/corpnewt/OCConfigCompare)）来查看新版 OpenCore 的 config.plist 文件与当前使用的文件的区别；如果版本比较接近的话，你可以直接查阅 [Differences.pdf](https://github.com/acidanthera/OpenCorePkg/blob/master/Docs/Differences/Differences.pdf) 来查看更改，确保我们的 config.plist 文件结构与官方的文件结构一致（补全缺失的 key）；\n3. 更新一下你使用的 kexts 以及 .efi 文件，确保和 OpenCore 不会出现兼容问题；\n4. 开启调试信息，并使用 ocvalidate 来验证配置文件是否有问题。\n\n不要担心 OpenCore 更新后，会不兼容旧的 macOS 引导，OpenCore 团队会做好向后兼容的。当你使用新版的 OpenCore 以及 kexts 也能正确引导当前的 macOS 系统之后，就可以开始使用系统自带的软件更新来升级了。\n\n## Windows 11 双系统\n\n\n虽然我在[之前的文章](/posts/7a2a84c6/#acpi-%E7%9B%B8%E5%85%B3)里已经比较详细地介绍过双系统，不过这次可能是因为升级的原因，操作起来的步骤略有不同。不过大体的操作逻辑是一样的。\n\n### 制作 Windows 11 镜像\n\n\nmacOS 下，确实没有一个像 Rufus 一样好用工具来制作镜像，像 Etcher 这种工具是无法用来制作 Windows 11 的安装镜像的。\n\n[这篇教程](https://www.freecodecamp.org/chinese/news/how-make-a-windows-10-usb-using-your-mac-build-a-bootable-iso-from-your-macs-terminal/)提供了一个比较好的方法。总结下就是：给 U 盘格式化成 MS-DOS（FAT）格式带 GUID 分区表，然后把 Windows 11 镜像的 sources/install.wim 这个超大的文件用工具切割成两个小一点的文件，不然就超过了 FAT 最大文件 4G 的限制。\n\n### 启动转换助理\n\n\n打开启动转换助理，接下来选择镜像以及配置 Windows 分区大小（如果你插着 U 盘，可能会提示让你拔掉，暂时拔掉即可），在等安装完成后会重启电脑，目前 Windows 11 的镜像没有自带可引导的分区，所以重启电脑后会发现找不到 Windows 的安装入口，这时选择进入 macOS 系统，如果这里出现了 Windows 安装分区，也不要进入！\n\n再次打开启动转换助理，在左上角菜单操作菜单 -> 下载 Windows 支持软件，保存在 U 盘中。\n\n### 分区 & 安装\n\n\n打开 macOS 的磁盘工具，给现有的磁盘分出一块分区来，分区格式随便选，反正一会 Windows 安装的时候要把分区重建。如果上一步骤你已经通过启动转换助理做了分区，这里的分区步骤可以跳过。\n\n分区完成后，重启电脑，关键的步骤来了：**按 F12 进入 BIOS 的启动引导项，然后选择 U 盘**，注意这里不要通过 OpenCore 的引导项选择 U 盘然后进入安装界面。\n\n如果直接通过 OpenCore 的引导项选择 U 盘进入的安装界面，大概率会安装失败，原因猜测是 Windows 安装的时候从 BIOS 拿到的 ACPI 文件与 OpenCore 本身加载的 ACPI 文件冲突了。\n\n> 为什么我会这么猜测呢，因为很明显从 OpenCore 进入 Windows 安装界面的话，分辨率是 4K 的，而如果从 BIOS 进入 Windows 安装界面的话，分辨率模糊的一塌糊涂。\n\nWindows 11 的安装程序需要添加 BypassTPMCheck 和 BypassSecureBootCheck 这两项注册表才能运行，如果你有 Windows 设备的话，可以用 Rufus 来刻录 Windows 11 的镜像，他会自动帮你跳过这两个检测。随后在选择安装位置的时候，定位到刚刚的那块硬盘分区，把它删除掉，分区会显示成未分配，选择安装 Windows 到此分区即可。\n\n### Windows 支持软件\n\n\n在 Windows 安装程序拷贝文件完成之后，会自动重启，并修改 BIOS 的启动项顺序，把 Windows 的启动引导放在第一位，所以这里会继续进入到 Windows 的安装界面（伴随着模糊的分辨率），等待安装完成后，这时不要急着装驱动，也不要运行我们的 Windows 支持软件，直接运行的话会失败。\n> 这里同样还是因为 ACPI 的原因，因为我们直接通过 Windows 启动引导进入的系统，没有使用 OpenCore 中的 ACPI 文件，而 Windows 支持程序会检测当前操作系统是否使用的苹果的 ACPI 文件启动。\n\n\n设置完成后会再次重启，这时可以进入 BIOS，调整一下启动项顺序，把 Windows 的启动项放在后面（或者直接禁用了），OpenCore 的放在第一位。然后重启就会进入到 OpenCore 的引导菜单了，这时就可以看到 Windows 的菜单项了，选择 Windows，然后进入系统后，打开 U 盘下载的 Windows 支持软件，进入到 BootCamp 文件夹，点击 Setup.exe 安装。\n\n完成后，双系统就成功了，可以从 Windows 启动到 macOS，也可以从 macOS 启动到 Windows 而不需要在引导菜单的时候手动选择。\n\n当然。开启了 NVRAM 的支持是前提。\n\n## 注意事项\n\n\n### 备份\n\n\n所有 OpenCore 的配置完成后，苹果系统已能正常工作时，一定要把你的 EFI 分区备份一下。另外可以再准备一个 U 盘，格式化成什么格式无所谓，只需要带有 GUID 分区表即可，然后将目前黑苹果的 EFI 分区给备份到 U 盘上的 EFI 分区。\n\n这样万一引导分区出现什么问题导致无法启动，重启电脑按 F12 从引导菜单选择 U 盘（这里需要从 BIOS 引导菜单选择 U 盘，而不是从 OpenCore 引导菜单选择 U 盘）也能进入系统及时修复。\n\n### 引导丢失\n\n> 如果你只是用 OpenCore 来安装黑苹果，不用来引导多个系统的话，一般不会出现引导丢失的情况。\n\n\n引导的丢失分两种，一种是 EFI 分区被覆盖或者不小心删除了，另一种是 EFI 分区没变，但是引导项没了。这里只讨论第二种情况（第一种情况自己做好备份即可）。\n\n我遇到过两种情况，出现了 EFI 分区没有变化，但是引导项被改了的情况：\n\n\n1. Windows 进行了一个大版本的更新，出现了引导菜单第一顺序被设置回了 Windows Boot Manager，也就导致了开机之后不经 OpenCore 的引导直接进入了 Windows，这种情况比较好处理，去 BIOS 里调整一下引导顺序就可；\n2. 重设了 NVRAM，会导致 OpenCore 引导项被删除，只留下了 Windows Boot Manager，这种情况稍微复杂一点，BIOS 里看引导菜单也没有 OpenCore 存在了；\n\n第二种情况需要进入 Windows 后，下载 EasyUEFI 或者 DiskGenius 重新给 EFI 分区的 boot 分区下的 bootx64.efi 添加回来。DiskGenius 可以[参考这个教程](https://www.diskgenius.cn/exp/manage-UEFI-boot-option.php)。\n\n### Reset NVRAM\n\n\nOpenCore 新版里需要在 OC/Drivers 文件夹中保留 ResetNvramEntry.efi 文件并在 config.plist 中加载，在 OpenCore 引导菜单中才会出现这个选项。\n\n### 最简原则\n\n\nOpenCore 的配置请一切从简：从零开始慢慢加，而不要从网上找了个同样配置的成品，开始在上面一点点调整。\n\n\n1. 如果你不知道某 kext 或者 SSDT 的作用，那么就不要把它加载到启动项里；\n2. 如果你的系统已经运行正常，就不要再把一些声称可以修复 xx 功能的补丁加载进来。\n\n比如我就没有使用 OpenCore 官方推荐的 USBX 和 AWAC 等 SSDT，只保留了 PLUG 和 PMC 这两个；USB 定制的 kext 也一直用的是几年前就定制好的，没有在用 USBToolBox 来重新定制；以及虽然我用的 Radeon Vega56 显卡，但是我发现没有 SMCRadeonGPU 等 kext 也是可以正常显示 GPU 温度，因此我也没有加载这个。\n\n## 成果\n\n\n其实在本次更新 Ventura 之前，我的黑苹果就已经工作的比较完美了，除了无线网卡没有驱动外，其他的比如睡眠、NVRAM、USB 等功能都正常工作，这次有了大佬移植的驱动，蓝牙，Wi-Fi，隔空投送与接力，剪贴板等全都正常工作：\n\n![image](https://cdn.blog.itswincer.net/img/handoff-working.png)\n\n唯一可惜的是，iMessage 和 FaceTime 无法登陆。\n\n## 总结\n\n\n写这篇文章的一个目的就是为了方便后续自己的查阅，避免以后每次安装黑苹果都要重新搜一下怎么动手（因为我这次就是这样又在网上搜了一圈），写了这篇文章后，自己要是遇到重装或者更新的时候也有个参考。\n\n参考：\n\n\n- [OpenCore Install Guide](https://dortania.github.io/OpenCore-Install-Guide/ktext.html#ssdts)\n- [如何使用 Mac 制作 Windows 10 U 盘启动盘](https://www.freecodecamp.org/chinese/news/how-make-a-windows-10-usb-using-your-mac-build-a-bootable-iso-from-your-macs-terminal/)\n- [国光的黑苹果安装教程](https://apple.sqlsec.com/6-%E5%AE%9E%E7%94%A8%E5%A7%BF%E5%8A%BF/6-1.html)\n- [FAQ | OpenIntelWireless](https://openintelwireless.github.io/IntelBluetoothFirmware/FAQ.html#what-additional-steps-should-i-do-to-make-bluetooth-work-on-macos-monterey-and-newer)"},{"title":"ChatGPT 与 TTS 之间奇妙的反应","subtitle":"一种很新的智能语音助手","url":"/posts/chatgpt-and-tts-work-together/","date":"2023-03-14T15:35:09.000Z","updated":"2023-03-14T15:35:09.000Z","category":"实验室","tags":["ChatGPT","TTS","语音助手"],"content":"其实早在去年底 ChatGPT 刚发布的时候，我就申请到了账号，不过当时的用户体验并不算好：ChatGPT 在说大段话的时候会突然断掉，然后还经常会出现请求量过多导致服务拒绝的情况，所以也就开始尝试了几天，新鲜感满足后就搁在一旁了。\n\n谁知过了两个月之后，ChatGPT 在国内的概念突然又被炒了起来，它的更多用法也被挖掘了出来，同时它本身的用户体验也提升了不少：不会再出现大段话突然断掉的情况；拒绝服务的情况也越来越少了；还支持了历史对话等。于是这时候我开始在有意识地使用 ChatGPT 来处理一些日常的事物了：比如写 PPT、常识性的知识问答，以及重构代码等。虽然在重构代码这一块，错误还是不少，但也确实会给予我一些灵感。\n\n当时就有一个想法，ChatGPT 什么都好，就是只有一点不好，只能通过打字交流（~~咳咳，要是能通过语音交流的话，面试啥的岂不是都可以用上了？~~）。可惜 ChatGPT 一直没有公开 API，想使用的话估计只能用无头浏览器来模拟了，不过这样一来还要破解 Cloudflare 的人机验证，工作量太大了…\n\n终于，在三月的时候 OpenAI 发布了 ChatGPT 的 API 以及对应的语音转文字模型 Whisper 的 API，之前想与 ChatGPT 语音交流实现起来应该没多大难度了，不过我这人有点懒，还是缺一个契机或者动力来做这个事。直到前几天的时候，女朋友转给我她的一个学长在朋友圈发布的视频，视频内容正是通过语音与 ChatGPT 进行对话，她觉得很有趣，问我能不能给她做一个，我想这正巧和我的想法不谋而合，于是乎，我就开始研究了这件事起来。\n\n<!--more-->\n\n## 模块拆分\n\n\n很显然，要通过语音与 ChatGPT 对话，整体的功能可以分成 3 个模块完成，分别是：\n\n\n1. 语音识别模块：这部分将用户的语音转化成对应的文字，也即是 ChatGPT 的输入；\n2. ChatGPT 模块：这部分就是把文字发送给 ChatGPT，然后把ChatGPT 的回答保存下来；\n3. 语音合成模块：这部分就是把 ChatGPT 的回答转化成语音，然后播放。\n\n以下是设计图：\n\n![image](https://cdn.blog.itswincer.net/img/chatgpt-tts-infras.png)\n\n下面我会分别阐述一下这三个模块的设计与实现。\n\n## 语音识别模块\n\n\n这个模块是我耗费时间最久的，我一开始并没有打算使用 Whisper API（~~白嫖惯了的人，总是想找个免费的~~），而是打算使用离线的方案，主要是考虑到用这种 API 会涉及到网络层面的开销，拖慢语音识别的速度，用户的体验也会相应地打折扣。\n\n我相继尝试了 [PocketSphinx](https://github.com/cmusphinx/pocketsphinx) 和 [DeepSpeech](https://github.com/mozilla/DeepSpeech) 这两个离线的语音识别方案，可效果都不太理想。PocketSphinx 的准确率实在差劲，DeepSpeech 的准确率倒是还可以，就是识别的速度太慢了，而且离线的方案还需要我自己来维护一套训练模型，我这半吊子的机器学习水平，实在懒得维护这些模型。\n\n于是兜兜转转我还是回到了找云服务商提供的语音识别方案上，找了半天，终于找到了一款 Python 的开源库 [SpeechRecognition](https://github.com/Uberi/speech_recognition)，虽然是个开源库，但它本身集成了市面上大部分服务商提供的语音识别方案，虽然大部分都是付费的（需要你自己去服务商购买然后输入 API KEY），但好在还是有 Google 家的方案还可以免费使用。\n\n于是语音识别模块我基本上都是封装了 SpeechRecognition 这个库的一些操作，等后续如果发现有什么用得不爽的地方我再来自己定制。\n\n## ChatGPT\n\n\n这个模块是最短时间完成的，也没啥好说的，直接调用 OpenAI 的 API 即可，不过我稍微研究了下 API 的参数，相比较默认的 API 进行了两个调整：\n\n\n1. temperature：按 OpenAI 的说法，较低的值会让回答更加稳定，比如用同样的语句问，temperature 越大，回答的答案也可能越会不同；\n2. messages：对于 messages 我更细化地进行了 2 个调整：\n\t1. 在所有会话的前面都加上 role=system 的指令，这一目的是让ChatGPT 的每一次回答都遵循 system 的指令，我目前设置的指令是：「Answer in concise language」，也就是用简洁的语言回答，如果不加这个指令，稍微长一点的话题就会反复说一些废话，这不利于对话的展开。这个指令在配置文件里是可更改的；\n\t2. 默认保留最近 3 次对话内容，ChatGPT API 默认并不会关联上下文的会话，这是与 Web 端最大的区别，如果想要关联上下文，那就只能把之前的会话内容一起发送，如果不限制一下保存的会话次数，那么越往后面消耗的 Token 就越恐怖；\n\n我目前的调教方法是，普通聊天就保持默认配置不动；如果想要进行特殊的会话，比如让它当百科全书来回答问题，那么会话保留的条数可以更短，system 指令可以设置成：「尽可能详尽地回答」；如果想要练习英文口语，那么可以设置 system 指令为：「Play a English teacher, Point out grammatical errors and ask questions according to the context」；如果想要模拟面试，那么可以设置 system 指令为：「扮演一名 xx 岗位的面试官进行面试，简洁地回答和提问」。\n\n## 语音合成模块\n\n\n这个模块也颇费了我一番功夫，一开始我也是想找离线的方案，同样也是因为想节省一些网络的开销，让对话进行地更顺畅。我也找到了对应的离线方案：[pyttsx3](https://github.com/nateshmbhat/pyttsx3)，这个方案是调用操作系统本身的 TTS 引擎来朗读：Windows 是 SAPI5，MacOS 是 NSSpeechSynthesizer，其他平台使用 eSpeak。\n\n这个方案虽然免费、省事，但是 pyttsx3 这个库有一个很严重的 bug：它不支持多线程，它如果放在非主线程之外运行，Speak 的时候不能阻塞住，五年前就有人在 Github 提了[这个 Bug](https://github.com/nateshmbhat/pyttsx3/issues/8)，反正目前是还没有解决。\n\n因此我不得已只能放弃了这个离线方案，转而白嫖起了 Azure 和 Google 的 API）——分别是由 [edge-tts](https://github.com/rany2/edge-tts) 和 [gTTS](https://github.com/pndurette/gTTS) 开源库提供。\n\n另外值得一提的是，我优化了语音合成播放的流程，将 ChatGPT 的交互模块与语音合成模块解耦成两个线程，之间用队列通信。如果是线性地执行，等 ChatGPT 的回答完全返回之后再进行朗读的话，在 ChatGPT 回答比较长的时候等待的时间太久了，因此每当 ChatGPT 的一句话说完的时候，就先把这一句话的内容发送到队列中，同时语音合成的模块会不断地从队列取数据开始朗读。\n\n这样，用户体验会好不少。\n\n## 链接\n\n\n演示视频：https://www.bilibili.com/video/BV1rY411z7tA/\n\n代码仓库：https://github.com/WincerChan/talkgpt\n\n## 一些思考\n\n高中的时候，我的数学老师挺有趣的，我在之前的文章里也有提到他。他并不是数学专业毕业，而是学机械的，后来因为找不到相关的工作就转行来当数学老师了。\n\n在某天上课的时候，他给我们普及历史上的三次数学危机（忘记是什么话题引起的了）：第一次是因为无理数、第二次是因为无穷小、第三次是因为罗素悖论，老师像讲故事一样讲完三次危机之后，问了我们一个问题：你们觉得还会不会有第四次数学危机的出现？当时一下班上都叽叽喳喳讨论起来了，无非都是说「应该不会有吧？」、「如果有的话那是什么呢？」之类的话，他在讲台上静静地看着我们讨论了一会，然后说：「看来你们都觉得再有数学危机发生了吧」\n\n看着大家都没有反对，应该是默认了他的话。紧接着他说：「我不这么认为，我想接下来一定还会有第四次、第五次数学危机，我们研究数学的，不能总是按照常识来做判断，在前几次危机发生前，当时的大家也不认为还会有数学危机发生，可事实就是发生了，所以我断定只要人类文明还在发展，接下来一定还会有数学危机发生」（原话已经过了快 10 年了，我自然是无法复述，只能说个大概的意思）。当时的我虽然听不太懂，但是也给我弱小的心灵带来了很强的震撼，现在回过头来我想我有点能理解了。\n\n我们是属于科技行业的人，在 ChatGPT 这波「浪潮」来临的时候，我们首先感受到了，至于是忽略这波浪潮还是利用这波浪潮，在写这个小工具的时候，我想我已经有了决断了。\n\n## 总结\n\n\n花费了几天的空余时间，也算是把这个工具初步完成了。虽然使用起来还比较粗糙，但剩下的打磨可以慢慢进行了。\n\n最近一段时间人有些浮躁，没怎么专心研究技术，做完这个项目下来，感觉还挺好的。我会慢慢拾起对技术的热情。"},{"title":"The Magical Interaction Between ChatGPT and TTS","subtitle":"A Brand New Voice Assistant","url":"/posts/chatgpt-and-tts-work-together-en/","date":"2023-03-14T15:35:09.000Z","updated":"2023-03-25T04:17:09.000Z","category":"实验室","tags":["ChatGPT","TTS","语音助手"],"content":"Back when ChatGPT first launched at the end of last year, I managed to get access to an account. However, the user experience at that time was not great: ChatGPT would suddenly stop when speaking long passages, and I would frequently get errors about too many requests leading to service denial. So after just a few days of experimentation, the novelty wore off and I put it aside.\n\nWho could have expected that a couple months later, the ChatGPT concept suddenly blew up in China again, with more and more use cases being discovered. At the same time, the user experience itself improved quite a bit: no more sudden stops during long passages; service denial happening less and less; and new features like conversation history being supported. So at this point I started consciously using ChatGPT to handle some daily tasks - writing PPTs, general knowledge Q&A, and even restructuring code. Although there were still some errors with the code restructuring, it did give me some inspiration. \n\nBack then I had an idea - ChatGPT is great at everything, except for one thing: it can only communicate via typing (Ahem, if it could communicate via voice, wouldn't interviews and such all become easy?). Unfortunately ChatGPT didn't release a public API at first, so if I wanted to use it, I'd probably have to simulate it with a headless browser, but that would involve cracking Cloudflare's captcha, too much work...\n\nFinally, in March, OpenAI released the ChatGPT API as well as the corresponding speech-to-text model Whisper API. My previous idea of voice conversing with ChatGPT now seemed simple enough to implement, but I was feeling a bit lazy and lacking motivation to work on this project. A few days ago, my girlfriend forwarded me a video that showcased voice interactions with ChatGPT. She thought it was very interesting and asked if I could make one for her. This happened to align perfectly with what I had been thinking about, so I started researching this idea.\n\n<!--more-->\n\n## Module Breakdown\n\nClearly, to converse with ChatGPT via voice, the overall functionality can be split into 3 modules:\n\n1. Speech recognition module: This part converts the user's speech into corresponding text, which serves as ChatGPT's input. \n\n2. ChatGPT module: This part sends the text to ChatGPT and saves its responses.\n\n3. Speech synthesis module: This part converts ChatGPT's responses into speech and plays it back.\n\nBelow is a diagram of the design:\n\n![Module diagram](https://cdn.blog.itswincer.net/img/chatgpt-tts-infras.png)\n\nNext I'll go through the design and implementation of each of these three modules.\n\n## Speech Recognition Module\n\nThis was the module that took me the longest time. At first I didn't plan on using the Whisper API (A lifetime freeloader is always looking for something free), but instead wanted to try offline solutions, mainly because I was concerned about the network overhead of using an API - it would slow down speech recognition and degrade the user experience. \n\nI tried two offline speech recognition options - [PocketSphinx](https://github.com/cmusphinx/pocketsphinx) and [DeepSpeech](https://github.com/mozilla/DeepSpeech). But neither worked that well. PocketSphinx's accuracy was terrible, while DeepSpeech's was decent but so slow, and offline solutions would require me to maintain training models myself. With my half-baked machine learning skills, I was too lazy to deal with model management. \n\nSo after going in circles I ended up back with looking for speech recognition as a cloud service. After quite a bit of searching, I found an open source Python library called [SpeechRecognition](https://github.com/Uberi/speech_recognition) that integrates most major speech recognition services, although most are paid services that require an API key. Luckily Google's offering can still be used for free.\n\nSo my speech recognition module is basically just a wrapper around SpeechRecognition with some custom operations. I can tweak it later if any pain points come up during usage.\n\n## ChatGPT Module\n\nThis module took the least time to complete and there's not much to say. I simply called the OpenAI API. However, I did research the API parameters a bit and made two adjustments compared to the default:\n\n1. temperature: According to OpenAI, lower values result in more consistent responses. For example, with the same input question, higher temperature leads to more diverse responses.\n\n2. messages: I made two more granular tweaks here:\n\n\t1. I prepend a `role=system` directive before all conversations. This is to make ChatGPT's responses follow the system directive. My current directive is \"Answer in concise language\", forcing brief responses instead of rambling. This is configurable in the settings file.\n\t\n\t2. I maintain the last 3 conversation turns by default. The ChatGPT API does not maintain context between conversations like the web interface does. To tie conversations together, previous contents must be included in the request. Without limiting history length, token consumption would quickly get out of hand.\n\nMy current training approach is to leave settings as default for casual chatting. For special conversations, like using it as an encyclopedia for questions, I lower history length and set the system directive to \"Answer in as much detail as possible\". For English conversation practice, I set the directive to \"Act as an English teacher, point out grammatical errors and ask questions based on context\". For mock interviews, I set it to \"Act as an interviewer for the xx role and conduct an interview, respond and ask questions concisely.\"\n\n## Speech Synthesis Module\n\nThis module also took quite some effort on my part. Again I wanted to find an offline solution to save on network overhead and make conversations more fluid. I did find a corresponding offline option - [pyttsx3](https://github.com/nateshmbhat/pyttsx3), which uses the OS's built-in TTS engine: SAPI5 for Windows, NSSpeechSynthesizer for Mac, and eSpeak for other platforms.\n\nAlthough this frees me from dependencies, pyttsx3 has a severe bug - it does not support multithreading. Calls to .speak() don't block if on a non-main thread, leading to overlap. This [bug was reported](https://github.com/nateshmbhat/pyttsx3/issues/8) 5 years ago and remains unresolved.\n\nWith no choice, I abandoned the offline option and went with mooching off Azure and Google APIs, provided by the [edge-tts](https://github.com/rany2/edge-tts) and [gTTS](https://github.com/pndurette/gTTS) libraries. \n\nOne optimization worth mentioning is decoupling the ChatGPT interaction and speech synthesis into separate threads communicating via a queue. With linear execution, waiting for the full ChatGPT response before speaking led to long delays for longer responses. Now, each ChatGPT response sentence gets queued immediately, while the speech thread continuously dequeues data to start speaking. \n\nThis improves the user experience tremendously.\n\n## Links\n\nDemo video (Chinese): https://www.bilibili.com/video/BV1rY411z7tA/ \n\nCode repository: https://github.com/WincerChan/talkgpt\n\n## Some Thoughts\n\nOne day in high school class, my math teacher told us about the three crises of mathematics throughout history (forgot how the topic came up): the first due to irrational numbers, the second due to infinitesimals, and the third due to Russell's paradox. After finishing the story-like overview, he asked us a question: Do you think there could be a fourth crisis of mathematics? We immediately started lively discussion, saying things like \"Shouldn't happen right?\" or \"What would it be about if there were another one?\". He quietly watched us discuss from the podium before saying, \"Seems like you all think there won't be another mathematical crisis.\" \n\nSeeing no objections, he continued, \"I don't think so. I believe there will definitely be a fourth, fifth crisis and so on. As mathematicians, we can't always judge based on common sense. Before each of the previous crises, contemporaries also didn't believe a crisis would happen, yet they did. So I assert firmly - as long as human civilization keeps developing, there will definitely be more mathematical crises.\" (It's been almost 10 years so I can't recall his exact phrasing, but this captures the gist.) At the time, I didn't really understand but still felt the immense impact on my undeveloped mind. Looking back now, I think I can appreciate his perspective.\n\nAs technology professionals, we are the first to experience waves like ChatGPT. Whether to ignore or utilize these waves, I feel I've made my choice while working on this little tool. \n\n## Conclusion\n\nAfter spending a few days' spare time, I've got a rough version of this tool working. There's still lots of polish needed, but the foundation is there. \n\nLately I've been rather restless and haven't seriously studied technology. Finishing this project feels quite good. I will slowly rekindle my passion for technology."},{"title":"2022 年终总结","subtitle":"纪念我随风飘散的 2022","url":"/posts/2022-year-end-summary/","date":"2023-02-07T12:14:34.000Z","updated":"2023-02-07T12:14:34.000Z","category":"碎碎念","tags":["2022","年终总结","工作","感想"],"content":"感觉 2022 年时间过得飞快，快到仿佛在看一部电影，电影开头有点枯燥所以没仔细看，直到电影中段我才刚开始进入情节，思考电影主角的经历怎么和我这么类似的时候，电影已经结束了，后知后觉才发现原来主角正是自己。这种「主角」、「观众」身份的反差带来的荒诞感让我有些不知所措，却也是我当下内心最真实的感受。\n\n<!--more-->\n\n## 游玩\n\n2022年初的游玩经历比较单调，基本上就是逛商场和吃饭，从年中开始的印象还是比较深刻的。因为把女朋友家闲置在广州的车开到深圳来了，周末和节假日的出游多了很多选择，不过也确实发现了深圳是真的没啥玩的……海滩、爬山、公园、商场、游乐园这些地方玩个两次就玩腻了。\n\n腻了之后，游玩路线就开始向深圳的周边城市发展。像是惠州、广州去了不少次，不得不说：惠州的海以及沙滩比深圳的看起来还是舒服不少，长隆的游玩体验也比深圳的欢乐谷要好，广州的美食更是可以把深圳吊起来打。去过了惠州以及广州之后，我和女朋友达成了一致的观点：深圳就是一个只适合打工人的城市。\n\n## 工作\n\n回头来看今年的工作内容挺乏味的，从两年半前刚入职时，内心充满新鲜感到现如今的略显麻木，工作内容的变化应该是占据绝大部分原因。从 2021 年底开始，我工作的重心就已经不在开发上面了，不过由于 2021 年的年终终结鸽了，因此并没有机会介绍当时的情况。\n\n当时产品的研发其实已经接近尾声了，接下来就是由我来主导由产品标准化部署、到生产成硬件盒子步骤，这期间整个流程的打通大约耗费了大约半年左右。这部分的工作其实都算是一些脏活累活，虽然能积累到一些经验，但相比来说，还是程序的开发过程会让我更有成就感。\n\n在公司呆了两年半，眼睁睁看着当初刚入职时的半成品产品，变成如今比较成熟的商业产品，也让我发现了公司或者行业的一些问题，我开始从更高的层面来审视自己的未来发展。\n\n我所在的是面向企业客户的网络安全行业，所研发的产品也是为了给客户提供威胁分析、基础的防护等功能，这些客户大多数是一些传统企业，如：国企、银行、政府单位等。它们都有一些共同点：网络基础建设很差，没有类似网络安全部门的存在，主要靠物理隔离来抵御威胁；同时又不具备基础的威胁分析的能力，因此对于我们来说，往往是出钱（由我们来提供服务器设备）又出力（帮客户进行威胁分析）。\n\n而且我们的产品是部署在客户侧的网络中，偶尔出现一些程序的 bug，查看日志调试变成了一件异常困难的事。有些客户无法提供远程服务，便只能请安服的同事去现场排查，由我们这边告诉安服的同事运行的命令，再由他拍照等方式反馈，这种方式效率又低、人又累。而且由于我是负责产品标准部署的人，对产品的各个组件也比较熟悉，所以主要是我来排查发现问题，再由具体的人去解决问题。这部分工作内容也让我觉得工作变得乏味了起来。\n\n年中的时候，我和领导提起了我的困扰，于是领导安排了另一位同事帮我分担。可没过几个月，公司层面开始了动荡，公司在前几个季度巨额的亏损，让公司开始了为期半年的裁员。我们的组织架构也是一变再变。人们对自己无法控制的动荡就会滋生不安情绪，尤其是今年过年公司竟首次没有在年前发年终奖，甚至都没有发一封邮件或是文章来说明一下此事、安抚一下员工，这无疑更是加剧了我们每个人的不安情绪，也引发了部分同事的不满（这其中自然也包括我）。\n\n其实通过我之前对行业的描述中就是可以预见公司的亏损是必然的，又出钱又出力，销售恨不得把客户供起来，客户提的什么要求都接受反而要我们研发来擦屁股。在这种模式下盈利基本上是不可能的，这也是我认为这个行业最大的弊端。\n\n之前一直有成为一名黑客的梦想，因此我毕业后选择的两家公司都是和网络安全相关的。可惜作为一名研发人员来说，没有机会体会到网络攻防带来的刺激感，反而受到了行业弊端所带来的一地鸡毛。下一份工作，我大概率不会再从事这个行业了。\n\n## 生活\n\n生活中最大的改变是我终于在女朋友的陪伴下学会了自行车，家里到上班的路上骑车大约 4.5km 左右，其中有 3km 是沿着河骑行，风景很不错，空气也比较清新，还可以锻炼身体。\n\n惭愧，翻了翻书单，去年一年有部分空闲时间消耗在了网文上，对于实体书并没有看什么，说来也是奇怪，在一个月内高强度看了四五本网文，之后半年就都没有看过了；影视的话貌似没有看到那种惊为天人的：爱情神话、甄嬛传、侠僧探案传奇、开端、无证之罪、圆桌派、黑社会、异物志、唐朝诡事录这些都算是还不错。\n\n## 结尾\n\n本文的大部分篇幅都是在描述我对工作的感受，说是年终终结到还不如说是我对工作、行业的吐槽文，不过这也的确是我在写这篇文章时最想要表达出来的：同质化严重、且内容不喜欢的工作所造成的后果就是每天盼着下班、工作日盼着周末；过了很久回味起这段时间时又回想不起来有什么值得纪念的事情，于是便会感觉到荒诞：这段时间到底是我亲身经历过的吗？终于发现，原来的确是我的生活，只是它怎么过得这么快啊，快到我都没有来得及好好体会。\n\n2023，愿我们都有空闲能好好生活。"},{"title":"我最近订阅的一些软件服务","subtitle":"包括科学上网、VPS 等","url":"/posts/software-services-I-recently-subscribed/","date":"2022-12-10T04:59:03.000Z","updated":"2022-12-14T12:28:52.000Z","category":"分享境","tags":["科学上网","VPS","订阅服务"],"content":"最近不知怎么，忽然就有了消费的冲动，除开双十一买的实体商品外，我把之前订购的一些云服务也做了一次大升级。俗话说货比三家不吃亏，可有些软件服务并不像实体商品能通过货比三家来对比选择，尤其是和网络相关的服务，所以你只能自己买来尝试，也就难免花了些「冤枉钱」。为了能让这些「冤枉钱」显得不那么「冤枉」，我决定写一篇博客来整理一下这些服务，如果恰巧能给有选购需求的人带来帮助，那就更好了。\n\n<!--more-->\n\n## 科学上网\n\n\n### 我的翻墙史\n\n\n话说我从高中开始，还不知道编程是何物的时候，就开始学着翻墙了，那时候印象比较深的有两个软件：\n\n\n1. 蓝灯：免费，安装软件即可翻墙，一开始用户少的时候，速度还是可以的。\n2. SS / SSR：软件免费，但需要搭配服务器节点使用。记得当时破娃基于SS协议添加了混淆模块重新包装成了 SSR 协议，当时一开始没有开源，后来被喷的才开源的。\n\n后来上了大学，有了自己的服务器，开始自己搭建翻墙服务了。再后来，GFW 变得越来越智能，自己搭建的 SS / SSR 服务很快就会被 GFW 发现，然后限速，最后封锁。于是那时候风头开始转向了 V2ray 这类可以流量伪装的软件。不过 V2ray 配置起来实在是太麻烦了，要自己生成证书、配置 Nginx、配置域名解析、WebSocket 等，实在是对我有些劝退……而且这层层加密、伪装后，性能也会有所损耗。\n\n后来不知道什么时候开始，翻墙服务商（以下简称机场）开始流行起来了，大大地减轻了用户配置起来的心智负担，我也在这时候开始使用起了机场，那时候大多数机场很不稳定，经常遇到用了没几天就跑路的，好不容易找到一个能用机场，在头几天速度很不错，然后在用户多了之后，就又很慢很慢了。\n\n闲话扯的有点多，下面正文开始说我这段时间对几个机场的体验。\n\n### GlaDOS\n\n\n这是一家典型的使用协议伪装的服务商，大部分都是 V2ray 节点。也算是我使用时间最久的一个机场（快一年半）这个机场也是有之前提到的问题、在刚开始使用的大半年里，速度都还不错，然后每到重大日子或者晚高峰的时候总会有一些节点挂掉或者速度变慢，尤其是最近，大批量的节点不可用伴随着部分线路又被撤掉。\n\n不过，这家机场有个很有趣的点就是每天签到可以续 1 天（所以理论上可以无限期的白嫖？），可惜线路实在一般，而且 IP 也并非是原生的 IP。\n\n基于以上考虑、我决心开始寻觅新的机场。\n\n### AmyTelecom\n\n\n这家是我在逛 V2EX 的时候看到有人推荐的，稍微搜了一下测评，发现是一家中转机场，并且只提供 SS  协议的节点。\n> 所谓中转机场就是在国内架设一台中转服务器，用户都是先连接到这台服务器，再由中转服务器与目标服务器通信。这家中转选的是华为云和阿里云。\n\n\n优点是线路好，国内访问阿里云和华为云基本不会受到高峰期的影响，尤其是在深圳地区，直接接入阿里云深港专线，香港节点延迟低得吓人（电信网 30ms）；缺点就是成本比较高，所以比较贵。\n\n这家只提供香港、日本、台湾、新加坡、美国这五个地区的节点，不过节点全部可用，且质量非常高，均为原生节点。\n\n不过我在使用了一段时间后发现了这家的另一个问题：有些网站打不开，这些打不开的网站里有部分是属于政治敏感的网站，也有部分是比如日本雅虎等正常的网站。我看到在官方的 telegram 里也有人反馈这个问题说是因为落地的限制（这家大部分都是 Kirino 落地），不过官方并没有承认是什么原因。我在他们的服务条款里也没有翻到具体有哪些域名是不能访问的。这一点得夸一下 GlaDOS，购买套餐的时候明确表示他们运行了域名拦截器拦截部分政治敏感域名的访问，并给出了一个域名列表。\n\n不过即使 AmyTelecom 运行了域名拦截器，但日本雅虎等网站打不开仍无法解释。\n\n### FlowerCloud\n\n\n这家是我在搜 AmyTelecom 的评测的时候看到的，同样是一家中转机场，不过相比 AmyTelecom，在中转服务器与目标服务器使用的是 IEPL 线路，理论上会比单纯中转机场线路更好，同样是只提供 SS/SSR 协议。\n\n这家南方的中转的就不是深港专线了，而是广港专线，所以我在深圳体验起来延迟会稍微高一些（60ms 左右），不过也是基本感受不到延迟。\n\n这家地区的节点比 AmyTelecom 多不少，像是欧洲、北美、南美，西亚等全都有覆盖。也是基本上所有的节点都处于可用状态。不过这些冷门节点相信大部分人也都用不到。\n\n这家同样运行域名拦截器，不过像日本雅虎等网站可以打开（不知道是不是因为这家落地比较多的缘故）。\n\n我目前是 AmyTelecom + FlowerCloud 双持。由于这两家都是年付，待后续再使用几个月，明年续费时候可能就会只使用一家了。\n> 题外话：这两家在我订购后没两天都宣布了双十二以及圣诞的优惠活动（85 折），原价订购的我像个大冤种。\n\n\n## VPS\n\n\n这期间我也尝试了几家不同的 VPS 提供商。\n\n### Racknerd\n\n\n这家在 lowendtalk 很出名，我在之前的博客里也有介绍过，也是我一直在使用的。服务挺不错的， 有啥问题基本上提工单都能得到回应。黑五的折扣也是实打实的，\n\n我在黑五的时候入手了一款美西的服务器，线路嘛，就那样，没啥优化，但硬盘和内存给的比较实在。\n\n这家 VPS 的Location 有美国中部、西部、东部和荷兰阿姆斯特丹可选，如果要购买建议选择美西地区（LA 或者 SJ），尤其注意不要选择荷兰，年费贵 6 刀，而且延迟超高。\n> 是的，我在前文所说的冤枉钱就包括订购荷兰节点的 VPS。\n\n\n### VMISS\n\n\n这家应该是个国人商家，我在最近购买了他们家的日本 VPS，这家和 Racknerd 家正好互补，这家的内存、硬盘、流量给的比较少，但是线路很不错，IIJ 线路，沿海地区基本上 60 ～ 70ms 的延迟，带宽也可以。\n\n不过我没打算自己搭建翻墙服务，两个机场怎么也够用了。没必要给自己的服务器惹上被封锁的风险。\n\n这家的地区比 Racknerd 多了几个亚洲的地区：香港、日本、韩国，都比较适合国内的用户使用。\n\n### Hosthatch\n\n这家也是在 lowendtalk 发现的商家，我购买了日本地区的 VPS，价格与 VMISS 相比高了 50% 左右，配置差不多相当于翻倍，不过他们声称供货需要 2 周左右，因此等拿到货之后我再来写评价。\n\n这家地区更多了，除了亚洲新增了新加坡地区，还包括澳洲、欧洲等地区。\n\n> 2022-12-14 更新：\n\n不出意外，这家的线路还是比 VMISS 差点，并不是 IIJ 线路，而是 NTT；电信网络的延迟有点高，移动网络的延迟倒是还行，带宽也比  VMISS 差不少。不过 CPU 是 AMD EPYC 7443，内存、硬盘 IO 等基础硬件配置比 VMISS 强了许多。这家我应该会继续用，毕竟电信的延迟再高，也比不上美西（LA、SJ）的延迟高。\n\n## iOS 端代理软件\n\n\n### Shadowrocket\n\n\n之前我一直都是使用 Shadowrocket 来作为 iOS 端的代理工具，不过它在配合 GlaDOS 机场的节点使用的时候我经常会遇到一个很奇怪的问题：连接公司 Wi-Fi 的时候，开启了 VPN 导致手机无法上网的问题，必须要断开 VPN，开启飞行模式，再重新开启 VPN才能恢复上网。但是当我换成了 AmyTelecom + FlowerCloud 之后就没有出现这个问题了。\n\n另外 Shadowrocket 的分流规则实在有点简陋，去广告的功能研究了半天也没成功。\n\n### Quantumult X\n\n\n在换了机场之后，我又入手了 Quantumult X。老实说，Quantumult X 这软件设计的交互逻辑真的有点奇葩……功能又复杂，如果不找教程的话完全无法通过自己的摸索来使用，而且稍微老一点的教程里的界面相比最新版 Quantumult X 界面都有不少改动，使用门槛比 Shadowrocket 真的高了很多。\n\n优点在于功能比 Shadowrocket 强大了不少，除了更细致的分流、重写规则外，还可以查看网络流量统计、日志、DNS 查询等，折腾了几个小时配置之后用了几天倒也用得还算舒服。\n\n不过去 Youtube 广告去得不是很明显，在首页的推荐还是会有广告，而且点进视频的时候，有时候广告会先弹出来然后一闪而过。有点影响体验，而且不知道是不是错觉，使用了 Quantumult X 之后，我发现手机掉电特别快。\n\n对于大多数没有复杂翻墙需求的人来说，我还是会比较推荐 Shadowrocket，除开售价便宜不少之外，Youtube 的广告去除也稍显鸡肋：因为我发现 AmyTelecom 有些节点打开 Youtube 就是没有广告，使用 Shadowrocket 测试首页推荐和视频播放都没有广告。\n\n## 总结\n\n\n总结一下，本文记录的所有花费大概在一千八百人民币左右，不过等明年会再取消掉部分订阅服务：\n\n\n- 科学上网方面，我目前是 AmyTelecom + FlowerCloud 双持，但明年应该会只会二者选其一，具体选哪个需要再等几个月观察一下二者的稳定性再决定；\n- VPS 方面，Racknerd 的荷兰节点我肯定不会续费了，SJ 的节点看情况是否续费；VMISS 的日本节点和 Hosthatch 的日本节点我应该都是会保留，Hosthatch 节点虽然对电信的线路差了点，不过我家里是移动网，倒也不是什么大问题。\n- iOS 代理，Shadowrocket 和 Quantumult X 都是买断制的软件，也不存在续费，后续的使用我还是会以 Quantumult X 为主。\n\n粗略估算了一下，明年的订阅服务应该会控制在 1000 元以内，其中机场订阅与 VPS 订阅的花费应该刚好五五开。"},{"title":"聊聊博客主题的更新","subtitle":"博客主题的保质期一般为两年","url":"/posts/about-recent-blog-updates/","date":"2022-09-15T15:45:08.000Z","updated":"2022-09-15T15:45:08.000Z","category":"博客栈","tags":["博客","Hugo","设计","主题"],"content":"两年前，我刚决定把博客迁移到 Hugo 时，因为找了许久都没有找到合适的主题，只好自己动手写了一个（项目地址：[Cirrus](https://github.com/WincerChan/Cirrus)）；在随后的两年中博客便一直使用着这套主题，这期间倒是也陆续发现了其它一些还不错的，不过我却没有什么更换的念头，因为在自己动手写了一个主题之后明白了一个道理：只有自己设计的东西才能真正贴合自己的需求。两年后的现在，看着我写的第一个主题，心中虽感慨万千，却也愈看愈觉得它「稚嫩」与「不成熟」，不由得泛起重新设计一版主题的念头。\n\n<!--more-->\n\n一番思考之后，我首先明确了本次重新设计最核心的理念：对现有的内容做一些裁剪。两年前因为不懂设计，所以总是想把博客的页面布局塞得很满，无论组件是否有用只要我想得到都塞进去，实际上部分组件根本没必要展示，还有部分组件可以换另一种更好的方式展示。\n\n这次重新设计的所有页面我都通过 Figma 画了原型图，然后对着原型图开始实现；相比之前在脑子里想布局然后转化成 CSS 再根据浏览器的实际效果调整，效率方面实在提高了太多。Figma 上手也比较方便，花了两个晚上跟着 B 站的视频操作了一下就基本掌握了初级的用法，设计一个静态博客足够用了。\n\n原来的样式可以通过 [Cloudflare Pages 的快照](https://bf4a6572.cirrus.pages.dev/)来对比查看。\n\n## 布局的改变\n\n博客的布局从原来的三栏变成了顶部导航 + 双栏：原先左侧的博客名称以及菜单信息挪到了顶部以减少空间占用，没啥用的博客副标题我也干脆直接去掉了。这样就有更多的空间来展示中间部分——也就是博客正文。\n\n而菜单部分，我也略作了修改，首先删除了原先占位置的 ICON 图标，并且还删除了归档页面的链接，现在归档页面只有通过首页的查看更多文章的链接才能进入，这样在顶栏显示时会和谐一些。\n\n随后我在谷歌分析查看了最近三个月每个页面的访问次数的统计，发现翻页的访问频率出乎我意料的低：第二页的访问量近三个月只有个位数，排名更在五十名开外，因此我决定把翻页的功能直接砍掉。\n\n而将翻页砍掉之后，为了让首页展示更加和谐，我把文章占用的空间做了递进处理：最近一篇文章占用空间最大，并显示副标题以及摘要部分；剩余 4 篇近期的文章将摘要以及副标题隐藏，只展示标题以及日期（这或许能骗一部分浏览量？）；而更早的文章则在首页直接隐藏，只留一个归档页面的入口。\n\n而右侧的布局也做了一些小调整，加上了文章篇数、总字数的统计，文章数也由原来的按年份统计改成了按类别统计，组件标题旁的 ICON 也移除了。\n\n## 减少动画\n\n之前的主题动画效果太多了，当时的我近乎炫技一般想给所有的交互都加上动画效果，并且同一类组件交互起来动画还不一样，使用起来就感觉很混乱。比如同为按钮：\n\n1. 翻页按钮的动画是边框颜色从灰变黑；\n2. 文章标题右侧的类别按钮则是背景的透明度变暗；\n3. 标签按钮则是背景与字体的颜色互换；\n4. 暗色模式 / 搜索按钮则只是单纯鼠标指针的变化；\n5. ……\n\n本次更新我也会将同类组件的交互显示效果趋于一致，我将原来一些标签组件、分类统计组件的按钮样式改为了超链接样式，因为它们从功能其实更接近于超链接——都是链接到其他页面。\n\n这样按钮组件在形式风格、功能上就更统一：\n\n1. 只在当前页面交互：给按钮加上 Border，Hover 时鼠标指针便成 Pointer，无额外动画。\n\n同时我也将之前的一部分按钮变成了超链接的形式：比如文章 Card 中的类别。\n\n而超链接的样式我也分为了 2 类：\n\n1. 正文部分的链接：字体为超链接颜色，并且统一加上下划线装饰、Hover 时下划线的高度会变高；\n2. 非正文部分的链接：字体为正常颜色，Hover 时字体颜色变成超链接的颜色，并加上下划线装饰。\n\n这样交互起来的动画效果就看起来比较和谐了。\n\n## 一些没啥用的优化\n\n另外还有些比较细碎的优化，不值得拿出来单独讲，在这里列举一下：\n\n1. 标题、日期，以及文章类别不再直接显示在文章封面上面：因为如果遇到某些浅色或者比较花的图片会显得文字有些难以辨认；\n2. 文章详情页底部的前一篇、后一篇文章 Card 在 Hover 时的动画效果我也直接删了，改成了用超链接的第二类效果；\n3. 摘要的最后一个字的位置显示为省略号改为用 SVG 图片来覆盖最后一个字实现，之前使用 webkit-line-clamp 的属性和 text justify 搭配在 Safari 上显示有 bug，省略号会和文字重合；\n4. 右下角新增了一个回到顶部的按钮，它在所有页面都会显示，不过目前它是常驻的，我在研究页面滑动到顶部时隐藏按钮的方案时发现有些复杂，就暂时不做了；\n5. 右上角的浅色 / 暗色模式切换的 ICON 现在会动态变化：处于浅色模式时显示月亮图标，表示点击会切换为深色模式；处于深色模式时显示为太阳图标，点击会切换为浅色模式；\n6. 趁着 Google Analytics 要求用户从旧版 Universal 迁移，干脆去掉了 Google Analytics 的统计代码。\n\n---\n\n最后，博客主题虽然更新完成，不过今年只更新了 2 篇文章，希望后续我能将更多的兴趣放在博客的内容创作上来——我好像每次都这么说，也不知道能不能做到。"},{"title":"从一次 DNS 流量测试说起","subtitle":"如何伪造一个正常的 DNS 请求","url":"/posts/start-with-a-dns-traffic-test/","date":"2022-07-02T11:29:20.000Z","updated":"2022-07-04T14:55:25.000Z","category":"分享境","tags":["DNS","计算机网络","流量测试","Linux"],"content":"又是大半年没更新，或许我不得不承认，我写博客的热忱相比两年多前的确是在逐渐退却，思考了一下，原因或许可以归咎于如下：\n\n1. 在工作上能学到的东西、值得记录的东西变得越来越少，最近半年几乎都乏善可陈了；\n2. 在业余时间的精力分散给了其他事情，导致研究技术的时间变少了（业余时间的事情，后续有机会再详细讲讲）。\n\n不过，最近在工作上遇到了一个有点意思的事，钻研了一下觉得值得写一篇文章来记录——于是屁颠屁颠地花了三个晚上时间完成了这 2022 年的第一篇博文（希望不要是唯一一篇博文）。\n\n<!--more-->\n\n## 背景介绍\n\n最近我们组要推出一个 DNS 防火墙产品——拦截黑名单域名并提供简单的查询分析功能。我主要是负责实现拦截功能，具体的工作是写一个插件让 CoreDNS 可以实现 DNS Sinkhole 的功能，也就是针对（特定的客户端）访问特定的域名返回错误的结果，同时将解析的结果输出到数据库保存下来以供后续分析。开发过程并不困难，反而是在开发完成后的测试阶段遇到了困难。\n\n## 抽丝剥茧\n\n如果只是对拦截功能的测试，还比较容易解决——无非是多写几个单元测试用例，可要对整个 CoreDNS 的解析、拦截功能进行测试就会麻烦不少：完整的 DNS 请求涉及到网络、IO、转发请求等各个方面，不再是通过测试用例就可以覆盖的。因此我最初的想法是在另一台服务器上把默认的 DNS 服务器改为运行 CoreDNS 的服务器地址，再在这台服务器上批量运行 `gethostbyname` 函数来发出域名的解析请求，每一条的解析请求背后都意味着一套完整的 DNS 解析流程，因此可以较好地覆盖 CoreDNS 解析、拦截功能的测试。\n\n不过这却引来了另一个问题，之前提到过，我们还需要把 CoreDNS 解析的 DNS 记录保存下来供后续分析使用，如果所有的 DNS 请求来源都是在另一台设备上，那么所有 DNS 记录的源 IP 都会是同一个，虽然这对功能测试以及性能测试没有影响，但在产品的实际展示效果以及产品体验上会大打折扣。\n\n**因此，搞来一批 DNS 流量并想办法让流量流经 CoreDNS 的服务器并保持源 IP 不变，问题就能得到解决了。**\n\n> 声明：文中出现的所有 IP 协议谨代表 IPv4 协议，暂未进行 IPv6 协议测试\n\n## 一些「头脑风暴」\n\n思考了一阵，我冒出了一个有点不太靠谱想法：要是能把公司内网的 DNS 流量全都指向 CoreDNS 就好了——这对我们来说是最省事的，可显然是不符合实际的，先不说公司的其他部门会不会同意，我们是以测试 CoreDNS 为目的，而测试的过程是不稳定的：如果 CoreDNS 挂掉了那意味着全公司的员工都无法上网了…这损失我们显然承担不起。\n\n于是我想到了另一个方法：既然不能改公司的原始 DNS 流量，那么我把原始流量通过 Tcpdump 导出成 Pcap 文件，然后把 Pcap 文件本身包含的 DNS 记录请求的地址改成 CoreDNS 服务器的地址，再通过类似 Tcpreplay 的手动重放不就可以了吗？\n\n乍一看，这似乎是比较好的解决方法，然而在实际验证过程中发现此法也行不通：原因在于 Tcpreplay 只会把 Pcap 文件里的数据重放在对应的网卡上，而**并不会**实际在网卡上创建 TCP 连接。这也比较好理解，毕竟我在机器 A 上抓包与机器 B 通信数据生成的 Pcap 文件，再通过机器 C 上的 Tcpreplay 重放，这并不可能重新让机器 A 和机器 B 建立相同的连接。\n\n## 伪造 DNS 请求\n\n虽然 Tcpreplay 的方式最终被验证是行不通的，但也算给了我一些启发：DNS 是建立在传输层之上的协议，我可以自行构造一份 DNS 协议的报文，再通过传输层协议（通常是 UDP）发送到 CoreDNS 的 53 端口，这样应当就能解决 Tcpreplay 无法产生真实连接的问题。\n\n我这里是使用的 Scapy 工具来解析出 Pcap 文件中的 DNS 协议，Scapy 可以调用 iPython 解释器用于调试，比较方便：\n\n```python\n>>> records = rdpcap(\"./dns.pcap\")\n>>> records[0][DNS]\n<DNS  id=31895 qr=0 opcode=QUERY aa=0 tc=0 rd=1 ra=0 z=0 ad=1 cd=0 rcode=ok qdcount=1 ancount=0 nscount=0 arcount=1 qd=<DNSQR  qname='baidu.com.' qtype=A qclass=IN |> an=None ns=None ar=<DNSRROPT  rrname='.' type=OPT rclass=4096 extrcode=0 version=0 z=0 rdlen=None |> |>\n>>> records[0][DNS].qname\n>>> UDPClientSocket = socket.socket(family=socket.AF_INET, type=socket.SOCK_DGRAM)\n>>> UDPClientSocket.sendto(raw(records[0][DNS]), (\"127.0.0.1\", 53))\n38\n>>> records[0][DNS].qd.qname = b'www.zhihu.com.' # 我们可以尝试修改 DNS 协议的 qname\n>>> UDPClientSocket.sendto(raw(records[0][DNS]), (\"127.0.0.1\", 53))\n42\n```\n\n这时，在运行 CoreDNS 的终端就能看到两条日志输出了：\n\n```bash\n[INFO] 127.0.0.1:61730 - 31895 \"A IN baidu.com. udp 38 false 4096\" NOERROR qr,rd,ra 88 0.041027042s\n[INFO] 127.0.0.1:61730 - 31895 \"A IN www.zhihu.com. udp 42 false 4096\" NOERROR qr,rd,ra 256 0.069857333s\n```\n\n这意味着 CoreDNS 能成功接收到我们伪造并发送的 DNS 解析请求（Yes！终于向着解决问题迈出了一步）。不过观察到 CoreDNS 的地址还是显示请求是来自 127.0.0.1——因为我们是通过 127.0.0.1 发起的连接，但我们的目标正是想伪造这个发起连接的地址，让它不能显示成实际发送 UDP 数据包的机器。不过这并不是 DNS 协议能够做到的事了，注意看上一个代码块，DNS 协议本身是不具备目标 IP、端口等连接信息的，这是更底层的协议做的事情。\n\n因此我们需要尝试伪造更底层的协议。\n\n## 更进一步——UDP 首部\n\n这里我再次恶补了一下计算机网络的知识，因为之前对计算机网络协议的使用都是到传输层便戛然而止，更低的 IP 层以及数据链路层则完全没有接触过了。而为了构造更底层的协议，就不能直接使用系统的套接字了——而需要使用 Raw Socket（原始套接字）。\n\n> 扫盲时间：无论我们创建流套接字（通常是 TCP 传输）或是数据报套接字（UDP 传输），都需要指定目的地址和目的端口，因为前者是网络层所需要确定的，后者是传输层所需要确定的；而我们创建的数据报或是流套接字并没有让我们去构造传输层以及网络层的首部，因为这些都由操作系统帮我们完成了。而我们现在想要自己构造网络层以及传输层的首部，因此便不能使用流套接字或数据包套接字了。\n\n```python\n>>> RawSock = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_UDP)\n>>> records[0][UDP]\n<UDP  sport=59503 dport=domain len=46 chksum=0x1b86 | ... > # dport 是 domain 意味着 53 \n>>> records[0][UDP].sport=10000 # 将 sport 改成 10000\n>>> del records[0][UDP].chksum # UDP 首部有改变，chksum 也会变，直接删掉此字段\n>>> RawSock.sendto(raw(records[0][UDP]), ('127.0.0.1', 0)) # 虽然我们删掉了 chksum，但 raw 函数会重新生成 chksum\n46\n```\n\n特别需要注意的是，因为我们构造的 UDP 首部本身是包含着 sport 和 dport 的，因此我们在发送的时候的目标端口直接填写 0 即可。\n\nCoreDNS 成功打印出如下日志，这意味构建 UDP 的首部也搞定了，离成功更近了一步：\n\n```bash\n[INFO] 127.0.0.1:10000 - 31895 \"A IN baidu.com. udp 38 false 4096\" NOERROR qr,rd,ra 88 0.070468417s\n```\n\n## 更近两步——IP 首部\n\n虽然使用原始套接字能让我们成功伪造 UDP 首部，即更改源端口为任意数，但其实源端口的改动并不重要。我需要改动的是源地址，而源地址的改动则涉及到了 IP 协议的首部。\n\n花费了一番功夫，发现了 `IP_HDRINCL` 这个原始套接字的选项，当创建的原始套接字是 `IPPROTO_UDP` 或者是 `IPPROTO_TCP` 时，此选项值默认填充为 0，此时待发送的数据包在流经 IP 层时会自动加上 IP 的首部，而当手动设置了此选项为 1 或者创建的原始套接字的类型是 `IPPROTO_RAW` 的时候，则不会自动加上 IP 的首部，也就是需要在发送的数据包上手动构造 IP 首部：\n\n> 以下测试代码只在 Linux 下测试过，macOS 无法通过测试。\n\n```python\n>>> records[0][IP]\n<IP  version=4 ihl=5 tos=0x0 len=66 id=49309 flags= frag=0 ttl=64 proto=udp chksum=0x9ec7 src=10.6.3.182 dst=10.6.3.133 | ... >\n>>> del records[0][IP].chksum  # 因为 IP 的 payload 有所更改，因此 chksum 肯定有变化，可以直接删掉它\n>>> records[0][IP].dst='10.6.3.33' # 更改 dst 为 CoreDNS 监听的地址, 但不能是 127.0.0.1\n>>> RawIPSock = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_RAW)\n>>> RawIPSock.sendto(raw(records[0][IP]), ('', 0)) # 因为包含了 IP 首部，因此目标 IP 地址也可不用填\n```\n\n> 之所以 IP 首部的 dst 字段不能填写 127.0.0.1 的地址，是因为 127.0.0.1 是本地回环的地址，本地回环的连接是不可能从其他的 IP 发起的，所以如果这里的 src 是 10.6.3.182 而 dst 是 127.0.0.1 的话，响应的数据包因为找不到发送方会直接被丢弃掉（可以用 tcpdump 来验证）！所以这里的 dst 需要填写本机的网络地址，如果是网络地址找不到发送方数据报会被发到网关，虽然到了网关也会被丢弃，但数据包已经从本机传输出去了（也能通过 tcpdump 来验证）\n\nCoreDNS 成功打印出如下日志：\n\n```bash\n[INFO] 10.6.3.182:10000 - 31895 \"A IN baidu.com. udp 38 false 4096\" NOERROR qr,aa,rd 85 0.000099594s\n```\n\nIP 首部的构造也已经完成，无论通过 CoreDNS 的日志或是 tcpdump 均可以看到发送请求的 IP 的确是被我们篡改了。\n\n问题已经基本得到解决了。\n\n## 更进三步——Ethernet 首部\n\n之所以还想着篡改 Ethernet 的首部，是因为只改 IP 首部还是有些限制：只能发送不经网卡的数据。这意味着我在解析 Pcap 之后只能发送到本机，也就是说我只能在运行 CoreDNS 的设备上进行解析 Pcap 测试，大多数情况下也不是什么大问题，可当进行压力或是性能测试的时候，解析 Pcap 也是会占用不少资源的，这样一来 CoreDNS 的性能测试就会有失偏颇。\n\n很自然地，我想到了可以通过篡改 Ethernet 首部，把发送方挪到另一台机器上：\n\n```python\n>>> EtherSock = socket.socket(socket.AF_PACKET, socket.SOCK_RAW) # 注意第一个参数，是 AF_PACKET\n>>> EtherSock.bind(('eth0', 0)) # 这表示我们通过哪个网卡发送数据包\n>>> records[0].dst = 'xx:xx:xx:xx:xx:xx' # 目的机器的网卡的 mac 地址\n>>> records[0].src = 'xx:xx:xx:xx:xx:xx' # 刚刚绑定的网卡的 mac 地址\n>>> EtherSock.send(raw(records[0]))\n```\n\n不过此方法同样有限制：需要保证 Ethernet 的 src 和 dst 处于用一个局域网内，这两者的通信不能通过网关。\n\n一旦需要通过网关，那么 Ethernet 的 dst 字段就不能是目的机器的 mac 地址了，而应该是网关的 mac 地址。而为了安全考虑，绝大部分的网关都会选择开启入口过滤， 即网关在收到 Ethernet 数据包的时候，会拆开 Ethernet 首部，去查看 IP 首部的 src 和 dst，如果查看到 src 不属于本网段，那么这个 DNS 请求会被直接丢弃。\n\n在通过 Python 验证了此法的可行之后，我选择了使用 Golang 来实际写解析的程序，因为 Python 的性能实在太差——用 Scapy 打开一个一百多兆的 Pcap 文件结果把我电脑的内存占用完毕了还没有加载成功……\n\n另外，出于兼容性考虑，但我在解析程序的发送端上没有选择使用原始套接字，而是使用了 gopacket——反正解析 Pcap 也是需要用到 gopacket，发送端也干脆用它，这样 macOS 上也可以运行了。\n\n至此，本次 CoreDNS 测试所遇到的问题，总算都圆满解决了。\n\n## IP 欺骗攻击\n\n问题已经解决了，不过在研究过程中还发现了一些可以值得说道的东西：既然可以通过构建 IP 首部来伪造请求的发送方，那么就意味着攻击方可以伪造成不属于本机的请求，而被攻击方也没办法通过把发送方 IP 加入黑名单来抵御——因为发送方 IP 可以任意变化（这种手法经常用在 DoS 攻击里）。\n\n这听起来好像有点无赖，不过刚刚也提到了 IP 欺骗的两个弱点：\n\n1. 大部分的网关都开启了入口过滤，发送方的 IP 如果不属于该网关覆盖的范围内，那么是发不出去的；\n2. 即使发出去了，因为 src 地址的改变，响应包也不会回到发送方，这意味着 TCP 协议是可以天然防御 IP 欺骗的，因为 TCP 在握手的时候序列号是与远程机器协商的。\n\n这两者都极大的限制了 IP 欺骗的使用场景，思来想去，DNS 协议似乎是最适合 IP 欺骗的攻击了……\n\n---\n\n最后，列出一些在本次研究过程中，遇到的一些好用的工具：\n\n- [GoPacket](https://github.com/google/gopacket)：Golang 实现的高性能的解析 Pcap 发送 Ethernet 数据包的工具\n- [Scapy](https://scapy.net)：Python 实现的数据包处理攻击，是 gopacket 的超集，可直接发送 IP 层的数据包，易用性、可调试性秒杀 gopacket，性能被 gopacket 秒杀\n- [Tcpdump](https://www.tcpdump.org)：网卡抓包工具\n- [Tcpreplay](https://tcpreplay.appneta.com/)、[Tcpliveplay](https://tcpreplay.appneta.com/wiki/tcpliveplay-man.html)：pcap 回放工具，前者只是回放数据包不创建连接，后者可以真实建立连接。"},{"title":"我的 FreeBSD 服务器配置","subtitle":"","url":"/posts/set-up-freebsd-server-of-mine/","date":"2021-11-27T10:04:55.000Z","updated":"2021-11-29T00:04:55.000Z","category":"分享境","tags":["FreeBSD","服务器","记录"],"content":"我一直是一个有些特立独行的人，因此对一些小众、非主流的事物有着偏好：通常不使用 Windows 作为电脑的操作系统，通常使用 Linux 或着 MacOS；使用 Markdown 来写文档，如果有精细的排版需求我会选择 LaTex，不使用 Word；Shell 的解释器我会使用 Fish 而不是 Zsh 或 Bash；浏览器也是 Firefox 的忠实用户；编程语言我也尽量往冷门的学，比如 Elixir……因此，在知道服务器的操作系统除了 Linux 还有 BSD 之后，使用 FreeBSD 作为服务器操作系统的念头便在心里埋下了，这埋下的念头之所以一直没有发芽，除了 FreeBSD 的软件相比 Linux 要少很多之外，更多的原因在于 FreeBSD 一直不支持 BBR 拥塞控制算法，索性，在最近的 FreeBSD 13 版本中，已经可以支持 BBR 了，于是我立刻订购了一台服务器开始了 FreeBSD 的折腾之路。\n\n<!--more-->\n\n## 一波三折的安装\n\n大多数的 VPS 服务提供商虽然在安装操作系统时提供了多种选择，但是大多都是 Linux 的不同发行版，换汤不换药。因此我费了不少力气才找到一家宣称支持 FreeBSD 的提供商。\n\n我开始选择的是 San Jose 的机房（他们提供有 Dallas、Los Angeles、），因为实测 San Jose 机房的带宽我跑得最满，于是我就发了一个工单和客服说我需要安装 FreeBSD，请他们帮忙挂载一下 FreeBSD 13 的镜像。十几分钟后他们回复说成功挂载了，需要我登陆 VNC 继续后续的操作，当我登陆 VNC 后虽然进入了 FreeBSD 的引导界面，但是报错了：\n\n![2021-08-10 10.33.50-1](https://p9.toutiaoimg.com/img/tos-cn-i-siecs4i2o7/afb270818cb041dcaf2c1822c0b65306~noop.image)\n\n于是我和客服反应这个情况，他们怀疑是我的镜像的问题，于是我换了一个 bootonly 版本的镜像，让他们重新挂载，问题依旧。来回试了好几个不同版本的镜像，始终都存在这个问题，我都快没有耐心了，终于他们说会标记这个问题让高级管理员来查看。\n\n过了几个小时，高级管理员回复了我，说他们正在探讨这个问题，并且怀疑是 San Jose 机房的内核、libvirt 版本不一致导致的，查验这个问题的修复结果需要重启，但由于机房存在大量的用户，所以这并不是一个很快就能解决的问题。于是他们提出可以为我免费迁移到他们确认可以安装 FreeBSD 的机房，一番测试后，我选择了 Seattle 的机房。\n\n虽然这番操作耗费了我数天的时间，但我的体验并不算差，因为客服回复的速度很快、也并没有推卸责任，也展现出了专业性。\n\n> 这里就不得不踩一下 WebHosting24 这家服务提供商了，这家虽然在重装系统列表里可以直接选择 FreeBSD 13 进行安装，但是在安装完成之后我发现 FreeBSD 系统没有 IPv6 的地址，于是我发工单询问客服，客服居然说他们的技术支持仅限于 Linux 系统，不针对 FreeBSD，所以需要我自行处理这个问题，如果需要他们提供帮助的话，我需要每十五分钟额外支付二十欧元的咨询费！\n\n## 开启 BBR 拥塞控制算法\n\n> BBR 拥塞控制算法能够极大程度上地改善网络状况比较差时的吞吐量（尤其是在远距离传输时），因此它特别适合身在中国大陆地区但是 VPS 却在太平洋另一边的用户使用。\n\nBBR 是一种拥塞控制算法，但是在 Freebsd 的实现却并没有包含在系统拥塞控制模块里，而是另一个 TCP stack，因此我们不能像 Linux 那样直接用 `sysctl` 指定一下 `tcp_congestion_control=bbr` 就行，而是需要自行载入 BBR 模块并重新编译内核来实现。\n\n> 我也不清楚为啥 Freebsd 开发组不默认将其集成在内核中，可能美帝的网络连接质量已经很高了，大多数用户已经不太需要 BBR 了吧～、\n\n### 下载内核\n\n我安装 Freebsd  13 时执行的是最小安装，没有包括内核的源码，所以需要自行下载：\n\n```bash\n>>> wget ftp://ftp.freebsd.org/pub/FreeBSD/releases/amd64/13.0-RELEASE/src.txz\n```\n\n内核里面的文件已经包含了目录结构，所以直接将其解压到根目录即可：\n\n```bash\n>>> tar -C / -zxf src.txz\t\n>>> cd /usr/src/sys/amd64/conf \t# 进入内核目录\n>>> cp GENERIC GENERIC-BBR\t\t\t# 创建 BBR 内核\n```\n\n### 配置内核参数\n\n使用编辑器打开 `GENERIC-BBR` 文件，然后将 `ident` 参数的值由默认的 `GENERIC` 改成 `GENERIC-BBR`，然后在下面加上 `options` 和 `makeoptions` 参数，见下：\n\n```ini\nident           GENERIC-BBR\noptions         TCPHPTS\nmakeoptions     WITH_EXTRA_TCP_STACKS=1\n```\n\n保存后退出。然后新建 `/etc/src.conf` 文件并填入以下内容：\n\n```ini\nKERNCONF=GENERIC-BBR\nMALLOC_PRODUCTION=yes\n```\n\n### 编译并安装\n\n```bash\n>>> /usr/sbin/config GENERIC-BBR\t# 注意此时目录还应该在 /usr/src/sys/amd64/conf\nKernel build directory is ../compile/GENERIC-BBR\t# 执行完后，就应该切换到对应的目录了\nDon't forget to do ``make cleandepend && make depend''\n```\n\n看，还贴心的告诉你内核的 build 目录在哪，以及告诉你怎么编译依赖～编译依赖完成之后，我们使用 `make -j2` 来正式开始编译内核。这个编译的过程可能持续十几分钟，具体取决于 VPS 的 CPU 性能。我的 CPU 是 2 核心的 AMD 3900X，这个过程耗时了十来分钟。\n\n编译完成之后，使用 `make install` 来安装新内核，然后重启。重新登录之后，在欢迎信息里应该就能看到内核变成了 `GENERIC-BBR` 了。\n\n### 开启 BBR\n\n使用 `kldload tcp_bbr` 来载入 BBR 模块。 不过直接这样载入在重启后会失效，需要将 `tcp_bbr` 加入 kld list：\n\n```bash\n>>> sysrc kld_list+=\"tcp_bbr\" # 或者直接在 /etc/rc.conf 文件末尾加上 `kld_list=\"tcp_bbr\"`\n```\n\n随后就可以开启 BBR 了：将 `net.inet.tcp.functions_default=bbr` 写入 `/etc/sysctl.conf` 文件，然后重启即可。重启之后，`sysctl net.inet.tcp.functions_default` 输出的是 bbr 就表示已经开启成功。\n\n贴一个对比测试吧，下面的 `OUTPUT` 文件是我在 Freebsd 开启 BBR 之后的速度；下面的 `1000MB.text` 文件是服务提供商在 Seattle 机房提供的测速文件（默认是没有开启 BBR 的）～\n\n![image-20210909233756955](https://p9.toutiaoimg.com/img/tos-cn-i-siecs4i2o7/2e9d630ed0a84a0f9c930039f97a0744~noop.image)\n\n## 配置 Jails\n\n[Jails](https://docs.freebsd.org/en/books/handbook/jails/) 是 Freebsd 中提供的容器化技术，可以类比成 Linux 里的 Docker，但是会比 Docker 使用起来麻烦一点，因为 Jails 有许多配置项都需要手动配置（网络配置、磁盘划分等），就像重新安装一个 Freebsd 系统一样。\n\n### 配置网卡\n\n由于 IPv4 地址的匮乏，大多数的服务器提供商都**不会**提供一个 IPv4 的子网段供我们使用（IPv6 地址倒是一般都会分配一个 /64 的网段），因此我这一步会将 Jails 的网络配置成 NAT 模式：所有的 Jails 出口共用一个公网的 IP（即提供商分配的 IP）。\n\n首先创建一个虚拟网卡分配给 Jails：在 `/etc/rc.conf` 里面加上两行：\n\n```ini\ncloned_interfaces=\"lo1\"\nifconfig_lo1_alias1=\"inet 10.6.0.1/26\"\t# /26 的子网足够用了\n```\n\n然后使用以下的命令让配置生效：\n\n```shell\nservice netif restart\n```\n\n> 注意这里填写的 IPv4 地址段要写当前没有被占用的，否则在运行命令之后你可能就连接不上你的服务器了，不过重启之后可以恢复。\n\n### 配置主机 NAT\n\n我们开启 `pf` 组件用来映射主机流量到 Jails 里。在 /etc/rc.conf 里写入 `pf_enable=\"YES\"`，然后我们创建 /etc/pf.conf 文件并填入：\n\n```ini\next_if=\"em0\"\nIP_PUB=\"xx.xx.xx.xx\"\n\nnat on $ext_if from lo1:network to any -> ($ext_if)\n\n# 下面配置可以将主机对应的端口直接转发到 jails 里\nTROJAN_PORT=\"{443}\"\nrdr on $ext_if proto tcp from any to $IP_PUB port $TROJAN_PORT -> \"10.6.0.3\"\n```\n\n随后启动 pf：`service pf start`。\n\n网络相关的配置已经完成，接下来可以正式开始配置 Jails 了。\n\n### 配置 qjail\n\n刚刚提到，jail 的配置很多都需要手动管理，qjail 可以让 jail 的创建和配置更方便一些，它内置了包括 jails 的创建、删除、重启、备份等基本的子命令。使用 `pkg install qjail` 来安装。\n\n安装完 qjail 之后，我们用 `qjail install` 来创建我们 jail 的模板，其实也就是下载 FreeBSD 的 base.txz 组件，它是一个可运行的最小 FreeBSD 系统。\n\n接下来我们就可以创建 jails 了：`qjail create -4 10.6.0.2 -n lo1 test`[^1]，-4 表示的是 IPv4 地址，可以在[配置网卡](#配置网卡)这一步填写的范围里面随便挑一个[^2]，记得要挑没有被占用的。\n\n[^1]: 这里的 `-n lo1` 参数非常重要，因为 qjail 帮我们简化了很多 jails 的配置，这也导致某些配置可能并不符合我们的期望，比如如果这里不加 -n 参数的话，这个地址就会被添加到默认网卡上，而不是 lo1，所以我们这里需要指定为 lo1 网卡添加地址\n[^2]:我们在前一步配置的时候只标注了子网范围，而在我们创建 jail 的时候实际上是给这个字网内加了一台机器，而 pf 的规则并不会主动去应用于新加入的字网的机器，因此我们创建完新的 jail 之后需要重启 pf 进程\n\n接下来我们使用 `qjail start test` 来启动这个 jail，并使用 `qjail console test` 进入这个 jail。\n\n进入 jail 之后，可以使用 `telent` 或者 `host` [^3]命令来测试网络连通性。\n\n[^3]:Jails 相比主机有诸多限制，比如默认 jails 内部不支持 raw_sockets，也就是说你无法使用 ping 命令来测试网络连通性，当然：`qjail config -k jail_name` 命令可以开启 jail 对 raw_sockets 的支持\n\n## 更新 TLS 证书\n\n我目前有一些网站没有使用 Cloudflare 代理，比如自己搭建的 Trojan 翻墙服务，用 Cloudflare 会大大拖慢访问速度，而 Trojan 又是需要 TLS 证书伪装的，故而我专门创建了一个 jail 用来创建并更新 TLS 证书。\n\n### 安装 acme.sh\n\n```bash\ncurl  https://get.acme.sh\n```\n\nacmes.sh 默认会安装在用户根目录的 .acme.sh 文件夹内。\n\n### 配置 DNS 验证\n\n申请 TLS 证书的时候，有两种常见的方式验证域名的所有权：\n\n1. HTTP 的方式：这种方式要求你要申请的域名已经搭建好了一个网站，并且要在网站根目录放一个验证文件，这种方式的要求有点「苛刻」：需要安装 Nginx、Apache 等 Web 服务，或者服务器的 80 端口是空闲的（让 acme.sh 自己伪装 Web 服务），如果是在普通主机上到也没那么麻烦，毕竟都是一次性操作；可是要在 Jails 里面运行 Web 服务的话，必须得在外部主机开启端口映射的服务，可我又不可能将主机的 80 端口映射到运行 acme.sh 的 jail 里，所以每次续签证书还得要手动切换映射服务，这太麻烦了\n2. DNS 的方式：幸好， acme.sh 还提供了另一种的方式来验证域名的所有权，只需要获取域名解析商处对应于明的的 Token 等信息写入环境变量，acme.sh 会自动创建一条对应域名的 TXT  Record 来验证所有权，这种方式好在完全没有外部的依赖，在 jail 和主机运行没有任何区别。\n\n```shell\nsetenv CF_Token=\"xxxxxx\"\nsetenv CF_Account_ID=\"xxxxxxx\"\nsetenv CF_Zone_ID=\"xxxxxx\"\n\n~/.acme.sh/acme.sh --issue --dns dns_cf --server letsencrypt -d example.com\t# 生成证书\n~/.acme.sh/acme.sh --install-cert -d example.com --key-file /cert-path/key.pem --fullchain-file /cert-path/cert.pem\t# 安装证书\n```\n\n这部分完成之后，acme.sh 就会创建并自动更新证书了。\n\n### 证书的应用\n\n此时还剩下一个最后一个问题：因为不同的 jail 的文件系统是相互隔离的，那么在这个 jail 里生成的证书如何让其他的 jail 能使用呢？\n\n不过还好，在主机端可以访问所有的 Jails 的文件系统（在 /usr/jails 里），所以我们可以把运行 acme.sh 的 jail 里的证书目录直接挂载到使用证书的 jail 的文件系统里：\n\n```shell\nmount -t nullfs -o ro /usr/jails/acme-sh/cert-path/ /usr/jails/trojan/root/certs\n```\n\n第一个地址是源目录（运行 acme.sh 的 jail 的文件系统），第二个地址是目的目录（使用证书的文件系统）。\n\n这样我们就可以在对应的 jail 里的 `/root/certs` 目录看到证书的文件了。\n\n参考：\n\n- [免费TLS证书进阶指南：acme.sh letsencrypt 和Cloudflare DNS API](https://cyfeng.science/2020/06/28/advanced-thinking-about-free-tls-license/)\n- [FreeBSD jails configuration](http://kflu.github.io/2017/02/06/2017-02-06-freebsd-jails/)\n- [实录：FreeBSD开启BBR](https://www.cnblogs.com/rn7s2/p/15212124.html)"},{"title":"Type-Length-Value Encoding Scheme Practice","subtitle":"","url":"/posts/tlv-encoding-practice/","date":"2021-05-05T06:04:02.000Z","updated":"2021-05-04T20:04:02.000Z","category":"实验室","tags":["TLV","Encoding","Protocol","IPC"],"content":"In the previous post, I introduced how to use Elixir to write a rate limit tool. After that, I was planning to integrate it with the[ DIEM-API](https://github.com/WincerChan/DIEM-API/). In this way, my API System doesn't need to depend on Redis. However, DIEM-API is written in Golang, and I have not decided to re-write it in Elixir in the short term. Besides, I wrote a[ search api](https://github.com/WincerChan/Search-API/) for my blog using Rust recently. Therefore, I need a cross-platform solution to address communication issues between Golang, Elixir and Rust.\n\n<!--more-->\n\n## Why not use other tools\n\nCurrently, there have been some ways to communicate between different processes (e.g. Pipe, Signal, Message Queue). But in fact, they have many limitations. Pipe and Signal require communication processes to be on the same machine. Message Queue and GRPC may be better solutions, but introducing new dependencies will complicate the system further.\n\nTCP is another potential solution, but it is only able to transfer binary data. In other words, there is no simple way to decode data into typed parameters after receiving it from sender. **RE**dis **S**erialization **P**rotocol (RESP) is a request/response protocol over TCP, with various types of response (e.g. *status reply*, *error reply*, *integer reply*, *bulk reply*) but only one parameter type (*string)*. However, function calls have only one response type but various types of parameters, which is the opposite to RESP. Therefore, RESP can not be used for inter-process calls.\n\nAnother way I tried is using separators between multiple parameters, which also introduces two new problems:\n\n1. Performance: splitting and casting string has penalty on performance; ([benchmarks](#benchmarks-golang))\n2. Accuracy: if the parameter contains characters that are the same as the separator, it is not able to distinguish them.\n\nAlthough these ideas don’t work, they gave me some inspiration. I decided to transfer the length of parameters and the typed parameter together.\n\nThis is *Type-Length-Value* (hereinafter referred to as **TLV**).\n\n## Introduce TLV\n\nTLV is an encoding scheme. It must be based on one communication protocol, like: TCP, UDP or Unix Domain Socket.\n\n![TLV](https://inews.gtimg.com/newsapp_ls/0/13492287563/0)\n\nA TLV element should consist of three parts (Figure 1):\n\n1. **Type**. It represents raw value’s type before encoding. Usually, we define an enumeration for these types. We use ones-digits to represent basic types, such as `0x1` for String, `0x2` for Integer, `0x3` for Float, etc.. We use tens-digits to represent compound types, such as `0x1[any digit]` for List, `0x2[any digit]` for Hash. The enumeration can also contain types which are unique to programming language, such as Atom type in Elixir.\n2. **Length**. It represents raw value’s byte length after encoding. However, it is useless for Integer and Float, because these types have fixed byte length (usually 8 bytes) after encoding.\n3. **Value.** It represents the raw value’s bytes after encoding. It can also nest in another TLV element when Type is a List or Hash (Figure 2). We can decode this part recursively.\n\n## Implementation Details\n\nIn this section, I will introduce how I implemented the encoding and decoding of TLV elements.\n\n### Type\n\nThis part should occupy **1 byte / 8 bits**. Lower 4 bits represent the basic type, which can cover 16 basic types. Higher 4 bits represent compound type, which can also cover 16 compound types:\n\n![one](https://p3-tt-ipv6.byteimg.com/origin/pgc-image/af64297ef6a9441fbcd6c289bfff0fad.webp)\n\n1. If raw value is a basic type, then higher 4 bits should all be 0.\n2. If raw value is a compound type, we should only use higher 4 bits, regardless of lower 4 bits.\n\n### Length\n\nThis part should occupy **4 bytes / 32 bits**. It can represent a value whose length up to 2 ** 32 bytes(about 4 GB).\n\nFor Integer and Float, higher 3 bytes are 0s, lowest byte is 8, which means Integer and Float can be represented by 8 bytes.\n\nFor String and compound type, we need to calculate the length of value first, and then convert the length to bytes.\n\n> Besides, we can use `binary.BigEndian.PutUint32` function for Golang, use `<<int_value::integer-32>>` for Elixir, use `.to_be_bytes()` for Rust.\n\n### Value\n\nThis part should occupy at least **8 bytes / 64 bit** (except Bool).\n\nFor Integer, we can use the above method to convert it to bytes; For Float, we can use math.Float64bits to convert it to int64, then convert int64 to bytes. For Golang, Rust and Elixir, String is a byte array (char array), which can be converted to bytes directly.\n\nIf there are nested elements, they must be encoded first, which can be processed recursively (in Elixir) or iteratively (in Rust and Golang). Same as decoding. And we should consider the case where a List element contains different types, which is allowed for dynamically typed languages (Python, Elixir) and some weakly typed languages (Golang can use []interface{}), although using reflection will cause more overhead. \n\n## Appendix\n\n### Benchmarks (Golang)\n\nI wrote some bench tests for TLV (encoding, decoding) and Separator + strings (mentioned in the [previous section](#why-not-use-other-tools) ):\n\n```bash\ngoos: darwin\ngoarch: amd64\npkg: DIEM-API/rpcserver\nBenchmarkToString-8      1000000               298 ns/op              32 B/op          3 allocs/op\nBenchmarkTLVEncode-8     1000000               130 ns/op              96 B/op          6 allocs/op\nBenchmarkStringTo-8      1000000               115 ns/op              48 B/op          1 allocs/op\nBenchmarkTLVDecode-8     1000000              14.9 ns/op               0 B/op          0 allocs/op\nPASS\n```\n\nYou can find the source test codes in [this repo](https://github.com/WincerChan/DIEM-API/blob/master/rpcserver/).\n\n### Implementation Code\n\nI used Elixir, Golang and Rust to implement TLV Encode Scheme, you can check the following repositories to view the source code:\n\n- [DIEM-API](https://github.com/WincerChan/DIEM-API/tree/master/rpcserver) for Golang implementation;\n- [search-api](https://github.com/WincerChan/search-api/tree/master/src/ipc) for Rust implementation;\n- [Ral](https://github.com/WincerChan/Ral/tree/master/lib/ral/server) for Elixir implementation."},{"title":"迟来的 2020 年终总结","subtitle":"","url":"/posts/summary-of-2020/","date":"2021-03-30T16:24:02.000Z","updated":"2021-03-31T13:24:02.000Z","category":"碎碎念","tags":["2020","年终总结","工作","生活"],"content":"不知出于什么原因，前几个月对写博客这件事情始终提不起太多兴趣和动力，连一年一度的年终总结都鸽了三四个月。其实早在去年十二月底时，我就开始写年终总结了，可似乎总找不到写作的「感觉」——对着屏幕脑子一篇空白，好不容易琢磨了一个开头出来也不甚满意，后来便不了了之了。\n\n<!--more-->\n\n就当我以为这篇文章要一「鸽」到底时，最近居然找回了之前恨不得三天写一篇博客的状态，可眼看 2021 年都过了四分之一了，还写 2020 年的年终总结似乎有点说不过去…好在女朋友说：「没关系，上市公司的年度财报一般也都是次年的 3 月份发~」，我想了一下，觉得很有道理——于是便有了这篇姗姗来迟的年度总结。\n\n由于最近的几篇博客都是偏向技术方面的，所以本文则会更偏向生活方面的记录，技术可能仅会选择性的提一下。\n\n## 在武汉\n\n虽说我对奇安信有诸多不忿，但抛开工作上的事情不谈，那段时光我还挺怀念的——主要是怀念和同事们相处，一起在人均三十多的小餐馆里面吃饭、喝酒，苦中作乐。\n\n在 2019 年的最后一天，我照例和小伙伴们在公司附近的学校食堂里吃饭，我点了一份牛肉小火锅，在吃的时候我打开手机刷微博，刷到了「武汉出现不明原因肺炎」，当时也没当回事，只是和同事说了一下，提醒他注意点（因为他租的房子正好在江汉路），随后另一名同事说晚上想去江滩跨年并问我们去不去，我本身也不是一个喜欢热闹的人，加上刚刚看到的新闻，摇了摇头拒绝了。\n\n之后两周，疫情逐步「发酵」，新闻上隐有愈演愈烈之势，但也没有对现实生活产生多少影响，该上班还是得上。且由于当时我已有离职之心，想着年后回武汉便准备辞职，因此在离开武汉的前一天晚上还去江汉路找朋友吃饭，当时地铁上和商场里很少有人戴口罩，不过我因为比较惜命还是戴上了公司发的口罩（之后想想还真挺后怕）。之前文章里提过，我在积攒了不少调休，因此我在过年前一周就回家了，离开武汉的当天是工作日，一个在公司上班的同事偷溜出来送了我一下，我还挺感动的，可惜之后我们也没再见过了（不过现在也经常联系）。\n\n## 又重逢\n\n早在月初时，便和几个初中同学约好了一场聚会。等到聚会前夕时，疫情已经变得有些严重了，我爸妈都劝我别去，但我还是去了——所幸我去了，遇到了我初中时代暗恋的对象，现在的女朋友。\n\n再见她时，觉得她依旧那么有气质，而我的心境仿佛过了快十年都没什么长进——与她不经意见间的眼神交流都会让我紧张。饭局开始，自然而然地聊起了各自的近况，聊到她时，她似乎有些局促，说她毕业后就一直在家待着申请国外的研究生，是从大三开始就有的想法，因此放弃了保研的资格。顺着聊到选择研究生的方向时，话题不可避免的转向了我——她想从事数据分析方面的工作，最近在上 Coursera 上的机器学习课程，而我恰好对这方面比较擅长，于是我说我之前正好上过这门课，「喔～～」饭桌上响起大家心照不宣的声音——就好像初中时那样。\n\n是的，即使我对初中时期的大多数事情已经淡忘，但和她有关的事情却记得很清晰。当时，我喜欢她这件事不知怎么就传遍了班上，以至于同学们总喜欢起哄——提到她时，总会有人小声说一句我的名字，接着便是哄堂大笑，我总会红着脸不说话，内心却有些欣喜。好在她是一个不怎么在乎这些「流言」的人，反而会经常问我数学题，而其他人看到她问我数学题时，便会说一句：「哦～又来问数学题了呀」，而她置若罔闻，待我解释完之后才面不红心不跳的回到座位上。当时的我挺希望有更多同学起哄，就好像起哄的人多了就能帮我说出我心里不敢对她说的话一样。\n\n之后的事情我在[高中篇回忆里](/posts/5fdce618/#错愕)有提到一些，中考结束时，我没有考上省重点，于是爸妈便想着参加并通过暑假夏令营考核的方式来进入这所中学，巧的是她与我被分到了同一个班里面，似乎她也是因为中考发挥失常。当时的我情绪有些低落，即使因为数学比较好能进入夏令营，在结营考试时却因为英语拖了后腿，无缘进入这个班级。在那之后，我在普通班里看着她在快班里成绩越来越好，而我只能在一本线外徘徊，虽然很不想承认，但我和她之间的应当是越来越远了。\n\n高考结束时，她是她们班上的第一名，登上了我们学校的报纸，我犹豫再三，仍是点开了她的对话框，将她上报纸的版面拍了一张照片发给了她，想象中的热烈情绪并没有出现——毕竟我和她已经三年没有说过话了，心里默叹一口气，还是把这份感情埋在心底吧。\n\n饭局结束后，我主动加上了她的微信，而几年前压抑在心中的感情突然有些蠢蠢欲动了，但我还是忍住了没有说出口，给她发送了一个课程的链接并告知有问题我可以随时解答后，我们结束了这场对话。\n\n在随后的三四天里我过得很煎熬，很想问她是否有在看我发给她的课程链接，如果看了的话是否遇到了什么问题？可又怕她觉得唐突。就这样到了第五天，她终于发过来了一个问题，有关逻辑回归的，具体问题我已经记不太清楚了，借此机会我和她聊了一下午，尽兴收场。随后几天，我们每天都会聊，虽然话题总是离不开学习，但能明显感觉和她之间的距离拉近了不少。之后我们的关系一直稳中有升，直到我准备提离职的那一天晚上。\n\n## 辞职时\n\n前文有提到过，我原本计划是在年后就直接辞职的（毕竟过年 7 天不上班还有工资拿），但因为疫情影响，以及公司随后宣布进行为期最少两周的在家办公让我决定暂时观望一下，想来不用去公司应该会轻松一些。后来的事实证明我真是太 Naive 了，也把我 Leader 想得太善良了——节后工作的第一天我们就开会开到了晚上 11 点，「办公室工作只是 996，远程工作就变成了 007」这话一点不假。\n\n随后几天公司各种奇葩规定仿佛在秀下限，日报还不算什么，甚至要求「小时报」，我对公司积攒的怒气值也终于在那天达到了顶峰。那天上午，Leader 忽然对我说，下午有一个会（是和我之前去上海出差的项目相关的）由我来主持，于是我从下午五点开始开会，一直开到了晚上八点，而且我作为负责人一直在讲话自然是没有机会吃饭的。会议结束后，我走出了房门，和家人坦白了我今天就要辞职的决定，~~耶稣也拦不住我，~~他们见我态度坚决，也没有多说什么。那晚由于我在写辞职信，所以顾不上和她聊天，写完辞职信时，已经是十点半了，我迫不及待的点开了她的聊天框，给她看了看我的辞职信——后来才知道那天她一直在等我找她聊天。\n\n在发给她看之后，我心里突然有些小忐忑：我担心她会像我其他的朋友一样不认同我的决定，而是希望我多忍一会 blabla 的，等到时机成熟一点、或者找到了下家之后再辞职；所幸刚说完我的决定之后，她就称赞我在这件事情上的果断，当时我特别开心能得到喜欢的人的理解和支持。\n\n于是乎，3 月 6 号那天晚上，借着徐佳莹的歌词，我表白成功了——那天晚上我激动得没怎么睡着。\n\n## 修养中\n\n离职之后的那段日子，我在[这篇博客](/posts/ee6b678/)里写的比较详尽，感兴趣的小伙伴可以移步观看，我就紧接着离职的两个月之后讲吧。\n\n## 找工作\n\n辞职后的两个月里没少被家里人数落：哎呀，你怎么还不去找工作啊；总在家待着怎么行啊，你不知道空闲时间越久就越找不到工作啊（还好有女朋友一直在身边鼓励我）……总之，无论是处于父母的唠叨还是我自己本身的计划，六月初的时候，我开始步入找工作的阶段了。首先是在 BOSS 直聘找了两家中型公司投了一下，结果都是已读未回，在这之后我就干脆放弃了招聘软件这条路，开始转向官网投递。\n\n官网投递的公司包括了之前对工作氛围我很认可并向往的豆瓣；以及工作理念我很看好的 LeanCloud。可能由于许久没面试，又是特别重视的公司导致有些紧张：豆瓣一面的几个问题答得都不是很好（稍复杂一点的数据库设计我真是一团糟），而 LeanCloud 则是因为技术栈的问题，投递简历后虽然得到了回复说我潜力很大（大概类似「好人卡」之类，拒绝你总要找个好一点的理由），但没有后续面试的机会。\n\n于是我又开始在 V2EX 上的招聘板块寻找帖子投递简历，先开始找的是一个比较小的初创公司（墨刀），一下午的时间就通过了两面，面试其实也就是和前后端的负责人分别聊聊天，过程还是挺愉快的，但是聊到福利环节的时候，因为公积金等缴纳基数只有 5000，所以即使技术栈我很感兴趣（Ruby）、交流也很愉快，在考虑良久之后还是选择拒绝了。\n\n找工作时，我**特意**避开了知名的大公司，因为来自上一家公司的阴影——我不想加班了，而据我在脉脉上的观察，大公司加班都很严重。而在找工作开始过去了快两周时间，两周时间说短不短说长也不长，但给我造成的压力已经有一些大了，心里的信念也有一些动摇。原来在遭到挫折之后，自我认知真的会不断的降低：会怀疑是否错估了自己的能力、最初的理念是否有失偏颇等等。而如果一个人在每次遭遇了挫折之后就开始不断的怀疑、调整自己的信念，我也不清楚最后他会变成什么样子，可我不想这样——「你尽可以消灭他，可就是打不败他」。\n\n就这样，我抱着十分矛盾的心理，讲我的遭遇告知了一位在博客圈「结识」的长者，并试图从他这里得到一些人生经验。其实发完之后我有些忐忑，毕竟我和他素未谋面，说是「结识」，其实仅仅是博客加了友链、Github 互 Follow 了而已。因此在仅几个小时，就收到了他长达三千多字的回复时，我感动得不成样子。而我也意识到了之前想法有些 Naive，事情并没有我想象的这么严重，都是我太钻牛角尖罢了。\n\n在这之后就是现在的公司了，也是在 V2EX 上翻到的招聘贴，不过录取的经历却颇有些一波三折：一面发挥不是特别好，有几个偏底层的问题没有回答上来，其中有的是因为没有 GET 到面试官的点，有的是因为确实不会；所以之后几天得到的回复是没有通过面试，谁知过了两周之后面试官又说没有找到更合适的了，想问问我愿不愿意继续后面的流程……于是，在八月初时，终于结束了在家待业四个多月的日子，开始了一段新的旅程。\n\n## 入职后\n\n之前几个章节都是在描写生活方面，本节就稍稍往技术上扯回一点吧～\n\n还是按照时间顺序聊吧，首先说说 GraphQL。我认为 GraphQL 就像是 ElasticSearch 一样，公司级别的产品会选择深入使用或者集成，因为它对于越大、越复杂的数据结构就越有优势，但是对于个人开发者而言，甚至都不会想到拓展这方面的技能；GraphQL 最大的优点就在于它对于复杂的数据结构非常具有表现力优势，比如图系统（从名字也可以看出），因为它可以非常方便的处理嵌套多层的数据，只需要编写对应的 Resolver（或者干脆配合 DataLoader 使用），各种嵌套字段的会由 GraphQL 自动寻找对应的 Resolver，然后解析数据再塞到 JSON 里。\n\n在熟悉了 GraphQL 之后，紧接着就是试图将图系统的同步 API 改写成异步 API（本文有[详细的描述](/posts/c12de45e/)），这一过程极大加深了我对异步以及 Python 的历史包袱的认识。以及在异步 HTTP 客户端调用同步 API 服务器时，大概率是会出现问题的——异步 IO 里一个进程同时监听了多个 fd，每个 fd 都对应了一个发送的请求，而同步服务器只能一个一个的处理这些请求，所以请求多了，要么把客户端本机的 fd 都用完了，报 `too many open files` 的错误，要么是服务器处理不过来了，只能选择舍弃掉一些连接，这时就会报连接失败的错误，所以及时关闭连接很重要。\n\n随后就是设计了一套用户登录的系统，主要是认证的设计，使用了 Refresh + JWT 双 Token 的设计，让 Refresh Token 弥补了 JWT 无状态的缺点（[这篇文章](https://hasura.io/blog/best-practices-of-using-jwt-with-graphql/)真的写的非常好）。\n\n## 书影音\n\n按道理来说，今年在家休息了四个多月，电影和书籍应该看了不少才对，可恰恰相反，可能是因为在家时有着找工作的压力，虽然有着完整的时间，但却没有什么观影的心情；而在找到工作之后又正好反过来了，有观影的心情却只剩下了碎片化的时间。好在我也已经看开了，不再去追求什么一周看一本书、两部电影之类的目标了。\n\n不过也简单总结一下吧，剧集方面：之前看过《黑袍纠察队 1》，很喜欢，所以对《黑袍纠察队 2》的喜爱自然是水到渠成的（只要续集不是太烂，我都会很喜欢看）；《想见你》则是我第一次与女朋友一起看的爱情剧，虽然是爱情剧，但是里面的情节引人入胜程度丝毫不逊色于悬疑片、《王国 2》同样是包含了一部分《王国 1》的偏好，加上僵尸、宫斗题材我非常喜欢；动漫最喜爱的是《异度侵入》，我和女朋友从下午开始一直看到了凌晨，欲罢不能～；而电影方面，因为我想寻求感官上的刺激，所以恐怖电影看得比较多，反而没什么特别印象深刻的。\n\n书籍方面，虽然只看了寥寥 4 本书，还都是技术方面的（在家待业时真的很难静下心来阅读文学类书籍），但是有一点我很满意的是看完了两本英文的书籍——《Elixir in Actions》（让我入门了 Elixir 语言）、《Kubernetes in Actions》（对 K8s 的理解加深了），总算完成了很久以来的梦想，不过可能是因为《in actions》系列的书写的比较通俗易懂，像《Algorithm, 4th Edition》我尝试了数次还是一页都看不下去。。\n\n---\n\n如果让用一个词来总结我的 2020 的话，我想应该是「幸运」。很幸运在从奇安信离职前交到了几个可以成为好朋友的人；很幸运重逢了少年时期的暗恋对象并成为了我的女朋友；很幸运在自我怀疑时有「长者」传授了人生经验；很幸运找到了一份非常喜欢的工作……还有许多，就不一一列举了。\n\n很幸运，很幸运让我遇到了你们。"},{"title":"博客搜索功能正式上线","subtitle":"","url":"/posts/blog-search-is-ready/","date":"2021-03-21T02:33:00.000Z","updated":"2021-03-21T02:33:00.000Z","category":"博客栈","tags":["搜索","博客","Tantivy"],"content":"博客建站以来，我使用过 Hexo 和 Hugo 两个框架，它们生成的博客在本质上都属于静态博客，对于「搜索」这个与数据库关系紧密的需求，显得有些力不从心——不过也并非没有办法：比如主流的解决方案（这里不考虑使用 Algolia、Swifttype 等第三方服务）就是预先生成一个文档（包括所有的博客数据），然后在浏览器端加载此文档再通过编写 JavaScript 代码进行搜索匹配，最后再输出结果。\n\n<!--more-->\n\n这种方案有几个缺点：\n\n1. **数据保存在客户端**，每次搜索都需要请求一次，这很不优雅（即使缓存在了浏览器端）；\n2. **不支持稍复杂的表达式**，比如按照时间过滤、指定 Tags 或者 Category（当然你也可以自己实现）；\n1. **不支持分词**，因此精确率会降低，相比前两点，这一点我其实不是很在乎，也有办法可以解决（本博客的关键词搜索方案就是采用逐字匹配的 : )\n\n当然也有优点：搜索不同的关键词不需要额外发送请求了，因此搜索的响应速度会更快……\n\n但这总归算不上一个优雅的解决方案。\n\n因此我很早（大约两三年前）就想为博客构建一个真正的搜索引擎，当时也研究过一些方案：使用 PostgreSQL 加上一些插件（因为当时已经在使用它作为一言的数据库了），后来觉得这些要是跑在我 512M 小内存的主机上实在是有点太为难它了，于是便搁置了；最近在新购置了一个大内存的 VPS 之后，也终于可以将这个想法实现了。\n\n## 开源技术的选择\n\n之前使用 PostgreSQL 作为解决方案，如今看来不是很满意：并非是 PostgreSQL 不好用，而是我想将数据库依赖从 [API 系统](https://github.com/WincerChan/DIEM-API)中删掉——因为数据库只是存放了一言（我还专门为随机读取一言写了一个[存储过程](https://github.com/WincerChan/DIEM-API/commit/d9345155d6648f7864d67878eaa278857129a7ad)），而查询也只是简单的 SELECT 操作，嵌入式数据库也足够用了，减少了依赖的同时性能还更好；同理我将 Redis 的依赖也删掉了，只是限流操作，我完全可以使用[别的方案](https://github.com/WincerChan/Ral)来代替。究其原因，其实是**我想在系统设计的复杂度上做减法**，尽可能谨慎的为系统引入新的依赖——如果已经引入了，那就尽可能的去掉。\n\n因此我将解决方案框定在了基于编程语言构建的搜索引擎上，这一次我没有选择自己造轮子：一是搜索引擎涉及的技术太复杂，我没有这么多业余的时间；二是业界已经有不少完善的解决方案，没必要自己造轮子了——这并非是我对搜索引擎背后的技术不感兴趣，等以后有空的话，我仍然会研究相关的技术。\n\n我对博客的搜索引擎有以下几方面的要求：\n\n1. 支持稍复杂的查询，比如像 Boolean Query、Term Query 、Regex Query 等可以组合起来查询；\n2. 可定制化程度最好高一些（这一点是非必须的），比如：我更偏向于 Lucene，而不是 ElasticSearch（仅举例，实际上我二者我都不会选）；\n3. 内存占用要尽可能的小，运行起来要尽可能的稳定，毕竟要 7*24 小时运行；\n4. 支持按照关键词对搜索结果高亮。\n\n综上，我选择了 [Tantivy](https://github.com/tantivy-search/tantivy)——支持复杂的查询以及对搜索结果的高亮；虽然没有提供开箱即用的配置，需要集成到程序里使用，但这反而更方便我自定义 API 接口；Rust 的内存管理不依赖于运行时，少了 GC 的存在，会比 Golang 之流要更省内存，非常适合编写底层性能敏感的程序。\n\n## 编写 API 的吐槽\n\n其实符合要求的搜索引擎并不只有 Tantivy，至少 Go 编写的 [Bleve](https://github.com/blevesearch/bleve) 和 C++ 编写的 [Typesense](https://github.com/typesense/typesense) 也算符合要求，不过出于私心，我仍然选择了 Tantivy——我想通过它来学习 Rust。\n\n忘记之前在哪看到一句话：学习第 N+1 门编程语言的难度，会比学习第 N 门时要低一半。之前由于接触的编程语言太少了，所以也没什么感觉。如今在断断续续接触了 Python、JavaScript、Golang、Elixir（其他的诸如 SML、Lisp、Ruby 等虽然也用来写过作业，但没有完整的项目支撑，经验也不够，就不提了）之后，觉得这句话得加上一个前提条件：必须是具备相同编程范式或者类似语言特性得语言。\n\n因为在学习不同范式的编程语言时，之前所具备的思维定势反而会误导你：比如当你在习惯了使用动态类型带来的便捷之后，在接触这类静态类型语言的时候发现居然变量、函数还需要声明类型才能使用；当你在习惯了命令式编程的顺序分支循环等语句之后，突然发现函数式编程里面的变量是不可更改的，以及最简单的迭代过程居然还需要使用函数递归的形式来实现……\n\n>  说这么多，无非是想掩盖一下「我在学习 Rust 的过程中遇到了麻烦」的尴尬😅。\n\n说两个我在使用 Rust 过程中觉得不爽的点吧。\n\n### 全局变量\n\n在使用 Golang 要初始化数据库连接的时候，一般都会先声明一个全局变量 `DB`，在读取配置文件的时候初始化这个变量，这样就可以在其他的模块里导入使用了；Python（Flask）则一般是在初始化 app 的时候，提前配置好数据库的信息，再调用函数完成初始化，再通过导入 Model 层定义的 ORM 类进行查询操作。\n\n无论是 Golang 或是 Python 所采用的方法，其实关键点都在于**全局变量**，而 Rust **默认**（防杠）不支持全局的变量（即在堆上直接分配），虽然有第三方的 Macro 可以使用，或者使用 `unsafe` 包一下，也能勉强为全局的变量赋值，可用着第三方的库不感觉别扭么？还有在一片整洁的代码上冒出一个 `unsafe`，就好像时时刻刻提醒你「不要这么做，这么做不好」一样，可也没有更好的方法了。\n\nRust 为了内存安全性，在编译期间就已经决定好了变量何时回收，因此需要避免在堆上声明变量，因为这样变量的生命周期变得迷惑了起来，道理我都懂，不能这么做的原因我也明白、我也没有更好的方法，可用着不爽该吐槽还是得吐槽。\n\n### 空指针\n\nRust 同样也不支持空指针，而是使用独有的 `Option` 类型来避免空指针的存在。可在我看来，这个解决方法并算不上好——或者说 Rust 本身做的还不够好。比如，某类型被 `Option` 包了一层之后，就会失去原类型所派生的属性：原类型派生了 Clone，但是套上了 `Option` 之后就没有派生 Clone 了。而在 Rust 里经常会遇到 `.clone()` 某一个变量的情况，因为变量的生命周期只能属于一个 Scope，所以在调用函数的时候往往会将变量 `.clone()` 一份之后传入参数，而由于 `Option` 没有派生 Clone，还得自己写一个 `Option` 类型的 Clone 实现。\n\n虽然自己写一个 Clone 实现也不到十行代码，但这种编译器明显可以优化的着实没必要自己写。\n\n### 其它\n\n把时间戳转化为时间类型都得借助第三方库，懂得都懂……\n\n---\n\n在花了大约两周的业余时间之后，我完成了博客搜索引擎的搭建（[源码](https://github.com/WincerChan/search-api)），虽然吐槽归吐槽，但真上线运行的时候还是「真香」了，尤其是性能方面——一个 Tantivy 程序居然只占用了**几兆字节**的内存（是的，你没有看错），本机测试 QPS 也达到了 3000/S。\n\n> 吐槽得再厉害，可就冲着 Rust 的性能、稳定和内存占用……也只能捏着鼻子忍了 : ）\n\n## 设计实现\n\n### 关键词搜索\n\n在之前提到，不采用分词的话，虽然召回率（Recall）一定能达到都是 100%，但精确率（Precision）却会大幅下降。比如搜索「新鲜」，如果不采用分词算法的话，一般会直接将它按 Unicode 分成单个字符，也就是会查出所有匹配到「新」和「鲜」的文档，其中虽然也包括了作为词语一起出现的文档，但还会包含有这两个字分别与其他字组成词语的文档。\n\n为了解决精确率的问题，我使用了 Tantivy 提供的 PhraseQuery——它相比普通的 TermQuery 多了一个匹配单词序列的步骤。在「新鲜」这个词的搜索时，它只会搜索「鲜」这个字紧跟在「新」后面的文档，这自然就很大程度提升了精确率。虽然 PhraseQuery 可以解决在搜索词语时的精确率问题，但是如果只使用 PhraseQuery，针对包含多个词语的搜索又会显著降低召回率，因此关键词的搜索我采用了 TermQuery + PhraseQuery 组合实现。其中单个词语内部之间使用 PhraseQuery，而不同的词语之间使用 TermQuery。\n\n---\n\n关键词搜索的长度被限制在 38 个字符以内，超过的会被忽略；\n\n如果关键词以 `-` 符号开始，则意味着搜索不包含该关键词的文档。\n\n### 时间范围检索\n\nTantivy 的范围检索暂时不支持 Date 类型，因此我将博客的发布时间存为了 int64 类型的时间戳，由于不过对于接口调用，还是使用 ISO8601 的日历日期表示法来作为查询参数会更易理解一些。\n\n---\n\n如果想查询在某一时间范围的博客，使用：`range: startDate~endDate` 来查询（其中开始与截止均为 `yyyy-mm-dd` 的格式），如果只提供了 startDate，则 endDate 会被默认填充为当前时间戳；如果只提供了 endDate，则 startDate 会被填充为 0，二者之间使用 `~`（半角符号的波浪线）连接。\n\n如果指定了多个时间范围，则只会选定首次出现的作为范围，其余的会被忽略。\n\n### 标签以及分类查询\n\n标签以及分类的组合过滤我使用 TermQuery 来实现，其中标签以及分类的查询最多允许 5 个。\n\n---\n\n如果要查询某标签下的文章，可以使用 tags:标签名 来查询，如果想查询某分类下的文章，可以使用 category:分类名 来查询，注意使用的是英文的引号。\n\n**以上三种查询可以自由组合，但组合需要其中至少一个，否则被视为非法的查询。**\n\n## End\n\n快去[搜索页面](/search/)耍耍吧～"},{"title":"Hexo，再也不见","subtitle":"迁移博客至 Hugo 的一些牢骚","url":"/posts/migrating-from-hexo-to-hugo/","date":"2020-11-15T00:18:26.000Z","updated":"2020-11-15T00:18:26.000Z","category":"博客栈","tags":["Hugo","主题","设计","优化"],"content":"时间倒回到两年前，当时的我刚刚结束实习返校：闲着没事又开始折腾起博客，那时博客才更换成 SPA 没多久，由于 Bug 太多，主题各地方的细节我也不是太满意，体验了一段时间满足了新鲜感之后，心里忽然升起了一种对折腾博客的倦怠感。于是我还是换回了原来的 Material 主题，这一用就用了两年。\n\n<!--more-->\n\n直到前段时间，Github 提示博客仓库有好几个 CVE 的漏洞，作为一个强迫症，自然是想修复这些漏洞，然而我发现这些漏洞是博客使用的一些 Hexo 插件的依赖造成的，有些插件作者都不再维护了，于是我便想弃用掉这些插件，找寻新的代替品；可又转念一想，就算找到了代替品，这种情况也还是会发生——毕竟我不能指望每一个插件的作者都不弃坑。权衡利弊之后，我决定从根源处解决问题——**如果没有 Hexo，自然也就不会有插件依赖的问题了**，因此我弃用掉了从建站伊始就使用的 Hexo 框架，转而投向 Hugo 的怀抱。\n\n## Why Hugo?\n\nHugo 并不像 Hexo 提供各种插件用来增强或修改框架本身的功能，不过好在 Hugo 框架本身的功能已经足够的多了，我只需要在上面做一些修改即可——这也正好符合我的需求，根据我自己的想法定制、维护，也就解决了让我弃用 Hexo 最根本的问题。\n\n其实早在两年多前我就有尝试过将博客换成 Hugo，只是当时逛遍了 Hugo 的主题，发现没一个能打的，原因也很简单：Hugo 是基于 Golang 的，主题创作者大多是后端；Hexo 则是基于 Node.js，主题创作者大多数是前端，而主题样式则完全考验的是前端能力，因此 Hugo 主题的整体水平自然落后于 Hexo。\n\n如今，既然我已决定使用 Hugo，那么不妨自己写一个主题。\n\n## 主题的设计\n\n本次主题我选择使用 Tailwind 作为 CSS 框架，它与其他 CSS 框架的区别在于默认不提供各种元素的样式，而是将各种 CSS 的属性预先定义成 class 的形式，这样如果我想控制某个元素的样式的话，只需要将对应的 class 名称加入元素的 classList 就好，颇有点声明式编程的意思。同时，由于 Hugo 集成了 PostCSS 框架，几乎可以让 Tailwind 开箱即用了。\n\n在 JavaScript 方面，由于之前 Hexo 年久失修的插件给我留下的阴影，一开始让我使用它时我是拒绝的，可转念一想有些 JavaScript 的功能的确可以提升博客的体验（Lazyload，Workbox 等），于是开始秉持着「主体功能上不能依赖于 JavaScript」的原则来使用 JavaScript；由于 Hugo 已然内置了模块用于 CSS 的预处理和 HTML 的压缩工作，在发布时我只需要打包 JavaScript 就好，因此在模块打包工具上我选择了 Rollup.js——一个非常轻量的工具，只支持 JavaScript 文件的打包。\n\n## 博客的一些改进\n\n### 评论的加载\n\n一般来说，博客评论的加载有以下几种方式（以 Disqus 为例）：\n\n1. 最原始的方式：在用户进入文章页面直接加载 Disqus，但这会给页面带来非常多的额外请求从而拖慢加载速度，而且因为中国的局域网环境，会更显著地降低用户体验；\n2. 优化后的方式：默认不加载 Disqus 的评论，用户需要看评论时，点击按钮以加载评论，这种方式比上一种好很多，但也会给用户带来一次额外的点击操作；\n3. 将二者结合：用户进入文章页面时，先请求一个 Disqus 的配置文件，如果在给定时间内未超时，则自动加载评论；反之则需要用户手动点击按钮以加载评论，这也是我之前一直使用的方法，可这种方法仍然会拖慢页面的加载速度——如果给定的超时时间比较长的话，仍然会产生和第一种方式类似的问题；\n\n博客的实践是在第三种方式的基础上做了一点优化：当用户进入文章页面时，不请求配置文件，只有当页面滚动到文章底部的时候才发送请求配置文件来测试 Disqus 的连通性，这样当用户首次进入文章页面时，页面的加载速度不会有什么影响。\n\n### 文章的加密\n\n> 博客是否需要加密文章，以及需要加密文章的原因不在本文的讨论范围。本文仅讨论实现手法\n\n之前 Hexo 博客的加密是通过插件完成的，如今更换成 Hugo 之后，自然要自己造轮子了。其实加密博客的思路很简单，在编译成 HTML 的时候将文章原本内容使用 AES（或者其他的什么算法都行）加密后替换掉，在前端展示时，再让用户输入密码通过 JavaScript 解密就好。\n\n这里我踩了两个坑：\n\n1. Go 的加密库与 JavaScript 的解密库的兼容性问题，Padding 函数需要设置成同样的，以及当密钥长度不够时的填充规则也要一样；\n2. Hugo 的 shortcode 不支持 Shell 命令的[调用](https://github.com/gohugoio/hugo/issues/796)，因此我不得不采取一种非常别扭的方式：Hugo 生成 HTML 文件后，手动调用加密程序将指定的 HTML 文件中的内容替换再写入源 HTML 文件。\n\n也由于第二个坑的存在，在本地使用 Hugo Server 调试时是没办法测试加密功能的，不过好在每次博客部署都是通过 Github Actions，配置文件写好之后倒也没有特别麻烦，只是心里总是觉得有根刺儿一样不舒服。\n\n---\n\n除此之外还有一些小改进，比如：\n\n- 所有的动画都是使用 CSS 实现的，不依赖于 JavaScript；\n- 所有的 JavaScript 都是延迟加载的，等到页面所有资源加载完成才触发执行；\n- 所有图片都是 Lazyload 的，考虑到 RSS 订阅的用户，文章内部的插图没有使用 Lazyload；\n\n- ……\n\n## 主题的使用\n\n一开始设计博客主题的时候，并没有打算发布，只想自娱自乐，因此将许多个人偏好耦合进了样式中，我也不打算改了，直接把博客[开源](https://github.com/WincerChan/Cirrus)吧。\n\n**博客的一些个人配置文件我使用了 Hardcode 的方式嵌入（比如 Google Analytics 的 ID）**，请注意修改后使用。\n\n还有，因为包含加密的文章，所以我将 content 文件夹注册成了一个 Hugo Module（这个 Module 其他人没有访问权限），如果你想直接运行，最简单的方法是删除在配置文件和 go.mod 里的 Module 相关内容，然后将你的 content 文件夹拷贝到根目录，就可以运行了。\n\n## 后记\n\n促使我从 Hexo 迁移至 Hugo 的原因或许大多数人的眼里看起来甚至有点扯淡，但我当时的确已经无法忍受了。后来冷静下来想了一想，Hexo 本身并没什么不好的，反而其衍生出来的生态、主题美观度、模板语言、API 自由度比 Hugo 强了不止一点。\n\n而我终究还是换成了 Hugo，究其原因应该是我已经对 JavaScript 的编译、打包、构建等前端工具链累觉不爱了吧——咦，那么我为啥迁移到 Hugo 之后还要使用 Rollup.js 打包工具呢，人呐，果然是矛盾的动物。"},{"title":"Python 并发之痛：线程，协程？","subtitle":"","url":"/posts/c12de45e/","date":"2020-09-29T12:43:29.000Z","updated":"2020-09-29T12:43:29.000Z","category":"分享境","tags":["Python","asyncio","并发"],"content":"算算日子，我又有两个多月没有写新文章了，是时候给博客除除草了——拖更的原因是（ ~~懒~~ ）换了一份新的工作，在适应新的工作与生活环境。在入职奇安信（上一份工作）的时候，有半年的时间没有更新博客，当时的我把原因归咎于公司 push 员工太厉害，导致员工没有属于自己的空间；可现在的工作明明给予了我足够的空间，我却还是两个多月没有新文章产出，看来个人方面也有一定的原因。\n\n废话好像有点太多了，本篇文章准备分享一下最近工作上遇到的问题以及解决办法。\n\n<!--more-->\n\n## 起因\n\n起因是部门产品的图相关部分的 API 查询（使用 GraphQL 自己实现的）太慢，一次普通的查询往往在后端会解析成十几个不同的子查询，子查询的内容上没有相关性；涉及的数据源也大相径庭，包括：MongoDB、ClickHouse，以及其他产品的 Web API，因此也无法通过关联查询减少查询次数。由于子查询太多，即使每一条子查询耗时都能控制在 300 毫秒内，那一条完整的查询也会耗费将近 5 秒的时间（来自十几个子查询耗时的叠加），这显然不正常。如果能将十几个子查询的方式从「顺序」改成「并发」就好了。\n\n因此我很自然的想到了使用 asyncio 来实现并发的查询，而 GraphQL 也提供了 AsyncioExecutor 的方式来异步执行查询语句，但是正当我沾沾自喜以为这个问题就这么从理论上解决了的时候——开发负责人告知只有图相关的 API 需要改成异步方式，其他的 API 保持不变，并说出了基于两个方面的考量：\n\n1. 大部分其他 API 只是针对一个数据源查询，不会像图一样有十几条子查询，换成异步并不能提升单次查询的性能；\n2. 将其他的 API 都换成异步工作量太大，且需要测试各种兼容性，再结合上一条原因，得不偿失。\n\n但直觉上，我认为如果只是将图相关的 API 改成异步，在后续可能会出问题，但具体为什么会出问题、以及出什么问题我还不知道，因此就先着手试试。迁移的过程比我想象中要轻松很多——motor、aiochclient、aiohttp 等库已经很成熟了，在这些异步库上封装一层与现使用的同步库的兼容层就行了。\n\n## 问题\n\n花费了一周时间，在本地测试没什么问题之后就放到了线上先让系统运行着测试。头几天没出什么问题，在我以为这个问题就这么完美的解决了并准备做其他事的时候，前端突然找到我说查询请求会报一个很奇怪的错误，复现的概率不高，但有时候就会出现，我心里咯噔一下，感觉是之前异步改造不完全造成的问题。在前端发给我看具体报错之后，我确认了的确是和异步相关的问题。错误信息相信大多数接触过 asyncio 的都看过，这差不多是 asyncio 里最常见的错误之一了：`RuntimeError: This event loop is already running`。\n\n和前端沟通后，在我本地的开发环境上却没有复现此 bug，因此我认为应该是生产环境上部署的工具与 asyncio 冲突了。\n\n部署的方式与其他 Python Web 端程序并没有什么区别，WSGI 服务器使用的是 Gunicorn，worker_class 设置为 sync（一共开启 6 个），每个 worker 开启了 20 个 threads，一开始我怀疑是 worker_class 的问题，可将其设置为 gevent 之后，仍然会出现这个错误，我开始觉得有点棘手了。\n\n## 吐槽\n\n在出现这个问题的时候，我就和朋友吐槽过，Python 这门语言真的是太割裂了（Python 2 和 3 版本间的割裂就不用说了），公司产品和开源社区完全就是两个极端：开源社区一个新 Feature 接一个发布，可大多数公司仍然守着 Python 2 不肯升级，原因也很简单：Python 3 对比 2 最大的更新就是 asyncio，可这玩意所解决的痛点相比 Python 2 升级 3 耗费的精力实在太微不足道了——Python 2 使用 monkey patch 一下再使用 gevent，也比用 asyncio 慢不了多少吧，既然如此，那我还费心思升级干啥？\n\n往远了说，我认为这仍然是 Python 的历史包袱仍然没有完全甩掉（即使 Python 3 在发布的时候宣称想甩掉一些历史包袱从而决定不兼容 Python 2），也是我认为 Python 最大的痛点——并发的问题。既然 Python 之禅宣称做「最好是只有一种方法来做一件事」，此话也被社区奉为圭臬，那为什么 thread，process，greenlet，asyncio 都可以用来实现并发这件事呢？要我说就应该在 Python 3 问世的时候甩包袱甩得更彻底一些，干脆就像 Node.JS、Go 一样，想用并发？可以，只提供一种方式，想直接调用系统原生的线程？不好意思，没这种操作。**让用户只用一种方法做一件事的最好办法就是不提供其他的方法。**\n\n在 Linux kernel 2.6 版本正式引入 IO 多路复用的时候，Python 2.4 已经发布，各种功能已经很完善了，不太可能抛弃掉现有的多线程模型转而投向异步 IO 模型。如果将此时作为分水岭的话，在这之前就诞生的语言（Python，Java，C/C++）大多都是使用内核提供的多线程实现的并发模型，而在这之后诞生的语言（Node.JS、Go 等）大多是自己实现的并发模型。而 Python 则因为 GIL（Global Interpreter Lock）的存在，即使提供的是系统内核级的多线程也无法像 Java 一样实现并行处理，所以 Python 的并发一直都为人诟病。而同为解释型语言的 Node.JS，人家压根就没多线程这玩意，所有 IO 事件都放在一个事件循环里跑，和 GIL 河水不犯井水。这也是为什么我说 Python 仍然具有一定的历史包袱的原因。\n\n## 定位\n\n在确定了是 Gunicorn 与 asyncio 的冲突之后，我开启了 asyncio 的 debug 模式，希望能从中获取一些有用的信息，果然，一个新的错误出现了：`RuntimeError: Non-thread-safe operation invoked on an event loop other than the current one`，报错文件是：`asycnio/base_event.py` 中的` BaseEventLoop.call_soon()` ，此方法是一个非线程安全的方法，因此在开启了 debug 的情况下，会 `_check_thread()`。报错原因则是 `_check_thread()` 函数会检测当前线程是否是 event loop（事件循环）运行中的线程。\n\n那么，event loop（事件循环）可能会在其他的线程调用吗？——一般情况是不会的，对于大多数程序而言，有异步 IO 处理并发就够了，不需要再使用线程了。但是，基于上面的两点考虑，我们不得不选择在使用 asyncio 的情况下再额外使用线程。\n\n> 这里的线程其实是广义的概念，并非指的是系统级别的线程，gevent patch 之后的 gthread 也算在内。\n\n在我们的项目里，event loop 是作为 module 级别的变量声明的，按照 Python 的内存管理，是存放在私有堆上的，因此从同一个 Gunicorn worker 里衍生的线程自然会共享这个变量。也就是说出现这个错误的原因在于当前的线程操作了由另一个线程（通常是主线程）创建的 event loop。\n\n可以更具体的解释为：`AsyncioExecutor.wait_until_finished()` 调用了 `loop.run_until_complete()` 方法，此方法会对 loop 进行`_check_closed()` 和 `_check_running()` 检测。而最先开始的 `this event loop is already running` 报错就是 `_check_running()` 时抛出的。\n\n## 解决\n\n问题定位到之后，解决就很简单了。既然多线程一定要使用，那么将 call_soon 换成线程安全的 `call_soon_threadsafe` 就好了。\n\n`AsyncioExecutor.wait_until_finished()` 里的 `loop.run_until_complete()` 也需要换成 `asyncio.run_coroutine_threadsafe()`，该函数可以向指定的事件循环提交 coroutine。\n\n这两处需要修改 GraphQL 相关库的源代码的地方可以使用 monkey patch 的方式修改。\n\n除此之外，event loop 的创建也需要改一下，不能直接通过 `asyncio.new_event_loop()` 来获取了，需要把它专门放在一个线程里 `run_forever`（因为 `call_soon_threadsafe` 会使用 `_check_closed` 检测 loop 的状态，所以需要保证 loop 一直处于 running 状态，而 `run_forever` 这个操作是阻塞的，所以需要另起一个线程），然后由其他的线程向它提交：\n\n```python\nclass ThreadEventLoop:\n\t\"\"\"\n\tRun Event Loop in different thread.\n\t\"\"\"\n\t@property\n\tdef loop(self):\n\t\treturn self._loop\n\n\tdef __init__(self):\n\t\tself._loop = new_event_loop()\n\t\tThread(target=self._start_background, daemon=True).start()\n\n\tdef _start_background(self):\n\t\tset_event_loop(self.loop)\n\t\tself._loop.run_forever()\n\n```\n\n## 结语\n\n从接触 Python 到现在，已经有近四年的时间了。最初觉得它语法简洁、标准库功能齐全，工作了一段时候后又觉得动态类型的有些不便以及写法过于开放难以维护，再到最近感受到协程与线程的并发之痛，不知是否是因为我的水平逐渐变高，越来越能发现 Python 的不足。对于把编程语言当做是一种工具的人来说，发现工具的不足或者不好的地方之后，只需要换一种工具就好了，只是我始终没有把编程语只当做是工具，更喜欢把它当成一门「手艺」，所以我自然希望这门「手艺」使用起来越顺心越好。\n\n吐完槽冷静下来后，我也尝试站在 Python 开发者的角度想，如果真的完全不顾历史包袱，不管和老版本的兼容性，那似乎就相当于创建了一门新的语言了。而假如未来真的有某一版本的 Python 完全没有历史包袱，又拿什么去吸引用户做迁移呢？我想这也是最初 Python 3 发布的新特性也会向 2.6 和 2.7 版本添加的原因吧。\n\n---\n\n所以如果要问我为什么喜欢 Python 反而还大力的吐槽，我想是因为我真的希望它变得更好吧。"},{"title":"基于 ETS 的漏斗限流","subtitle":"","url":"/posts/16c559c7/","date":"2020-07-08T10:36:34.000Z","updated":"2020-07-10T12:01:04.000Z","category":"实验室","tags":["ETS","Elixir","限流"],"content":"ETS（Erlang Term Storage），是一种运行在 Erlang 虚拟机上基于内存的项式存储系统，在功能上类似于「简化版」的 Redis，但由于集成在 OTP 内部，相比 Redis 来说有两个优点：\n\n1. 不用像 Redis 必须通过网络端口访问，所以在理论上的存取性能会比 Redis 要高几个数量级；\n2. 存取的数据结构比较灵活，可以是任何的 Erlang/Elixir 项式。\n\n在稍稍查阅了 ETS 的相关文档之后，我便决定将目前 API 项目中的漏斗限流模块使用 Elixir + ETS 重写（稍后会介绍一下我为什么这么做），当然只重写限流部分并不能替换现有的基于 Redis 的限流，在日后我会将整个的 API 系统都用 Elixir 重写一遍。\n\n<!--more-->\n\n## 漏斗限流\n\n漏斗限流是我之前在阅读《[Redis 深度历险](https://book.douban.com/subject/30386804/)》了解到的一种限流方法，相比于传统的 Nginx 请求限制（ngx_http_limit_req_module）会更加的灵活。比如：漏斗限流可以接受短期内的多次访问，只需要不超过漏斗的总容量即可，在暂停访问则会一点一点恢复容量——这才应该是比较符合常理的限流方式，毕竟某接口的访问间隔不可能总是恒定的。\n\n漏斗限流的初始化参数包含如下四个：\n\n1. 漏斗的总容量；\n2. 漏斗的流水速率；\n3. 漏洞当前的剩余容量；\n4. 上一次请求的时间。\n\n其中前两项参数相同类型的漏斗都会保持一致，后两项则是每一个独立的漏斗都不一样。因此我在设计目前的限流模块时，只使用了剩余容量、上一次时间这两个参数，总容量与速率设置成了恒定不变的。\n\n## 使用 ETS\n\n继使用 Elixir 重写完[豆瓣的爬虫](https://github.com/WincerChan/douban-export)之后，总感觉有写不舒服：Elixir 擅长领域不应该是在爬虫，而应该是在服务端应用上。因此我决定继续深入研究 Elixir。只是手中暂时也没有什么新坑，于是就想着使用 Elixir 把 API 系统重构一下，虽然重构完成后我也不一定会将现有的 Golang 版本的 API 替换（毕竟 Golang 的部署实在太香了），但重构应该是会加深我的 Elixir 的理解。\n\n那么为什么我会选择使用 ETS 呢，其实有一个很重要的原因就是 Elixir 的数据是不可变的，因此当使用另外的数据结构（比如：Map）修改或新增键值对的时候，会涉及到比较大的内存和时间开销（复制旧的 Map 数据到新的 Map 上），于是我便把目光转向了 ETS。\n\n> 其实我最早的打算是使用 Heap 这个数据结构，只是虽然 Heap 在新增键值对的性能很高（O(1)），删除的时候也不错（O（lgn）），但是在更新的操作很麻烦，需要查找出旧的删除，再插入新的。更关键的是 Elixir Heap 的实现方式是配对堆，与二插堆提供的上浮下沉操作不一样，自己实现配对堆的更新操作的话不知道会踩多少坑。。\n\n简单写了一段代码来测试 ETS 的存取性能：\n\n```elixir\ndefmodule TestETS do\n  defp set(0), do: nil\n  defp set(n), do: :ets.insert(:ets_test, {:key}) && set(n - 1)\n\n  defp get(0), do: nil\n  defp get(n), do: :ets.lookup(:ets_test, :key) && get(n - 1)\nend\n```\n\n简直出乎我的意料，一千万次的插入和查找操作均在 1 秒内完成（硬件水平：i7-9700K，16G 3000MHZ）。\n\n#\n\n## 惰性删除\n\n在设计好了插入和更新（更新同样可以使用 `insert` 函数完成）后，还有一个非常重要的功能：「删除」。如果不定期将存储在 ETS 的键值对删除的话，内存的占用就会越来越多，所以得需要实现一个定期删除的策略。我考虑的策略是如果某 IP 五分钟之内没有请求，那么就将 Key 为 IP 的键值对从内存中删除。\n\n为此需要记录每一个 IP 访问的最后时间，且最好按照时间来严格排序（从功能上来说 Redis 的 sorted set 其实是完美契合的，只是这样一来的话又得用 Redis 了，那目前为止的工作就没有意义了），如果不能严格排序的话，用 Heap 也是一个不错的选择。只是同样会因为 Elixir 数据不可变的原因，成为性能的瓶颈。\n\n在 Google 了好一段时间之后，终于在 Stack Overflow 上找到了我想要的方案：使用另一个类型为 ordered-set（类似于 Redis 的 sorted set）的 ETS Process 来存储 IP 访问时间顺序的数据，为了避免数据的冗余，只需要保存 Key（即 IP）和时间即可，**在需要删除的时候**，先获得 ordered-set 的第一个元素，然后取出时间判断这个时间是不是已经过去五分钟了，如果是的话，就把这个数据删除，同时也需要将另一个 ETS Process 里对应的键值对删除。\n\n> 对于这个「在需要删除的时候」的检测，我将其设置为每一次访问都会触发。\n\n## 提高可用性\n\n完成了删除的功能开发之后，限流系统已经可以正常使用，但是为了提高系统的可用性，还需要将当前系统的主要进程使用 Supervisor 监管。目前功能实现分为三个模块：\n\n1. **Ral.Cell**：这个模块是对外提供的接口，只有 choke 函数被定义为公开，其余辅助函数均对外隐藏。choke 接受一个参数 Key，不限制类型，但最好为 Atom，返回值是 true 或者 false，代表本次请求通过或者不通过；\n2. **Ral.CMD**：这个模块是接受 choke 函数被调用时产生的对数据库的操作，将其与 Ral.Cell 拆分是为了让消息能在两个进程之间异步地传输，提升性能；\n3. **Ral.ETS**：这个模块是专门控制 ETS 的相关进程的，如果和 Ral.CMD 合并成一个模块的话，需要将 ETS 的参数设置为 `:public` 或将整个 Ral.CMD 注册成 GenServer，但前者有些*危险*：任何进程都可以写入 ETS 的数据，理想情况应该是最多允许其他进程读取数据而不允许写入；后者与用 Message Queue 传递消息相比将显著的降低（大约 50% 的）性能。\n\n三个模块中，需要被 Supervisor 监管的有 Ral.CMD：需要保证 Message Queue 消息接收方始终可用和 Ral.ETS：需要保证 ETS 的服务始终可用——至于 Ral.Cell，只包含对 ETS 的查询操作和对 Ral.CMD 的调用操作，因此无需对其使用高可用。\n\n---\n\n功能[完善后](https://github.com/WincerChan/Ral/)，简单跑了一下 benchmark，每秒处理数可以达到 27w，而之前使用 Redis 的限流模块QPS 只有 2w，这就将系统的性能瓶颈从限流模块转向了 Web Server，算是一个比较成功的轮子吧～"},{"title":"离职的两个月之后","subtitle":"","url":"/posts/ee6b678/","date":"2020-05-22T06:40:12.000Z","updated":"2020-05-22T12:34:21.000Z","category":"碎碎念","tags":["离职","工作","计划","思考"],"content":"三月下旬的离职，已经是两个月前的事了。在那之后我没有立刻开始寻求一份新工作，客观原因是考虑到我正处于疫情的中心地带——湖北；主观原因则是在调整自己的状态：想让自己完全从上一份工作状态里抽离出来——时隔两月，我总算可以比较客观、冷静地谈论起离职这件事了。\n\n<!--more-->\n\n## 在前公司的状况\n\n我的 leader 并非是技术出身，对因产品迭代而产生的技术问题往往视而不见，因此划定上线（提测）的日期往往非常紧迫，加班加点也只能堪堪完成功能上的开发，也就让员工不得不忽略代码质量的好坏与软件设计的正确与否。当然，由于我们组的外包人员非常多（占 80%），就算给他们更多的时间，他们也不一定有能力写出更好质量的代码或做出正确的设计，不过这并不是可以破罐子破摔的理由。\n\n目前产品使用的 Web 框架是部门 VP 在五年前根据 Flask 定制的，把开发流程全部封装得严严实实：只需要继承一个 class 并将 URL 参数放在重写的 get、post 等方法的参数列表里，然后将 URL 加入某 YAML 文件里面，就可以开始编写业务逻辑了。你不用明白框架是如何将 class 注册为对应 URL 的视图函数，也不用明白如何从 URL 参数里取出和函数参数对应的名称的值并校验值的范围、类型，只需要写业务代码就行了，像极了流水线上的工人。\n\n代码质量的低下以及框架本身偏向业务的定制加速了架构问题的产生：目前的系统甚至无法支撑十个用户的同时访问。原因在于框架一开始就没有考虑到并发，部署时也是使用的 FastCGI（单线程） + Nginx，Python 2.7 又无法使用 asyncio。同时，代码的规模越来越大、历史包袱愈堆愈多，而架构却无甚改进，导致目前的系统已经完全不能在本地运行起来了，这给调试带来了非常大的困难——只能把代码替换到服务器上运行（还不能打包替换，因为环境并不是你一个人在用），然后看日志。\n\n## 离职的原因\n\n离职的最主要原因是 leader 的管理理念与我个人的职业发展理念不符：他过分强调业务（KPI）的重要性，只在乎可量化的指标，例如：何时提测、功能是否完备；而对：架构的改进、代码的质量、用户的体验等非量化指标完全不在乎。\n\n具体总结后的原因如下：\n\n1. 公司不重视技术，招了很多很水的外包，导致产品的代码质量很差；\n2. 领导对开发时间错误估计，以及人员良莠不齐导致加班很多（经历过两个多月的 996）；\n3. 框架无改进、开发流程不规范，导致历史包袱愈堆愈多，开发、Debug、部署的负担也越来越重；\n4. 只在乎 KPI，不在乎产品的具体实现和体验，如：某页面请求加载十几秒都不在乎。\n\n这些原因既是我离职的原因，也是我认为目前产品的症结所在。我曾向 leader 指出这些弊端，并给出了解决方案，但 leader 想都没想就以当前项目太紧为由驳回了。看，领导根本不在乎这些，只要保证提测时产品本身是差不多可用的就行了，代码质量？那是什么，KPI 里有写吗？但我仍然相信，这些弊病迟早会拖垮这个产品，只是我没有必要等着这一天的来临罢了。\n\n这样的管理理念磨灭了我钻研技术的热情，也违背了我做技术的初衷（从入职后的四五个月里 Github 的 contributiosn 基本为 0 可以看出），因此我选择离开。\n\n## 两个月我做了什么\n\n在下定决心辞职之前，我也想过在论坛发一个帖子，询问我这样的状态是否应该辞职，后来想明白了：为什么我的人生需要其它素不相识的人来决定，或者难道大部分人劝我忍一忍我就真的能安心干下去了吗？答案是否定的。想明白了这一点，我便直接裸辞了。\n\n离职之后我在技术方面做了这些事：\n\n1. 阅读了《Kubernetes in Action》这本书，学习了 K8S，并在我的项目 [DIEM-API](https://github.com/WincerChan/DIEM-API) 上实践了；\n2. 在 Coursera 上完成了《Algorithm, Part I》课程的所有内容，完成了《Algorithm, Part II》课程的前两周内容；\n3. 完成了 MIT 6.824《Distributed Systems》第一个 Lab MapReduce 的内容；\n4. 重构了 Github 上的几个项目的代码，这段期间的 contributions 基本保持全绿。\n\n这些内容对我的提升比我在公司八个月所获得的更多，因此我也并没有因为辞职而后悔。\n\n## 总结 & 打算\n\n离职就算不是一件光明正大的事，至少也并不需要讳莫如深：我对公司并没有什么怨念，同事之间也相处得很愉快，只是这些并不在本文的讨论范畴。毕竟离职的原因肯定不是因为公司对你太好了，而是因为公司有些毛病你**无法忍受却又无力改变**，因此只能选择离开。\n\n毕业前因为想离家近，所以我选择了武汉；而接下来，我想的下一份工作能让我的价值得到比较好的展现。更进一步的讲，我想做一些更贴近用户的产品、一些用户真正需要的产品，能让用户的生活更加舒心，也可以满足我个人的成就感。"},{"title":"使用 OpenCore 引导黑苹果踩坑记录","subtitle":"","url":"/posts/7a2a84c6/","date":"2020-04-22T13:02:19.000Z","updated":"2023-04-09T13:11:19.000Z","category":"实验室","tags":["黑苹果","OpenCore","Hackintosh","Bootcamp"],"content":"从大一暑假开始，我便一直使用 Linux 作为日常所用的系统，这三年要说我用 Linux 如何顺心，那绝对是鬼话；可要说我使用得特别难受，那也不至于。因为它的确提升了我的开发体验和编程技能。它的优点我很喜欢、它的缺点我一开始就知道并能接受——这便是我能坚持使用 Linux 三年的原因。\n\n虽然坚持使用了这么久，可我还是要说一句 Linux 作为日常使用的系统真的很不方便，而不方便就会想要去折腾，折腾来折腾去发现时间都浪费了，它还是老样子；可使用 Windows 吧，看着丑哭的字体渲染和残废的命令行工具，感觉自己写代码都没什么动力了，所以当我第一次见到 macOS 时，我在心里就默默地种草了。\n\n种草容易拔草难啊，这一拔就拔了三年。\n\n说起来是有些奇怪，明明我这么想用 macOS，为什么不直接买一台 Mac 呢，其实是因为我对 Windows 还有需要：闲暇时我也会打打游戏，而购置一台用于打游戏顺畅的 Mac，恐怕就只能从 (i)Mac Pro 起步了——我肯定是不会买的。于是，我选择了黑苹果。\n\n## 配置单\n\n> 按照 Tonymacx86 的说法，黑苹果最好选用八代或九代的 Intel CPU ➕ AMD 的显卡配合 Z390 芯片的主板。\n\n本节的撰写时间是 2019 年 9 月，以下是当时的价格，仅供参考：\n\n| 配件 | 型号                       | 价格（¥） |\n| ---- | -------------------------- | --------- |\n| CPU  | Intel 9700KF               | 2499      |\n| 显卡 | AMD Vega 56                | 1600      |\n| 固态 | 西部数据黑盘 512G          | 614       |\n| 散热 | ID-COOLING CHROMAFLOW 240  | 359       |\n| 电源 | 全汗 MS600                 | 599       |\n| 主板 | 技嘉 Z390 I AORUS PRO WIFI | 1319      |\n| 内存 | 海盗船 DDR4 3000           | 718       |\n| 机箱 | Sunmilo T03（定制）        | 939       |\n| 合计 |                            | 8647      |\n\n在本文发布时候，我已经使用基于 Clover 引导的黑苹果半年时间了，最近突然手贱升级了 Catalina 导致系统挂了，所以才想干脆放弃 Clover，转向 OpenCore，于是便有了这篇文章。 \n\n> ⚠️：如果你是 OpenCore 纯新手，强烈建议先读读我新写的这篇[这篇博客](/posts/open-core-boot-macos-ventura-tutorial/)，是一篇更详细的黑苹果安装教程，同时包含了一些术语的解释，否则可能无法理解本文提到的一些术语。\n\n## ACPI 相关\n\nACPI 的补丁会被 patched 到 OpenCore 引导的所有系统，因此某些非必须的补丁（比如 SSDT-USBX.aml）不建议在 ACPI 中加入，不然可能会造成其他系统无法启动等情况。\n\n### DSDT 提取\n\n目前比较推崇的提取 DSDT 的方式是采用 Clover 来提取，因为这种方法能提取出原生的未曾被 patched 过的 ACPI，但这对从未安装过 Clover 引导的人有些麻烦：需要在 U 盘上创建一个 Clover 的 EFI 分区。\n\n由于 ACPI 的补丁范围并非针对单一的操作系统，因此在使用 OpenCore 引导的系统中提取到的 DSDT 可能并非原生的，不过如果你未曾修补过你的 ACPI，也没使用过黑苹果，可以考虑使用 [SSDTTime](https://github.com/corpnewt/SSDTTime) 工具来提取 DSDT（支持 Windows 和 Linux，不支持 macOS）：双击 SSDTTime.bat（需要 Python 3 环境），选 4 来提取 DSDT：\n\n```bash\n#######################################################\n#                     SSDT Time                       #\n#######################################################\n\nCurrent DSDT:  None\n\n1. FixHPET    - Patch out IRQ Conflicts\n2. FakeEC     - OS-aware Fake EC\n3. PluginType - Sets plugin-type = 1 on CPU0/PR00\n4. Dump DSDT  - Automatically dump the system DSDT\n\nD. Select DSDT or origin folder\nQ. Quit\n\nPlease make a selection: 4\n```\n\nDSDT.aml 会被提取到脚本目录的 Results 目录下。\n\n ### 注入原生电源管理\n\nSSDT-PLUG.aml（名字并无限制） 补丁是用于支持原生的 CPU 电源管理。使用 SSDTTime 进行生成：\n\n1. 运行 ./SSDTTime.command（SSDTTime.bat）\n\n   ```bash\n     #####################################################\n    #                    SSDT Time                      #\n   #####################################################\n   \n   Current DSDT:  None\n   \n   1. FixHPET    - Patch out IRQ Conflicts\n   2. FakeEC     - OS-aware Fake EC\n   3. PluginType - Sets plugin-type = 1 on CPU0/PR00\n   \n   D. Select DSDT or origin folder\n   Q. Quit\n   \n   Please make a selection: \n   ```\n\n2. 输入 「3」后，将 DSDT.aml 拖入当前终端窗口，并 Enter :\n\n   ```bash\n     #####################################################\n    #                   Select DSDT                     #\n   #####################################################\n   \n   M. Main\n   Q. Quit\n   \n   Please drag and drop a DSDT.aml or origin folder here:\n   ```\n\n3. SSDT-PLUG.aml 会自动生成在 Results 文件夹：\n\n   ```bash\n     #####################################################\n    #                   Plugin Type                     #\n   #####################################################\n   \n   Determining CPU name scheme...\n    - Found PR00\n   Determining CPU parent name scheme...\n    - Found _SB_\n   Creating SSDT-PLUG...\n   Compiling...\n   \n   Done.\n   \n   Press [enter] to return...\n   ```\n\n### 开启原生 NVRAM\n\nSSDT-PMC.aml（名字并无限制）补丁是用于开启主板原生的 NVRAM 支持。\n\n使用方法见 xjn [这篇文章](https://blog.xjn819.com/?p=543)的 3.12 节。如果你的主板和我的一样，可以直接使用[我的 SSDT-PMC.aml 文件]( https://github.com/WincerChan/Gigabyte-Z390I-OC/raw/master/EFI/OC/ACPI/SSDT-PMC.aml)。\n\n加载了 SSDT-PMC.aml 之后，「系统偏好设置-节能」里面能看到五个选项——未加载 PMC.aml 之前只有 4 项；未加载 PLUG.aml 之前只有两项。\n\n如果没有开启（模拟或者原生）的 NVRAM，系统可能会出现以下问题：\n\n1. 关机或者重启非常慢且功能错位：明明点了关机，却触发了重启；\n3. 睡眠唤醒之后屏幕在鼠标键盘失灵，屏幕冻住（freezing），然后重启。\n\n## 定制 USB 端口\n\n由于 OpenCore 的配置比较追求轻量化，因此一些人在将 Clover 换成 OpenCore 的时候可能会出现一些 USB 设备失灵的问题：鼠标和键盘的指示灯都没有亮，显示没有通电。\n\n这里可以使用 SSDT-USBX.aml 来解决这个问题，但是并不推荐，原因之前也说过了，ACPI 的补丁对 Windows 也是适用的，而 Windows 压根不需要这个 USBX 的补丁，并且这个补丁有一个 bug（feature？）：它会将所有的 USB 设备识别成内置的接口，即使你插入的是 U 盘。一旦系统将 U 盘识别成内置的硬盘，就无法使用 Mac 自带的「启动转换助理」来刻录 Windwos 系统盘了（这一点下一节会详细讲）。\n\n除了使用 ACPI 补丁之外，还可以使用 macOS 内核扩展（kext）来解决这个问题：首先使用 USBInjectAll.kext 来设置所有 USB 接口为外置 USB，确保系统能正常使用；然后打开 Hackintool 的 USB 选项卡，随后将主板的所有 USB 逐个插一遍，将非活动端口删掉，并使用连接器定制每个端口的类型。\n\n![Hackintool 使用](https://ae01.alicdn.com/kf/He25802d3c2794f5798061c54d99eb7308.png)\n\n随后点击导出图标，会导出 USBPorts.kext 和几个 ACPI 补丁到桌面，在 config.plist 里面加载 USBPorts.kext，并停掉 USBInjectAll.kext 就可以了。\n\n## 双系统引导\n\n> 戳[这里](https://www.bilibili.com/video/BV1GA411b7H9)观看双系统使用 Bootcamp 引导的视频。\n\n在使用 Clover 引导的时候，需要将 CLOVERX64.efi 设置为默认的引导，在使用 OpenCore 的时候稍稍有点不一样，不需要且**不能**在 Windows 直接使用 bcdedit 命令更改 Path 为 OpenCore 自带 BOOTx64.efi 的值。\n\n### 安装 Windows\n\n> **如果你电脑目前已经安装了 Windows，直接看下一节。**\n\n下载 Windows 10 ISO 镜像，插入 U 盘，打开「启动转换助理」，将三个勾全部选上，点击继续。\n\n![启动转换助理](https://ae01.alicdn.com/kf/Hcd2c33e5ad594203afe6a9184b2d47a47.png)\n\n如果启动转换助理没有报错的话，会让你选择分给 Windows 的硬盘空间。选择完了之后会重启。\n\n如果在下载 Windows 支持软件的时候，提示无法连接到服务器的话，依次选择左上角的 操作菜单 -> 下载 Windows 支持软件，路径选择 U 盘。此时也需手动使用磁盘工具分区出一块 Windows 所用的硬盘。\n\n重启后，**一定要继续使用 OpenCore 引导，而不要按 F12 直接进入 U 盘的引导**。\n\n在 OpenCore 引导选择界面应该会看到名为「 U 盘的名称（external）」的引导项。选择它，就会进入系统安装的界面了。\n\n安装完 Windows 之后，系统会自动重启，重新进入引导选择界面的时候，会看到多了一个名为 Windows 的引导项（排名应该只在 U 盘名称的后面一位），选择它。\n\n### Windows 修复引导\n\n如果在选择 Windows 启动时提示「ocb-startimage-failed-already-started」，别慌，这是因为 OpenCore 不知道从哪引导 Windows，你需要手动指定一下：进入 macOS，在 config.plist 的 Misc -> BlessOverride 添加一项：「\\EFI\\Microsoft\\Boot\\bootmgfw.efi」。这时再重启，应该就可以正常进入 Windows 了。\n\n正常进入系统之后，将 U 盘里刚刚下载的 Windows 支持软件安装（文件夹名称应该是 WindowsSupport，文件是 setup.exe，双击安装），安装后会要求重启。\n\n重启时在 OpenCore 引导菜单时选择进入 Windows，进入系统后，右下角应该会显示 Bootcamp 的运行图标，选择重启到 macOS，应该就能正常重启到 macOS 了。\n\n> 需要注意的是：如果没有开启 NVRAM，是没办法做到这一点的：Windows 使用 Bootcamp 重启到 Mac，Mac 使用启动磁盘重启到 Windows，因为无法使用 NVRAM 来指定开机时的启动项。\n\n---\n\n参考：\n\n- [iShengP 的 Z370F + i7–8700K + RX570 Hackintosh Build 黑蘋果建置 (Catalina ver. with OpenCore)](https://medium.com/ishengp-laboratory/ishengp-catalina-OpenCore-80be977427ae)\n- [使用 OpenCore 引导黑苹果](https://blog.xjn819.com/?p=543)\n- [精解OpenCore](https://blog.daliansky.net/OpenCore-BootLoader.html)"},{"title":"Kubernetes 初探","subtitle":"","url":"/posts/e0246a27/","date":"2020-03-16T04:27:32.000Z","updated":"2020-03-16T10:47:32.000Z","category":"实验室","tags":["Kubernetes","PostgreSQL","Erlang"],"content":"之前对 Kubernetes（K8s）一直抱有一种很「暧昧」的态度：我想了解它的特性，并且也尝试根据别人总结的经验去接触它，但尝试接触后却总像雾里看花，好像懂了一些又好像什么都不懂。\n\n我对新技术技术又总是充满渴望的，渴望来自于对旧技术的不满，这种不满在最近辞职后达到了顶峰：我不想通过别人总结的「二手知识」来接触 K8s 了，而是希望全面地了解 K8s 如何解决了现有软件架构的缺点从而火起来的。正好借着本文，写一下我近期关于架构方面的一些思考（第一篇架构相关的文章，可能会有些稚嫩）。\n\n<!--more-->\n\n## 软件架构的改进\n\n几年前，软件的架构都是**单体式**（Monolithic）的：即使一个 Web 系统的大多数模块在业务上并不是紧密相连的，它们仍然会运行在一个操作系统级别的进程当中（如今大把的软件仍然是这样的架构），这也就意味着单独改动某一个模块，在部署时必须重新将整个系统都打包一遍。并且由于大部分单体式的软件在架构层面缺少优化，在打包部署时简直就像是一场灾难，而作为开发人员最难受的是明明有办法阻止灾难发生但却无能为力。\n\n> 比如我的前公司：先把 Web 应用打一个包（包含各种 pip 的库），再把底层依赖打一个包（Elasticsearch、PostrgeSQL、Nginx，以及各种 rpm 包），这两步下来，包的大小已经直逼 3 个 G 了，每次打包部署的流程差不多都要花费两三个小时，而且有时候还安装失败。\n\n近几年，随着 Docker 的问世，**微服务**架构（Microservices）火了起来。它将单体式的软件拆分了微小且可独立运行的组件，这些组件之间是相互解耦的，因此它们可以独立地开发、部署、升级。而在微服务架构中修改了某模块之后，因为模块组件之间的运行环境是相互隔离的，也不用将系统整体打包了，只需要单独重新部署这个模块就可以了。\n\n而随着系统的复杂性逐渐提升，微服务架构中的组件必然会越来越多，配置、管理并让组件们一直保持顺畅地运行（即使是系统在升级中）也成为了一个问题。由人工来保证组件自动化配置、监督组件的运行、故障时进行处理，显然是一件吃力不讨好的事，于是 K8s 这类容器编排工具出现了。\n\n## 非 K8s 不可么\n\n> 高可用的系统设计至少需要满足以下几点；容灾性（Fault-tolerance）、扩展性（Scalability）、分布式（Distribution）、快反应（Responsiveness）、热升级（Live Update）。\n\nK8s 的确是满足了这几点，但这些并非是 K8s 的「专利」 ，实际上，在二十多年前爱立信所创造的 Erlang 编程语言便已经满足了这几点要求：即使 Erlang 诞生的时候并没有微服务这个概念（没错，我就是 Erlang 吹）。\n\n甚至可以说，K8s 在相当程度上借鉴了 Erlang 的思想：Erlang 虚拟机（BEAM）上运行的所有进程（这里的进程类似 Golang 的协程，并非是操作系统级别的进程）都是相互孤立的，进程之间的通信只能通过 message box 来传递，甚至没有共享内存，这简直就是天然的 Docker 啊！同样是因为进程孤立，跨虚拟机进程通信和虚拟机内的进程通信就只是网络开销不同，也因此 Erlang 天生就支持分布式。至于容灾性，Erlang 同样自带了进程级别的 Supervisor，当进程崩溃的时候，会自动重启。\n\n那么，既然 Erlang 设计的这么厉害，为啥现在火起来的是「借鉴」 Erlang 思想的 K8s 而不是 Erlang 本身呢？因为 Erlang 的运行模型实在太特殊了，比如：Erlang 的数据是绝对不可变的，进程之间传递数据只能复制不能传引用，才导致进程可以完全相互独立，进而保证进程崩溃的时候不会影响到其他进程。\n\n而 K8s，则是将这一系列的思想从特定的平台抽离了出来，不必再拘泥于 Erlang 这么特殊的模型了，让其他任何语言编写的程序均可以做到高可用。而对于如今的公司来说，将服务拆分然后用 K8s 进行部署的难度显然远远低于将现有代码改成用 Erlang 或者 Elixir 实现。\n\n## K8s 的实践\n\n> 在前公司，我曾尝试在架构需要调整的项目里推过 K8s，但架构评审的时候，被领导以同事都不会 K8s 为理由给驳回了，这一点倒是在我意料之中，毕竟领导担心承担决策失败的风险，以及他大概认为给开发一两周的时间熟悉 K8s 给他带来的收益比写一两周代码要少吧 :)\n\n既然目前在工作中用不到，我就只能在自己的项目中用了。\n\n于是决定将 [DIEM-API](https://github.com/WincerChan/DIEM-API) 项目改为使用 K8s 部署，并将整个项目解耦为三个部分：\n\n1. 基于 Golang + Gin 框架的服务层（Stateless），这里本应该根据功能再划分为不同的服务，但是因为目前只提供了一个 API，已无法更细分了；\n2. 基于 PostgreSQL 的数据持久层（Stateful）；\n3. 基于 Redis 的缓冲层，提供限流服务（Stateless）。\n\n单独说明一下第三点：虽然使用了 Redis 作为缓冲，但是其中存的数据仅是 IP 的访问频次，而访问频次对于功能来说并不重要，故这里还是将缓冲层的组件定义为无状态型服务。\n\n无状态型服务（服务层、缓冲层）包含两方面的设置：\n\n1. 设置 kind 为 Deployment 方便进行 Live Update，同时会自动创建 ReplicationSet 管理 Pods：崩溃时自动创建、可随意扩展服务；\n2. 设置 kind 为 Service，提供静态 IP 以供外部访问，因为 Pods 是不稳定的，可能随时被销毁并重建，同时 Service 也可提供负载均衡服务；\n\n至于有状态服务（数据持久层）要复杂一些，除了包含无状态型服务需要的两方面设置外，还需要配置 PersistentVolume 用来生成存储的资源，以及 PersistentVolumeClaim 用来请求 PersistentVolume 的资源。\n\n有关具体的配置文件信息，请查阅[项目内](https://github.com/WincerChan/DIEM-API)的几个 Yaml 文件。\n\n## 后记\n\n我在读完《Kubernetes in action》的前十章之后才对 K8s 有了一个比较清晰的认识，也总算明白了之前对着别人的教程创建了 Pods，然后怎么删都删不掉的原因：因为创建的是 ReplicationController，就算删除关联的 Pods 也会被重新创建。\n\n也知道了容器是基于 Linux Kernel 提供的 namespace 和 cgroups 技术来实现的，因此在容器内运行程序几乎没有额外的开销。\n\n本文并没有解释 Pods、ReplicationSet、Services、Deployment 等 K8s 的基础概念，一方面是我担心因为了解不够深入而难以解释清楚（毕竟我也就接触了两三周时间），更重要的是，希望读者能通过阅读书籍和官方文档来获取一手的知识。"},{"title":"我的学生时代（大学篇）","subtitle":"","url":"/posts/71f1f91c/","date":"2020-02-10T09:30:03.000Z","updated":"2020-02-11T06:30:03.000Z","category":"碎碎念","tags":["感想","大学","学生时代"],"content":"最近忽然有些念旧，想着距离写完[我的学生时代（高中篇）](/posts/5fdce618/)也有大半年时间了，趁着前几天的创作欲还未散去，本文就好好聊聊我的大学时光吧（再不聊我都怕忘记了）。\n\n温馨提示：本文会有些长，会尽量按照发生时间的先后叙述，不过我无法保证本文的叙述具有 100% 的准确性，毕竟人的的记忆本来就不甚可靠。\n\n<!--more-->\n\n## 专业\n\n现在回想起来，应该是从高二开始吧，便对计算机（的某一分支）有兴趣了，当时沉迷于安卓系统的优化，比如：刷各种 XDA 的魔改内核、ROM 等，不过受限于条件，只是停留在使用别人修改好的软件包层次，并没有机会自己手动修改。\n\n应该还是在高二吧，上微机课的时候，老师会控制全班同学的电脑，不让我们自己玩，但唯独只有一个同学不会被控制。有一堂课（好像是在讲顺序分支循环那些，记不太清了），老师向我们解释到为什么不控制那个同学：「因为我上课讲的内容他都懂了，所以我让他自己玩」。当时就觉得这个同学好厉害啊，可能这时开始，一颗种子便埋在心底了。\n\n填志愿时，这颗种子经过了一年多的萌芽，已经慢慢开始生长了。于是乎，即使所有的亲戚朋友都反对，我仍是选择了计算机专业。\n\n## 大一\n\n九月入学，校园各大社团（包括学生会）都开启了招新活动，不过我一个都没参加，大概是因为性格散漫惯了吧，不想受到什么约束。\n\n大一上学期学了第一门与计算机相关的课：HTML 与 CSS3 基础，由于刚入学，课听得都很认真，在期末时交的静态网页作业拿到了全班最高分（直到之后很长一段时间，我都在因为这个事纠结我是从事前端还是后端），高等数学也考了满分，一时间有些膨胀了。\n\n这人嘛，膨胀了之后，会有一段时间觉得自己很牛逼，我在这段时间里（大概从大一下学期开始吧），开始上课不听讲了，甚至还伙同两三个同学逃了高数课跑去看校园十佳歌手，晚自习也不怎么去上了，学习态度的散漫，导致我这学期的成绩比上学期退步了许多（当然这是后话了）。\n\n也是在这段时间里，学院开设了第二门与计算机有关的课——C 语言，同时学院的  ACS 协会（别问我全称，我也不记得了～是一个与 ACM 竞赛相关的组织）开始招新了，招新的学长在台上说了一大堆加入协会的好处：找工作时各种大公司的内推、参加 ACM 竞赛可以获得加分（保研时有用）等等，虽然这些好处没怎么打动我，不过仍是稀里糊涂的就加入了协会（可能看着身边的人都加入了吧），开始了短暂的刷题生涯。在杭电上刷了五六十道题之后，我发现我对算法没什么兴趣，期间也曾尝试转到安卓组，发现还是没什么兴趣，于是便退了协会。\n\n---\n\n在五月份，某大牛同学（初中开始编程）组了个队参加「互联网 +」创业创新大赛，我也加入了。目标是做一个考研的交友平台，可以根据个人信息推荐相似的研友，他负责推荐算法，我负责用爬虫采集数据，并清洗。当时第一次接触网络爬虫，也没有经验，只能在网上随便找个爬虫改改凑活着用，虽然最后这个项目只拿了校级的奖项，但是在这个过程中我发现我喜欢上爬虫了，于是我开始觉得要自学编程了。\n\n所谓「工欲善其事，必先利其器」，在学习之前，首先得要把环境搭好，上网看了一圈之后，决定装一个 Linux 系统（与 Windows 共存）专门用于编程，当时我对操作系统完全是一窍不通，导致在装完 Linux 系统之后重启直接回到了 Windows，百度后尝试了许多方法（比如：把 UEFI 模式改成 Legacy啊、用什么 Boot 编辑器啊），但都没什么卵用，逼得我甚至冒出了将 Windows 整个格式化掉的想法。\n\n最后还是在暑假期间解决了，还在简书写了一篇教程（一年之后居然有两万多浏览量），成功安装好双系统之后，我又开始像高中折腾安卓一样开始折腾 Linux 发行版的各种美化（真是死性不改😅）：Terminal 的美化，状态栏、主题图标的美化等等，原定好的学习编程计划也搁置了。如果时光可以倒流的话我一定会告诉当时的自己：「不要再花时间在这些没卵用的美化上了！快点学习吧！」，不过当时的我也肯定听不进去，毕竟颜值才是第一生产力～\n\n## 大二\n\n对大二上学期这段时间的记忆比较模糊，应该也并没有发生什么值得记录的大事吧：唯独对数据结构这门课印象很深，老师是我们院的副院长，可以看出他很懂数据结构，但是讲课不是特别好，不是很能吸引人，这门课我们全班的战绩都挺惨的，好像没有人超过 80 分。\n\n在大二的寒假期间，似乎终于想起了自己半年前好像就说要学习编程了，于是开始比较系统地学习 Python 了（大概是因为之前接触过爬虫，我对 Python 印象很好），在知乎上听说 MIT 6.0001 这门课用于入门 Python 不错，于是便开始看跟着视频一起学习，授课老师（MIT 计算机学院院长）讲得非常好，而我遇到理解不了的就用谷歌查，花了一个多月时间才差不多把这门课的内容学完。\n\n不过这一切都是值得的：本课程在我对计算机的理解还是一张白纸的时候并没有急着在上面写写画画，而是耐心地教了我怎么才画才算是正确的，换句话来说，本课会花很多的时间来培养你的计算思维，而一旦养成了计算思维，编程便不再是什么难事了。\n\n**即使是现在，我依然会向所有想学习计算机的人推荐此课入门。**\n\n---\n\n到了大二下，印象比较深的课就是操作系统了，先前提到过，我在大一暑假时便开始接触 Linux，老师在得知了这个消息之后，某堂课上走到我身边悄悄对我说：给你两周时间，两周后的这节课，有半节课时间给你表演👿，题材不限，风格不限，和 Linux 相关就行。我花了两天时间好好准备了一下，还抄了一个 PPT，至于结果嘛，emmmm 反正挺尴尬了，因为下面的学生似乎都没在听，从这一点看，当老师还是考验人的～\n\n四月份（也有可能是五月份），学院组织了一个院级的算法比赛，闲着没事就参加了一下，看看许久没写算法是不是退化了许多（题目我是一道都不记得了），最后拿了一个二等奖，奖品是一个 32G 的 U 盘，感觉还不错～（只是我也并没有因此对算法提起多大兴趣。。\n\n五月初，一朋友说她（好吧，其实是当时的女朋友）正在尝试用 Hexo 搭博客，我搜了一下，之后，便有了这个博客～\n\n>  提问：搭好博客后最重要的一件事是什么呢？\n>\n> 回答：当然还是美化啊～\n\n当时基本上把所有好看的 Hexo 主题都尝试了一遍（NexT、Yilia），最终还是决定了使用 NexT，选定好博客主题后的那两个月内非常高产地写了差不多十篇文章，应该是新鲜感作祟吧，很多文章都没什么营养，没多久便把大部分都删掉了。\n\n得益于博客的搭建，我的知识面被扩充了不少，也了解到了 SICP（Structure and Interpretation of Computer Programs）这本神作，在暑假前，我在图书馆借阅了这本书，花了一整个暑假的时间，却仍只读完了半本（读完了前两章，做完了[习题](https://github.com/WincerChan/SICP)），该怎么形容我那两个月的感受呢，感觉自己的编程世界观受到了冲击（也是在阅读第一章后，我彻底明白了递归与迭代的区别），感觉自己的脑回路好像都被重构了一样。\n\n一般来说，当我们在编写软件的时候（尤其是大型的软件），核心便是控制复杂度，而本书的核心——抽象，便是控制复杂度重要的手段。我在工作后接手了祖传的项目代码，才理解控制复杂度的重要性（当然这也是后话了）。\n\n**在看完了 MIT 6.0001 后，如果你想成为一名更好的程序员，并打算继续深入，那么看看 SICP 这本书吧，不会错的。**\n\n## 大三\n\n大三时，逃课开始变成了家常便饭（尤其是离散数学，但是我一学期没怎么去上过，期末反而还考了满分），不过数据库这门课我倒是每次都去上了（只是差不多每堂课都会迟到😅），因为授课老师就是上学期的操作系统的老师，对她印象还蛮好的（不过我现在还很奇怪的一点是为什么老师要教 SQL Server 而不是 MySQL 或者 PostgreSQL）。数据库课程分为理论课和上机课，由于上机课和理论课不在同一所教学楼，于是在理论课下课时便会和几个同学绕一大圈，逛逛校园，再慢慢地抵达上机课的教室，好在老师也不会说些什么。\n\n当时还有一门课是软件工程，遗憾的是软件工程的重要性是我在工作之后才明白，因此当时这门课我并没有去几次，而且老师一开始就说了这门课的考核标准：交一个系统上来就行了。于是断断续续花了两个月时间，读完了狗书（Flask Web开发：基于 Python 的 Web 应用开发实战），照着书上面的代码自己敲了一遍，也算清楚了 Python 的开发流程。\n\n除了了解 Python 开发之外，当时还针对 NexT 主题做了很多定制化操作，也借此学习了一下 JavaScript 中是如何使用 Template 的。\n\n---\n\n大三的寒假正巧碰到搬瓦工上架了 19.9 刀的 CN2 套餐，于是毫不犹豫就下手了，从此我拥有了人生第一台服务器～有了服务器之后，最先做的事就是把博客挪到了服务器上，顺便折腾了一下 CI/CD；其次 Flask + SQLite 写的一言 API 也总是崩溃，于是就花了两天时间用 Golang [重写了一遍](https://github.com/WincerChan/DIEM-API)，数据库也换成了 MySQL，也部署到了服务器上（虽然服务器只有区区 512M 的内存，但是Go 这货还是真的省内存，满载时也不过 10M 的占用。\n\n到了大三下学期，更加的放飞自我了，专业课程只剩下编译原理了，不过真的好难啊（而且我当时还是已经通过 Lisp 了解了 AST），为了学好编译原理我还兴冲冲的去图书馆借了虎书准备好好研究一下，结果拿回寝室就吃灰了。。\n\n四月份，和高中那个微机课不被监控的同学交流时，得知他拿到了腾讯的暑期实习 Offer，给我羡慕得不要不要的。谈到职业生涯时，我也挺慌的，因为我甚至还没有想好是从事前端开发还是后端开发（因为当时正在学习 React，写了个[项目练手](https://github.com/WincerChan/Meme-generator)，反响还挺好），更别说是具体的岗位了。\n\n大一的暑假是玩过去的，没必要担心，毕竟才第一年；大二的暑假是学过去的，一直在学 Lisp，感受着 Lisp 给我脑子带来的冲击。而大三暑假，则是最迷茫的一个暑假，一方面是在纠结自己的职业规划：前端还是后端？后端的话，我比较熟悉的语言只有 Python，但 Python 的岗位实在太少（且我不想转 Java）；前端的话我又没什么能拿得出手的项目。另一方面则是有些陷入了[自我怀疑](/posts/d9253d8c/)中：两年来，我将学习的重心放在自己感兴趣的方面这一决定是否正确，又或者我是不是应该好好完成学校的课程。\n\n## 大四\n\n大四上发生了一件特别有意思的事，一同学也在找工作，他说他暑假学了两个月 Spring，但现在对 Spring 基本还是一无所知，于是乎我和另一朋友「苦口婆心」劝了他一个晚上，终于劝他转 PHP 了，然后过了两个星期，他就找到了 PHP 的工作（没有任何黑 PHP 的意思😆）。\n\n随后，便是去杭州实习了，去杭的两个月可以看看[杭州见闻](/posts/2848ddef/)这篇文章，这里不赘述了。从杭州回来之后，在学校呆了一个月，那一个月是我大学四年过得最放松的一个月：逃课也不用战战兢兢地担心被老师发现（当时还有一门 Python 的选修课，因为学分还没修满）、实习证明也顺利弄到手，更重要的是，这几个月的实习，驱散了我几个月前的自我怀疑，也明确了自己未来的职业规划。\n\n还有一个小插曲就是这门 Python 课了，由于我提前和老师打过招呼说我要去杭州实习，所以平时课去不了，老师说没关系，最后用 Python 写个东西交上来就行了。于是在最后一堂课，我把大三暑假复习计算机网络时写的一个[静态 HTTP 服务器](https://github.com/WincerChan/Tiny-HTTP)交了上去，并阐述了分别使用 Asyncio 和 Thread 实现的并发，结果老师说这个程序太复杂了，不相信这个程序是我写的（大概是觉得他一个教 Python 的都写不出来吧），费了好大力气甚至把 Github 页面都亮了出来他才相信。。\n\n---\n\n大四寒假，主要是搞论文的事，选题时恰巧写业务写得有点烦（现在的工作对比来看，能安稳写业务真的很难得了），于是选了个文本情感分类方面的课题，当时还在 Coursera 上学习机器学习的课程，上到第五周的时候，往后翻了翻课表，发现并没有介绍文本分类之类的算法😒。\n\n于是便弃了这门课，改为自己找论文看着谷歌学，顺便学习了一下 Latex～顺便说一句，Latex 太适合我这种强迫症了～\n\n毕业前夕还发生了一件事：我发现学校的校园网络不登录居然也是有 IPv6 的地址的，且具有互联网的访问权限。嘿嘿，略加思考，便想到了一个可以[薅学校羊毛](/posts/36b4c1ab/)的方法，原理很简单：需要保证有一台支持 IPv6 和 IPv4 的服务器就可以了，用这台服务器在本机和互联网之间中转一下，那么即使即使只有 IPv6 的互联网权限，也可访问 IPv4 的网站了。\n\n## 结尾\n\n毕业时，我罕见地有些不舍：不知是不舍这所学校、还是不舍同过窗的同学、抑或是不舍可能是最后一段学生时光。但应该还是不后悔的吧，虽然投入开源项目我付出了很多时间，但的确也扩充了我的知识和眼界，不过也不是说程序员就都要做开源，只是我个人确实通过做开源获得了很多提升：如果你能坚持在两年内，每天平均编程四个小时，我想你也会获得很多提升，而开源只是我坚持的动力罢了。\n\n大学四年里，我放弃了一些欲望，只想活得轻松一点。\n\n这欲望是指对保研的渴望（努力上课，好好听讲，参加各种竞赛）、对组织能力的锻炼（加入各种学生会、班委）等等，转而将精力投向了我所感兴趣的方面。当然我意思也不是说我现在多么成功，只是想说明，**当你决定要跟从内心做自己喜欢的事时，接下来只需要坚持下去就好了。**\n\n---\n\n本系列正式完结（不排除有续作的可能，嘿嘿）～"},{"title":"累加器引发的一点思考","subtitle":"","url":"/posts/286f4007/","date":"2020-01-30T02:42:09.000Z","updated":"2020-01-30T02:42:09.000Z","category":"分享境","tags":["编程","杂谈"],"content":"趁着最近肺炎，在家修养生息：看看剧，看看电影，偶尔也会学习一下。最近在学习 Elixir 这门语言，由于其实在太小众，只能抱着一本英文书啃（第一次看英文书籍，也没想象中那么难，就是看得比较慢），在看到 Elixir 实现累加器（就是《黑客与画家》里介绍的累加器）的时候，突发兴趣研究了一下，便有了本文。\n\n<!--more-->\n\n## 累加器是什么\n\nPaul Graham 在《黑客与画家》中是这么描述累加器（函数）的：\n\n> 我们需要写一个函数，它能够生成累加器，即这个函数接受一个参数 n，然后返回另一个函数，后者接受参数 i，然后返回 n 增加（increment）了 i 之后的值。「这里说的是增加，而不是 n 和 i 的相加（plus）。累加器就是应该完成 n 的累加。」\n\n比如说，这个函数是 foo，那么它应该具备以下行为：\n\n```python\nacc = foo(2)\nacc(6)  // result = 8\nacc(7)  // result = 15\n```\n\n想了一下，如果某语言可以比较舒服的实现这个函数，则该语言需要具备两个特性：\n\n1. 对词法变量的完全支持；\n2. 函数是一等公民（即函数可以作为返回值）。\n\n## 图灵等价\n\nCommon Lisp 的实现：\n\n```lisp\n(defun foo(n)\n  (lambda (i) (incf n i)))\n```\n\n虽然根据图灵等价来说，所有的语言在功能上都是相同的，但这没有意义：因为题目要求的并不只是**实现**一个（累加器）**功能**，还对具体的实现有**额外的要求**（必须使用函数来实现），因此你没有办法使用 Java 来实现（因为 Java 无法把函数作为另一个函数的返回值）。\n\n举一个更一般的例子，比如有个问题：要求计算 167564386575724718662 的平方，但不得自行编写处理整数溢出的函数。在这个问题中：计算一个数的平方是**功能**，而不得自行编写处理整数溢出函数则是**额外的要求**。\n\n如果只是针对功能来说，确实所有图灵完备的语言都可以实现，只需要处理一下溢出的整数就好，但这类问题狡猾在对具体的实现还有额外的要求，因此，整数会溢出的语言便无法解决这个问题。\n\n## Python 的实现\n\n在书中，Paul Graham 给出了 Python 的一种（累加器）实现：\n\n```python\ndef foo(n):\n    s = [n]\n    def bar(i):\n        s[0] += i\n        return s[0]\n    return bar\n```\n\n之所以需要这么写，而不能直接使用 lambda 返回的原因有两点：\n\n1. Python 中的 lambda 无法使用赋值（=）符号；\n2. Python 中对词法变量并非完全支持。\n\n有关第一点，《流畅的 Python》一书中提到，因为 Guido 不想让 Python 变得太函数化，因此极大地限制了 lambda 的使用。\n\n而第二点，则是因为 Python 不支持对词法变量「重新赋值」的缘故：\n\n```python\ndef foo(n):\n    def bar(i):\n        n = n + i\n        return n\n    return bar\n```\n\n在 foo 内部的 bar 函数中，`n = n + i` 语句会在当前词法作用域新建一个变量 n（当前作用域不存在 n 而且有「=」符号），因此这个写法是错误的，运行会得到 UnboundLocalError 的错误，除非在 bar 函数中显式声明：`nonlocal n`，表示 n 使用上一层词法作用域的值。\n\n那么为什么书中的实现没有声明 `nonlocal` 也可以呢？注意我刚刚提到的，Python 虽然不支持对词法变量的「重新赋值」，但是支持对已存在的词法变量「修改」：对于 s 来说，`s[0] += i` 这个操作，并没有把 s 重新赋值，而只是把 s 的其中一个元素修改了，换句话说 s 本身的地址是没有变的：\n\n```python\n>>> a = [0]\n>>> id(a)\n4438808928\n>>> a[0] = 1\n>>> id(a)\n4438808928\n```\n\n同理，其他可变的数据类型（class、dict）也都可以实现这个功能：\n\n以下是使用 dict + lambda 实现的：\n\n```python\ndef foo(n):\n    d = dict(r=n)\n    return lambda i: d.update(r=i+d['r']) or d['r']\n```\n\n看起来虽然简洁了不少，但我觉得这远不如使用 `nonlocal` 来得优雅，而且这种方式也降低了可读性。\n\n## Elixir 的实现\n\n### 数据不可变\n\n我学习 Elixir 也有二十来天了（从[这一次提交](https://github.com/WincerChan/Douban-Export/commit/7ef2cde7a87cd125ec00515dc979b42da71ce572)开始），虽然早就预见数据不可变会给我的编程习惯带来一定影响，但是没想到影响会这么大。\n\n还是拿累加器举例子。更近一步地说，要实现这个累加器（函数），只需要保证闭包内部的词法作用域能修改外部作用域的变量就可以了。\n\n```elixir\niex(1)> outside_var = 5\n5\niex(2)> lambda = fn -> IO.puts(outside_var) end\niex(3)> lambda.()\n5\niex(4)> outside_var = 6\niex(5)> lambda.()\n5\n```\n\n但由于 Elixir 的数据是不可变的，定义 lambda 时，内部词法作用域保存的 outside_var 的引用地址的值是 5，定义完毕后，lambda 内部引用地址的值便无法被修改了。\n\n> 这里虽然对 outside_var 绑定了两次值（5 和 6），但第二次绑定并不是修改内存地址的值，而是重新申请一块内存赋值为 6，再将其绑定给 outside_var。\n\n也就是说，虽然 Elixir 对词法变量完全支持（不会像 Python 一样报错）：\n\n```elixir\niex(6)> foo = fn n ->\n          fn i ->\n            n = n + i\n          end\n        end\nwarning: variable \"n\" is unused\niex(7)> f = foo.(7)\niex(8)> f.(8)\n15  # 首次调用，符合预期\niex(9)> f.(8)\n15  # 这里我们期待值为 23\n```\n\n但这种写法得到了不符合我们预期的行为，它同样会在内部匿名函数的词法作用域中添加 n 变量（由于 n 没有使用，所以解释器报 warning 了），并不会对外部作用域的 n 变量进行修改。且 Elixir 并没有 Python 那样的 trick（使用 list、dict 等可变类型），毕竟 Elixir 里的数据是不可变的（无论是什么数据类型）。\n\n那么问题来了，Elixir 该怎么修改并保存变量呢，更一般地说，Elixir 如何保存进程的状态呢？\n\n### 消息传递\n\n由于 Elixir 里的进程（这里的进程，有别于操作系统的进程，更类似于 Go 或者 Python 里的「协程」）都是完全孤立的，进程间无法通过共享内存来通信，因此 Elixir 采用消息传递（message passing）的方式进行进程之间的通信，也是通过它，我们可以构建出保存状态的进程。\n\n比如这里的累加器函数，在每次调用累加器时，需要做两件事：\n\n1. 从消息信箱中获取上一次累加的结果；\n2. 更新这个结果，并将结果发送给消息信箱。\n\n```elixir\nfoo = fn n -> send(self(), n)\n  fn i -> result = \n    receive do\n      num -> num\n    end\n    send(self(), result + i)\n  end\nend\n```\n\n值得注意的是，虽然 receive 语句是阻塞的，但是能保证每次开始调用累加器时，消息信箱中总是有数据的（来自于上一次累加发送的消息），因此进程并不会阻塞住。\n\n```elixir\niex(1)> f = foo.(2)\niex(2)> f.(2)\n4\niex(3)> f.(2)\n6\n```\n\n不过，由于这种方法涉及进程之间的通信，因此耗费的时间远比原生支持修改外部作用域变量的语言要多（大约是 Python 的实现方式的 10 倍左右）。\n\n## 结尾\n\n其实有些纠结是否应该发这类文章，主要是纠结其内容是否有价值，后来想了想，当然是有价值的，价值的名字叫做「独立思考」。\n\n参考：\n\n- [黑客与画家](https://book.douban.com/subject/6021440/)\n- [Elixir in Action 2nd](https://book.douban.com/subject/30425309/)"},{"title":"2019 · 终焉","subtitle":"","url":"/posts/a9aef93a/","date":"2020-01-01T09:10:26.000Z","updated":"2020-01-03T05:19:26.000Z","category":"碎碎念","tags":["2019","感想"],"content":"翻了翻存档，我这个之前平均一月发一篇博客的人居然有半年没有新文章产出了，在这里给挂念着这个博客的各位小伙伴说声抱歉（前几天逛 V2 的时候还被催更了）。工作以后确实经历了许多事，也成长了不少，本文作为 2019 的告别文，就稍微记录这一年发生的事吧。\n\n> WARNING：本文负面情绪有些重，有些流水账，有些吐槽向。\n\n<!--more-->\n\n## 毕业\n\n在毕业论文选题时，我特地挑了一个完全陌生的领域——机器学习，本想着能跟着导师学点新东西，结果导师太不靠谱——压根不管事（啥资料什么的都不给，开题报告的要求都是研究生代写），只好自己摸索着学了。\n\n花了差不多俩月时间（中间包含着春节），捣鼓了一篇万余字的论文出来（论文是用 Latex 写的 ，为了让排版符合学校规定，调整了好久，如果不是因为这点，应该一个月就差不多了），满心欢喜地发给老师，结果老师压根就没看：「明天打印一份出来我再看，电子版与打印版的格式会不一样」，我盯着屏幕上的 PDF 文件陷入了沉思，难道 PDF 电子版打印出来会不一样嘛？\n\n第二天把论文带去了教室，老师把其他人的论文都看完了才看我的，所幸给出了比较正面的评价：「从论文看，你这两个月确实是做了点研究的」，心里顿时长舒了一口气。随后两周，果然比较顺利地通过了答辩，老师也把我的论文推上了优秀毕业论文。\n\n回首这一年看来，捣鼓机器学习的那两个月应该是我这一年最快乐的时光了（我对学习新知识还是有挺大的渴望）。\n\n## 培训\n\n七月份，我正式入职了某家公司（公司名就不透露了，因为接下来要说它坏话 :）\n\n一开始听说公司要求去北京培训两个星期（我 Base 在武汉），我就不太乐意，把 Base 在全国各地的人都拉去北京培训，培训的目的肯定不会是培训工作技能，极大可能是「洗脑」——利用从众心理，当周围的人都认同一件事的时候，你很大可能也会被同化。\n\n培训第一天，给全体人员了十二个组，每个组大约十来人，选定了组长、组长秘书，从此之后的每天早上都会进行组内分享，分享自己认为昨天成长了什么（无非是围绕着奋斗、客户、产品的扯淡），虚伪到了极点。每人都分享完毕后，组内投票选出成长达人，在全体人的面前分享「获奖感言」。\n\n我并非不喜分享，只是这种明明言之无物、却又不得不说的分享，我很反感。\n\n## 工作\n\n两周后，漫长培训如期结束。到岗的第一天，直属 Leader 就把我和另一个也是校招进来的人叫到办公室，客套了几句，随后说：「你们是校招生，前三个月对公司的产出肯定是比较少的，所以我要求你们前三个月每天都不得早于九点半下班」。\n\n看着另一个校招生没有任何犹豫就点了头，无奈之下，我也只好妥协，答应的同时，心理仍然侥幸地想着，没关系，三个月嘛，很快就过去了。\n\n只是我没想到，妥协一旦有了第一次，便会成了无数次。\n\n九月初，我开始正式开发一个新的定制项目，没有需求、没有产品、没有原型、没有测试，只有一个 PPT，让我们对着 PPT 把产品做出来。九月下旬，要求我们出差上海，驻场开发，为期一个月。\n\n去上海的一个月里深刻体会到了什么叫「朝令夕改」，每隔两天客户开会都会提出新的需求，没有产品，所以只能让开发去和客户对接需求，呵，我真想骂人。‘\n\n在上海的最后一个星期，我们组有一个北京的校招生离职了，对外的理由是家里出了一些事。另一个在武汉的校招生说 Leader 已经宣布正式进入 996 了（还从其他组抽调了人），目的是为了完成部门产品的一年一次的迭代开发。\n\n操他妈的」，告诉我消息的那个校招生在和我通电话的时候骂了出来，「我 es 压根就没学过，就直接让我着手开发」、「你能在上海多呆一会就呆一会，回来就苦逼多了」……我心里想着，没关系啊，已经妥协两次了，再妥协一次又有什么关系呢？\n\n## 996\n\n毕业前，我一直在思索寻求一份什么样的工作（自然是计算机行业，这里是指更加具体的方面），恰逢 996.icu 项目最火的时候，我告诉自己，既然不知道想找一份什么样的工作，那就反其道而行之——不找一份 996 的工作。大约是造化弄人吧，公司并没有履行约定好的 1075 工作制（没记错的话，入职半年只有两次准点下班），996 还是降临到了我的身上。\n\n从上海出差回来的第三天，那天我八点半下的班，八点四十 Leader 打了个电话给我，问我为什么这么早下班，事做完了没有，我说做完了。\n\n「这么早就做完了？看来是工作量不饱和啊，明天给你多加一点」。\n\n「操他妈的」，我也爆粗口了，只不过是在心里骂的。\n\n第二天一去公司，询问了一下提前走的三个人（其中有两个人都是其他组调来的），都同样被打电话询问了。有趣的是，Leader 昨天并不在武汉，而是在北京出差。\n\n两天之后，被打电话的一个人直接提了离职（他是其他组借来的，已经在公司呆了一年半了），裸辞，只不过部门大领导没有同意。\n\n经历了两个月的 996，我深深明白了 996 真正摧残人的地方不是身体，而是心灵。它会慢慢磨损掉一个人心气，当你知道即使在规定时间做完了事之后，你也无法到点下班时，效率对于你来说便无所谓了。\n\n>  跟着领导混吧，他喜欢看着我加班，那就加吧，只要听领导的，技术什么的反正领导也不在乎，能做出来就行，管他用什么方式呢。\n\n我不想，真的不想自己变成这样的人。\n\n## 辞职\n\n周一的上午，来到公司后，给自己冲了一杯奶茶，慢慢地饮下去，享受着胃里因为温暖传来的舒适感，惬意极了。\n\n慢慢走到了 Leader 的附近，「XX，有个事我还是决定应该提前告诉你一下，我准备离职了」，说这句话的时候我一直在仔细观察他的面部表情。可惜似乎没看到什么变化，「你稍等一会，我一会去找你」。\n\n两分钟后，他把我叫到了一个会议室。\n\n「坐」，他指了指椅子，「啥情况啊，为啥突然想到要离职」。\n\n「感觉刚毕业还是应该学点技术，业务写多了实在没什么意思」，我说得很委婉，毕竟我不知道该怎么和他说和我合作的一个同事连 URI 是什么都不知道，没准说出来之后发现他也不知道 URI 是什么（还是有这个可能性的，毕竟他认为把函数调用的结果赋值给一个变量之后在内存中的占用会多一倍）。\n\n「那你找好下家了吗？」，他随口问到。\n\n「没有，裸辞」，我没打算说谎。\n\n「那如果可以给你换组，你可以留下来吗？」，他问道。\n\n我愣住了，我没想到他会这么说。\n\n「你想做什么方面的呢，安全？机器学习？渗透？这些我都可以帮你安排」，谈话的天平似乎慢慢向他的方向倾斜了。\n\n……一场非常「诡异」的谈话开始了。谈话的双方分别是一个刚入社会不久的本科毕业生、另一方是整个部门最赚钱的组的 Leader。\n\n他给出了留我的条件：我本周为当前的项目的内存稳定性进行优化，今后的工作他会把我平时工作的业务量控制在 30%  以内；并且下周开始，我负责另一个即将产品化的项目进行架构调整，我对该项目的架构、技术选型有着完全的控制权。那是一个与  Hadoop、Hive、HBase、Spark 有关的大数据项目，仔细想了想，似乎我的技能树里就差了大数据这一块了。\n\n最终，我选择留了下来。不是因为别的，而是因为一月份上三周班能拿一个月的工资～\n\n## 生活\n\n996 的人，还有生活吗？这是我一直在思考的问题，每天下班之后随便看看视频就已经十一点多，洗个澡之后躺在床上就十二点了，甚至每天八小时睡眠都无法保证。\n\n这便是我工作之后博客便停更的最根本原因，也是我今年一年观影量锐减的主要原因。好在上半年还有不少存货，还是简单总结一下吧。\n\n读书方面，今年一共读了 11 本书，推荐两本书：《乌合之众：大众心理研究》和《蜘蛛男孩》，前者讲的是心理学，有些观点有些偏激，不可全信；后者是一部奇幻小说，很温暖、很跳跃、很好看。\n\n电影方面，今年共看了 62 部电影，似乎没有明显高出其他电影一筹的（像去年的我不是药神），觉得还不错的有：寄生兽、哪吒、升级（Upgrade）、海王、调音师。\n\n剧集方面，今年看过的都不错，长剧强烈推荐：六龙飞天，是一部讲高丽如何被推翻的剧，虽然有 50 集，每集 1 个小时，但真的非常吸引人，一看就上瘾的那种；短剧推荐：致命女人、半泽直树、花甲男孩转大人。以及高中非常喜欢的一本小说——《庆余年》，终于改编成电视剧了，一开始担心会毁原著，但是却出奇精彩！\n\n动漫方面，似乎今年只看过五部，最好看的定然是灵能百分百 II：温情、热血、打斗、治愈，太完美了。\n\n---\n\n写本文时，总觉得心中有股气，不写出来觉得委屈得难受，写完之后静下心思考了一下，我应当是把对 Leader 的厌恶都加在了公司的身上了，是有些不妥；可又一想，一个敢把公共会议室当个人办公室的人在这个公司居然混的这么好，这大概能说明公司本身管理就出了问题吧。\n\nAnyway，2019，总归是结束了。至于 2020 嘛，简单一些，开心就好~"},{"title":"记一次反向代理的搭建","subtitle":"","url":"/posts/1352252a/","date":"2019-07-04T03:47:43.000Z","updated":"2020-06-05T16:26:43.000Z","category":"实验室","tags":["反向代理","Startpage","搜索引擎"],"content":"最近和朋友聊天时，他说发现了一个云计算服务商：「[ZEIT](https://zeit.co)」，可以为程序免费提供托管，想问问我有没有什么好的想法。我查看了一下发现这货在全球提供的线路还真不少（亚洲大部分地区都有），用作代理软件想必体验会比较不错。\n\n于是我首先想到搭建 ShadowSocks、V2Ray 这类代理软件，不过很可惜 ZEIT 在部署上有限制：不支持 WebSocket（当然更不支持 SOCKS5 了），且虽然线路的延迟比较低，但在带宽上却有限制，于是我暂时放弃了正向代理，把注意打到了反向代理的头上。\n\n<!--more-->\n\n反向代理相比正向代理的限制不少，最大限制的在于一次只能代理一个网站。想了想还是决定代理一个搜索引擎——[Startpage](https://www.startpage.com/)，用于手机等不那么方便翻墙的设备搜索。至于为什么选择它嘛，有两点原因：\n\n1. 它是一个非常「干净」的搜索引擎，隐私性做得非常好，甚至没有登录功能，用户偏好也只是用 Cookie 实现；\n2. 它匿名地向 Google 提交查询，再将结果返回给用户（某种意义上来说，它也算 Google 的反向代理），所以搜索质量约等于 Google。\n\n~~至于为什么不选择 Google，答案也很简单，Google 会检测计算机的异常流量，一旦检测到异常，则必须通过「reCAPTCHA」检测才能继续使用。尤其是在使用反代的时候，出现检测的机率非常高，这对想迅速得到搜索引擎反馈的用户来说，无疑是一种灾难。~~\n\n> 时隔一年，我真香了，在把[本站](https://mirror.loerfy.now.sh)的代理切换成 Google 一段时间之后访问时也并没有出现「reCAPTCHA」检测，因此本站会继续保持代理 Google。\n>\n> ⚠️：目前，我的 ZEIT 账户因为搭建的代理被太多人次访问（每个月差不多使用了 100g 的流量），已经遭到官方永久性冻结账户了。所以大家还是尽量自己搭建自己使用吧。\n\n## 思路\n\n反向代理的核心思路或者说原理其实很简单：中转服务器把来自客户端的请求发送给服务端，再将服务端的应答返还给客户端。单纯地实现这一功能也非常简单，使用 Golang，你甚至不需要借助第三方库便可搭建一个很简单的反向代理。\n\n```go\nfunc Proxy(w http.ResponseWriter, r *http.Request) {\n    reverseURL, err := url.Parse(protocal + host)\n    proxy := httputil.NewSingleHostReverseProxy(reverseURL)\n    r.Host = host\n    proxy.ServeHTTP(w, r)\n}\n```\n\n这几行代码就足以搞定 Google 的反向代理了，也能让你愉快地使用 DuckDuckGo 了，然而却无法使用 Startpage。\n\n是的，可能因为「Startpage」本身就相当于对 Google 的反代，所以它对反向代理极其不友好，具体见下。\n\n## 薛定谔的 Bug 们\n\n### 绝对路径\n\n当我运行刚刚的程序，打开浏览器并输入地址满心欢喜地看着 Startpage 的首页一点点出现时，我几乎以为已经成功了，可是当我输入关键字搜索时，打开 Firefox 的调试工具却发现它的请求资源都是从「Startpage」域名返回的。\n\n是的，Startpage 很「聪明地」将静态文件的引用使用了绝对路径，而不是大多数网站都使用的相对路径，这意味着我还需要修改 Response Body，将原域名都替换成自己的域名，这一点倒是没什么难度（当时我是这么想的），正好 Golang 也提供了 ModifyResponse 用于 Response 的修改。\n\n可当我代码写好了然后发现运行结果仍和原来一样时，我开始觉得有点难办了。\n\n### 传输编码\n\n造成这个问题的原因其实很明显，但我却花了半天的时间才找到：Startpage 在网页传输时启用了 GZIP 的压缩编码，因此直接替换 `www.startpage.com` 是行不通的，需要将 Response Body 解码之后再替换。\n\n完成解码替换之后，终于如愿看到请求资源都是从本域名返回的，我又一次以为自己要成功了。可是当我点击搜索结果的下一页时，网页却久久处于加载之中，我开始觉得或许不应该选择代理「Startpage」了。\n\n### 域名改变\n\n打开 Firefox 的调试工具之后，发现它居然把第二页的域名给换成了与首页完全不同的二级域名——「www」会变成类似「s2-us8」、「s3-us6」这的前缀，而具体变成什么样是由首次搜索的时候随机返回的。\n\n这个问题其实应该是无解的——除非你把所有出现的二级域名都进行代理（类似 YouTube 其实也是把每个视频的源文件放在不同域名的服务器上），不过很可惜，Startpage 只是单纯把域名换了，实测之后直接输入域名前缀也是可以正常使用的，因此只需要把代理的 URL 从 `www.startpage.com` 换成 `s3-us6.startpage.com` 就可以加载后几页的内容了。\n\n### 处理 Header\n\n在修复了以上三个 Bug 之后，搜索功能已经很完善了，不过还有一个小问题，就是用户的偏好设置无法保存，比如自定义背景、偏好语言等，点击保存按钮会 301 重定向至 `www.startpage.com` 页面，是的，这又是「Startpage」为反向代理设置的一道关卡。（没办法，自己选的路，哭着也要走完 : ）\n\n在修改完 301 的重定向地址后，点击保存发现虽然不会跳转到「Startpage」域名了，但是设置依然没有保存下来，一番 Debug 后发现是 Cookie 的问题，Cookie 设置的 Domain 不是同样使用的是绝对路径，「Startpage」为了不让别人反代真是煞费苦心呐！\n\n在直接把 Cookie 的 Domian 字段干掉之后，使用起来终于和原网站无异了。\n\n## 总结\n\n虽然一开始只想着反代一个搜索引擎，但中途想着还是把普适性做得更广一些，让它能代理任意的网站，因此考虑的方面也比较多，但最终的成就感还是挺爽的，自己也对 HTTP 各字段的理解更深刻了。\n\n目前这个反向代理工具支持文本替换、重定向替换、Cookie 替换等，源码[已开源](https://github.com/WincerChan/mirror)在 GitHub，部署在 ZEIT 上，如果你想部署在自己的服务器上，建议使用 master 分支。\n\n参考：\n\n- [Reading gzipped HTTP response in Go](https://stackoverflow.com/questions/13130341/reading-gzipped-http-response-in-go)\n- [Golang Example: multi-route, multi-lambda with dependencies](https://spectrum.chat/zeit/now/golang-example-multi-route-multi-lambda-with-dependencies~fb35e1e2-9f29-47b2-87a2-0977775fc45c)\n- [How to dump a response of an HTTP GET request and write it in http.ResponseWriter](https://stackoverflow.com/questions/41313949/how-to-dump-a-response-of-an-http-get-request-and-write-it-in-http-responsewrite)"},{"title":"我的学生时代（高中篇）","subtitle":"","url":"/posts/5fdce618/","date":"2019-06-15T05:53:44.000Z","updated":"2019-06-15T05:53:44.000Z","category":"碎碎念","tags":["感想","学生时代","高中"],"content":"在临毕业的这段时间，生活似乎短暂地失去了目标，并不是丧，我也没有认为这是一件坏事——至少我可以有更多的时间思考并记录我的想法，当然更多时间我在好好地、不带任何负担地放松自己。\n\n直到前几天 [WakaTime](https://wakatime.com/) 发邮件过来说已经两周时间没收到我的 Code Activity 了，问是不是插件出了什么问题：「Please [reinstall the plugin](https://wakatime.com/plugins) to continue using the WakaTime dashboard」。其实并不是插件出了什么问题，而是我真的两周没有编程了（笑。\n\n<!--more-->\n\n休养够了，也终于意识到应该做或写点什么了：于是我开始了本文的创作。本文决定聊聊我的高中以及大学生活（其实我一直都有些畏惧谈论这个话题，原因之后会提到）。\n\n## 错愕\n\n从进初中开始，快班里的我们便只有一个目标——进入省重点高中，为学校赚来更好的名誉（当然也为自己的前途）。中考结束，很遗憾，我离省重点的分数线还有几分的差距，当时班上有几个和我分数差不多的人选择了市重点：学杂费全免，直接去最好的班，还有奖学金。当时的我，对于省重点和市重点没有什么明确的概念，所以还是听从家人的想法：交「择校费」，进入了省重点。\n\n我仍然记得从初中班主任（我和他关系很不错，他曾不止一次地鼓励我，甚至在我说因为回家太晚而不想上晚自习时，提出可以每天晚上开车送我回家；在中考前，让我不用做数学卷子，把心用在其它学科上）手里接过录取通知书时，他脸上那种复杂的表情——惋惜与错愕。前者在于我最终还是没能过省重点的分数线，后者在于我居然还是上了这所学校。\n\n## 堕落\n\n高一上学期，还未分班，想学文的和想学理的混在一起上课，我所在的班级不巧在以后会成为文科班，一想到反正以后也会转班，那就转班后再好好学习吧！恰巧在朋友的安利下，又接触了网络小说（玄幻啊，都市啊~~，言情啊~~），于是一发不可收拾彻底沉迷于小说，而「转班后再好好学习」也成为了我心安理得的借口。\n\n当时的化学老师非常照顾我（因为我第一次摸底考试化学考了并列第一名，当然是吃初中的老本），他也是最早发现我堕落的老师，因此找我谈过几次话，虽然我并没有因谈话而上进，但我仍然感激他在我陷入黑暗的时候愿意拉我一把。\n\n在未分班时，考试排名差我也有理由搪塞：文科我不会。可到了高一下学期，便进行了预分班，我被分到了一个新的班级，预想中的「重新做人」并没有出现在我身上，反而是更加的堕落——因为我同桌也看小说。与此同时，「文科我不会」的谎言也不攻自破（虽然是预分班，但学校会针对文理科的学生单独出一份文理科目的排名）。家人以为是我沉迷手机（说实话当时也确实沉迷手机，毕竟是智能机刚兴起的时代，但不是沉迷于网络，而是沉迷于折腾手机 ROOT 之类的），于是把我的手机没收。仅留下一个 MP4，但 MP4 仍然可以看小说，于是我仍沉迷于小说。\n\n最终，堕落的高一以我期末考试 1062 的名次（年级不到一千两百人）结尾，而我也没有和家人扯什么「其它人中考分比我高，我学不过他们」这种诛心的理由。\n\n高二上学期，上课看小说的情况似乎并没有得到改观，反而是我在与老师斗志斗勇的过程中成长了——「发明」了一种能上课看小说而不被抓到的方法：用书在课桌的前面和右侧各摆一摞，形成一个角落，一有风吹草动就把「作案工具」塞到书下面专门预留的缝隙里。得益此「发明」，我上课看小说没有被老师抓到过一次。可惜之后效仿的同学越来越多，班主任就禁止桌面上的书摆放成这种形状了（话说我这也算是迫使别人改变规则的人了 233333）。\n\n## 奋起\n\n似乎很难想起当初选择从堕落的深渊里爬出来的理由（或许不是想不起，而是我自己也不知道），但终究还是选择往上爬了——我开始严格控制看小说的频率，并开始学习了。\n\n没过多久，正巧班主任把我调换了座位，我的同桌变成了班长，前桌坐的是班上第一名，我们三人「一见如故」：感兴趣的课（数理化）会一起认真听讲，一起听数学老师讲人生道理；在另外的某些课上则会小范围地互相逗乐、互相扯淡，那段时间不仅是我高二过得最快乐的时光，也是进步最大的时候，我很感谢他俩，也开始明白为什么家人一定要送我来这所学校了。\n\n除了他们，我还想说说老师们，尤其是数学老师。在他的课上，我学会了数学这种严谨的思考方式，以及他那近乎到自恋的自信（名言：答案和我不一样就是答案错了），兴趣来了，成绩也就水到渠成了。高二下，我数学考了全班第一——145 分，数学老师似乎开始注意到我这个默默无闻的学生了，从那之后，我像是想证明什么似的，每次数学都很尽力地考，可却再也没考上过 130，可也没低于过 110。\n\n语文课，永远都是睡觉的课——语文老师是学佛的，也非常佛系：发现你睡觉时，便会很温柔地抚摸你的背让你不要睡觉，大部分人在被叫醒后仍然继续倒头就睡，他也不恼，继续上他的课。英语老师也非常有趣：经常在课上和我们这些成绩不太好的学生「互动」，还经常放电影给我们看，得益于她，我拾起了对英语的兴趣。\n\n好景不长，高二下学期过了才两个月，我们三人组的欢乐时光被班主任强行结束（原因是某人告密说我们三人上课讲话影响课堂纪律），也因此，高二的我对班主任怨念颇深。\n\n## 荒诞\n\n上了高三，学校开始要求学生要上两节晚自习（七点到八点半以及八点四十到十点），我们的班主任又要求早上六点五十就要到校，而且我还要搭公交往返，这样一来的话一天根本无法保证八个小时睡眠，于是我就让父亲和老师说我不上第二节晚自习，好在当时我的成绩稳定下来了，也有了底气提出这个要求。\n\n虽然每天晚上比同学早一个多小时回家，但我早上仍旧无法那么早起床（尤其是冬天），迟到成为了我的家常便饭，基本高三大部分的早自习我都是被罚站在教室后面背书，最多的一次罚站了近二十人，这也算我们班独特的风景线了。\n\n在临近高考的几个月里，我过得比之前更放松了：会在老师要求我们自习时和坐最后一排的朋友一起靠在墙上看《奔跑吧兄弟》，却又不敢笑出声；会在早自习下课的五分钟时间内和同学跑去食堂吃碗面条，然后理所应当地迟到十几分钟才进教室，并打赌班主任不会守在门口……多么美好的时光啊，美好而短暂。\n\n高考前夕，我玩得特别好的一朋友（他成绩比我好，高三的摸底考试基本都比预估的一本分数线高四十分，而我一般高十分左右）问我：\n\n「你要是没过一本线，会不会复读？」\n\n「不会」，我不假思索地回答到。\n\n「我也不会」，他透过黑框眼镜，深沉地看着我说：「除非我二本都没考上」。那是我们第一次比较正经地谈论我们的未来。\n\n那年是湖北省高考自主命题的最后一年，出卷老师似乎拼了命想让这届高考的学生记住他一样，数学卷异常地难。导致湖北当年的一本分数线是十几年来最低，而我，也倒在了我最擅长的数学上（没考到 80 分，我现在还觉得有些对不起数学老师）。\n\n去学校领分数条的那天，阴霾天空，我遇到了那朋友：\n\n「考多少分啊？」，他问我。\n\n「不好意思说」，我摇了摇头，眼睛望向地面。\n\n「我不信你还能有我低，我四百五都没到」，我猛地抬起了头望向他，却只看到他嘴角的苦涩。那是我们第二次，无比正经地谈论我们的未来。\n\n高中啊，以「我没过一本线，他没过二本线」这样荒诞地结束了。\n\n---\n\n高中部分已完，由于大学部分需要写的东西比较多，我会另起一篇文章，敬请期待。"},{"title":"奇安信（原 360 企业安全）服务端开发面经","subtitle":"","url":"/posts/d42e79bb/","date":"2019-05-18T04:34:04.000Z","updated":"2019-05-19T04:02:43.000Z","category":"分享境","tags":["面经","奇安信","服务端"],"content":"现在说起来我自己都不信，之前我居然一直以为秋招是为当年毕业的学生准备的，直到我们班有人签了百度，我才知道秋招原来是为次年的应届生准备的😅，不过当时已经十月，秋招已经基本结束，于是只好准备来年的春招了。\n\n<!--more-->\n\n话说回来，本次春招我准备的也不算特别充分，很大一部分原因是毕业设计选题选了一个自己陌生的领域，并且还准备评优秀毕业论文，所以年后一直在准备毕设，空闲时间才会找公司投递。我对公司还是挺挑的（钱多事少离家近，起码要满足两点吧），而且还要招 Python 岗，可供选择的公司就更少了，找来找去也只投递了一家公司——奇安信（原 360 企业安全），所幸最后也拿到了 Offer。\n\n本文是对这次招聘流程的一个总结。\n\n## 笔试\n\n我是三月底投递的简历，四月中旬发来的笔试通知。有两道编程题，一道非递减数列（AC 67%，这题 Python3 的输入格式有问题），一道实现哈希表（AC 91%，同上，Python3 输入仍然有问题），这两题难度均介于 Leetcode 的 Easy 和 Medium 之间。\n\n由于两道编程题都没 100% AC，我以为凉了，结果在 4 月 23 日晚上十一点发来面试通知，通知我 25 号下午面试，当时就有点慌，面试时间太近，只有一天时间准备（24 号上午还要去看复联 4 首映，本来想不去了，后来想想首映一辈子就这一次😅），于是看完电影赶紧把数据库和操作系统还有计算机网络复习了一下。\n\n## 一面（30 分钟）\n\n等了小半个钟，面试官才姗姗来迟（可能是因为面试的太多了），面试官是一个中年微胖的大叔：\n\n1. 先做个自我介绍吧\n2. 元组和字典的区别（我当时以为我听错了，心想这俩完全没一点相似的啊）\n3. Node.js 的特性，与 Python 的区别（这一点应该是看我简历上有写）\n4. Python2 和 Python3 的区别\n5. Python2 和 Python3 在多线程有什么区别（我当时想了一下，觉得好像没区别，就说 Python2 多线程不太了解）\n6. 说说多线程的锁\n7. 多进程有什么用\n8. 说说函数式编程的特性\n9. 框架了解吗，说说 Django 和 Flask\n10. Django 的一次请求流程\n11. Django 里用了哪些标准库（好奇怪的问题😳）\n12. 写一个 Python 的注解（我以为他问的是 Type Hints，后来意识到可能说的是装饰器，就把装饰器的概念说了一遍，问他具体是哪一个，结果他也说不清楚，说自己好久没接触 Python 了，于是这个问题就过了）\n13. Numpy 了解吗？Numpy 里新增了什么类型？为什么 Numpy 效率高？\n14. Elasticsearch 用过吗，说说分片（我当时已经很久没用 ES 了，有些基础概念忘掉了，就说我只知道分桶，不清楚分片）\n15. 算法了解吗？说说堆排序和快排（不知道堆排序，就说了一下快排）\n16. 手撕代码——单链表赋值（还比较简单）\n17. Python 和 C 的区别\n18. 有什么想问我的（这里我作了一个小死，问了一下面试官觉得我怎么样？回答是思维比较发散、活跃，也比较喜欢钻研新东西，但对某些东西背后的原理挖掘不够深入，总体来说算挺不错了😉）\n\n与我想象中的面试还是有很大的区别，计算机网络一点没问，操作系统一点没问，数据库一点没问（让我一天的复习付诸流水😅），总体来说都是按照简历来发问，很 Nice 的体验。\n\n几分钟后收到二面的短信。\n\n## 二面（18 分钟）\n\n也等了小半个钟，二面面试官应该是小组或者部门的 Leader 了，特别温和，居然用了「您」来称呼我：\n\n1. 自我介绍\n2. 说说你印象最深的一个项目（我说去年的实习可以吗？他说可以），我说了七八分钟，他偶尔会打断并针对我的叙述提问\n3. 你觉得这段实习你在其中学到了什么，阐述了三个方面，又说了五分钟\n4. 听说你想去武汉啊？（对，离家比较近）来北京吧，武汉可能没有这个岗位了，北京钱多，又是核心部门，我目前的组就是服务端开发的 blabla...\n5. 然后就没问我问题了，说会在技术方面给我评分，一会 HR 会有三面，问一些其它的事情\n\n原本我以为一面没问数据库、网络，二面怎么也该问了吧，可是还是没有（看来是真的不按套路出牌啊😅），面试官超级 Nice。\n\n几分钟后收到三面的短信。\n\n## 三面（28 分钟）\n\n这一面 HR 问的问题实在是太多，跟查户口一样，又没有录音，只能回忆起一部分了：\n\n1. 你是哪人\n2. Docker 为什么最近火了起来\n3. Docker 和虚拟机有啥区别\n4. 实习的时候具体做什么，大概多久适应团队\n5. 为什么读计算机专业（开始讲故事）\n6. 高考失常了吗（开始讲故事 × 2）\n7. 为什么不复读（开始讲故事 × 3）\n8. 想过考研吗，为什么不考研？\n9. 有其它公司的面试吗（惭愧，没有）\n10. 你觉得前两位面试官怎么样\n11. 你觉得笔试题难度怎么样\n12. 你对自己的评价怎么样\n13. 对自己的职业规划是怎么样\n14. 公司如果要求转岗你怎么办\n15. 工作地点想选择哪个城市\n16. 对我们公司了解吗\n17. 有什么想问我的\n    1. 有调休吗😅（HR 还有点蒙，转头问了一下其它人）\n    2. 薪资待遇怎么样（HR 说最近在集中面试，等面试结束后会逐一评定薪资）\n\n我这俩提问都是比较迫切的，问的并不算好，不过和 HR 聊天还是比较愉快的。\n\n## 后记\n\n等待 Offer 的过程不可谓不煎熬，5 月 16 号在群里看到有人说接到 Offer Call 了，当时心里就凉了半截，17 号晚上九点看到有人已经收到 Offer 了，一看我的邮箱，心另半截也凉了。结果十点一看发现我也收到了😅，当天激动得一晚上没睡好。\n\n祝各位都能拿到心仪的 Offer~"},{"title":"高校生使用教育网的一点姿势","subtitle":"","url":"/posts/36b4c1ab/","date":"2019-04-27T01:53:04.000Z","updated":"2019-04-27T01:53:04.000Z","category":"实验室","tags":["IPv6","教育网","破解校园网"],"content":"最近一直忙于毕业的相关事项，所以也没有新文章产出——并非是找不到写作素材，实在是没写作时间。虽然这几天依旧很忙，但总算也抽出了一点时间完成了本文，希望能给广大高校生在办理宽带时带来一些帮助。\n\n<!--more-->\n\n## 前言\n\n目前大部分高校的校园宽带应该都对使用者作出了诸多限制，比如：一号一机，禁止使用路由器（破解后才可以共享）；与校方合作垄断，导致价钱比家用宽带贵一大截等。在校生也只能被迫接受——毕竟，你总不能真的不用电脑上网吧？\n\n好在目前越来越多的高校里校园网已经开始支持 IPv6 了，而一般校园网只针对 IPv4 的流量计费，对 IPv6 产生的流量是不计费的，至于原因，我猜测有两方面原因：一是 IPv6 相关技术还不是特别完善，IPv4 计费系统可能需要修改；二是目前国内 99% 的网站都不支持 IPv6，而纯 IPv6 环境下是无法访问 IPv4 网站的，所以干脆就没做这一限制。\n\n> 连接上校园网后，不要认证，戳[这里](https://ipv6-test.com/)来测试是否支持 IPv6，当然也可以直接打开 Google，目前 Google 可以通过 IPv6 直连。\n\n但，谁让我是学计算机的呢，这并不能难倒我。既然无法通过 IPv6 直接连接 IPv4 的网站，那利用一个同时支持 IPv4 和 IPv6 的 VPS 做一层代理不就可以绕过这一限制了吗？原理见下拓扑图：\n\n![原理](https://ae01.alicdn.com/kf/HTB1Q5w0S9zqK1RjSZFp761kSXXaO.png)\n\n这就意味着，只要你具备 IPv6 网络，**便可以通过此方法绕过诸多限制，从而免费上网**。\n\n## 获取 IPv6\n\n目前比较出名的 VPS 服务商除搬瓦工外，大部分都原生支持 IPv6 连接，包括：Vultr、Linode、DigitalOcean。而搬瓦工的 VPS 中 OpenVZ 架构自带 IPv6，KVM 架构则需要利用 Tunnel Broker 技术来提供 IPv6 隧道给只支持 IPv4 的用户（我的搬瓦工 CN2 主机便是通过 Tunnel Broker 来获取 IPv6 支持的，这也是搬瓦工的客服推荐的方案），它定义在 [RFC 3053](https://tools.ietf.org/html/rfc3053)。\n\n**如果你的 VPS 原生支持 IPv6 连接的话，便可以跳过这一步。**\n\n### 获取 Tunnel\n\n目前 Hurricane Electric 免费提供 Tunnel Broker 服务（我 TM 吹爆！），该公司运营了世界上以对等数目计算的最大 IPv6 网络，所以服务方面是不用担心的。戳[这里](https://www.tunnelbroker.net/register.php)注册。\n\n随后点击左侧的 `Create Regular Tunnel`，再在框内输入 VPS 的 IP 地址，再选择一个地区服务器来作为隧道的一端，这里建议根据服务器的地区来就近选择，我这里选择的是 Los Angeles。\n\n![Tunnel 面板](https://res.cloudinary.com/wincer/image/upload/v1556005626/ovm2o8n4mjlp7wsqrp3g.png)\n\n### 配置 IPv6\n\n创建成功后，在以下页面选择你的系统，如果是 Debian 系就选择 Debian/Ubuntu，其余就选择 Linux-net-tools。\n\n框中会出现几行命令，登陆 VPS，依次运行这几行命令就行了。\n\n![IPv6 配置命令](https://ae01.alicdn.com/kf/HTB1p5F6SxnaK1RjSZFB763W7VXaM.png)\n\n**第四行被我抹去的地址便是公网 IPv6 的地址。**\n\n> 如果对  Tunnel 的速度需要更换的话，可以删除该 Tunnel 后在 VPS 运行  `modprobe -r sit` 命令或者直接重启，再重新创建一个 Tunnel。\n\n### 测试\n\n不出意外，这时 VPS 已经可以使用 IPv6 连接了：\n\n![测试 IPv6 连接](https://ae01.alicdn.com/kf/HTB1QJtRSxjaK1RjSZFA762dLFXaT.png)\n\n需要注意的是，如果选择非北美地区的服务器，会绕道美国，所以这里的 PING 值会略高。\n\n## 配置代理\n\n代理可以选择 Shadowsocks，但本次要介绍的不是它，而是另一款代理软件：V2Ray。该代理软件比 Shadowsocks 多了许多种伪装流量的方法，且占用内存更低（毕竟是 Go 写的），这对于小内存的 VPS 来说，非常重要。只不过其配置文件比 Shadowsocks 要劝退小白一些。\n\n### 服务端安装\n\n输入以下一行代码进行安装，系统需支持 Systemd：\n\n```bash\nbash <(curl -L -s https://install.direct/go.sh)\n```\n\n有关更详细的安装教程见[官方文档](https://www.v2ray.com/chapter_00/install.html#linuxscript)。\n\n### 服务端配置\n\n如果是通过以上命令安装的话，配置文件在 `/etc/v2ray/config.json` 目录，以下是我的配置文件，没有流量伪装等进阶配置：\n\n```json\n{\n  \"log\": {\n    \"loglevel\": \"warning\",\n    \"access\": \"/var/log/v2ray/access.log\",\n    \"error\": \"/var/log/v2ray/error.log\"\n  },\n  \"inbounds\": [{\n    \"port\": 10086,\n    \"protocol\": \"vmess\",\n    \"settings\": {\n      \"clients\": [\n\t    { \n\t      \"id\": \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n\t      \"alterId\": 4\n\t    }\n      ]\n    }\n  }],\n  \"outbounds\": [{\n    \"protocol\": \"freedom\",\n    \"settings\": {}\n  }]\n}\n```\n\n`inbounds`：入站配置，是一个**数组**。\n\n注意协议这里填的是：`VMess` ，由 V2Ray 原创的一份加密传输协议。\n\n`clients` 是一个 Object 数组，每一个元素里的 id 必须满足 UUID 格式，且服务端客户端需保持一直，作用类似于 Shaowsocks 中的密码。\n\n`outbounds`：出站配置，也是一个**数组**。\n\n### 客户端安装\n\nLinux 客户端的安装与服务端一致。\n\nWindows 建议使用 [V2RayN](https://github.com/2dust/v2rayN/releases)，带有图形化界面，下载 `V2RayN-Core.zip` 解压，下载 `V2RayN.zip` 解压出的 .exe 文件放入刚刚的目录下。\n\n目录应该与以下类似：\n\n``` bash\n.\n├── config.json\n├── geoip.dat\n├── geosite.dat\n├── guiLogs\n│   ├── 20190421.txt\n│   ├── 20190422.txt\n│   └── 20190423.txt\n├── guiNConfig.json\n├── pac.txt\n├── readme.md\n├── user-wininet.json\n├── v2ctl.exe\n├── v2ctl.exe.sig\n├── v2ray.exe\n├── v2ray.exe.sig\n├── v2rayN.exe\n├── wv2ray.exe\n└── wv2ray.exe.sig\n```\n\n### 客户端配置\n\n#### Linux\n\n格式与服务端一致，你需要修改的仅有 address 和 id 部分：address 填写服务端的 IPv6 地址；id 需与服务端一致。 \n\n```json\n{\n  \"log\": {\n    \"loglevel\": \"warning\",\n    \"access\": \"/var/log/v2ray/access.log\",\n    \"error\": \"/var/log/v2ray/error.log\"\n  },\n  \"inbounds\": [{\n    \"port\": 1081,\n    \"listen\": \"127.0.0.1\",\n    \"protocol\": \"socks\",\n    \"settings\": {\n      \"netword\": \"udp\"\n    }\n  }],\n  \"outbounds\": [{\n    \"protocol\": \"vmess\",\n    \"settings\": {\n      \"vnext\": [{\n        \"address\": \"xxxx:xxxx:xxxx::xxxx\",\n        \"port\": 10086,\n        \"users\": [\n          {\n            \"id\": \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n            \"alterId\": 4\n          }\n        ]\n      }]\n    }\n  },{\n    \"protocol\": \"freedom\",\n    \"tag\": \"direct\",\n    \"settings\": {}\n  }]\n}\n```\n\n这时，打开网络代理，填入：\n\n![](https://ae01.alicdn.com/kf/HTB1ewfaXvc3T1VjSZLe762ZsVXa0.png)\n\n注意，**这里一定要选择手动代理模式**，不能使用 PAC/自动模式，因为我们的目的是要本地的所有流量都走代理。而 PAC 仅会当遇到被墙的 IP 时才会走代理。\n\n#### Windows\n\n双击 V2RayN.exe 后，点击右上角的`添加 VMess 服务器`：\n\n填入地址，端口，id 即可：\n\n![Windows 配置](https://ae01.alicdn.com/kf/HTB1gzJSSrrpK1RjSZTE763WAVXaO.png)\n\n再将右下角的系统代理模式改为全局模式，道理同 Linux 类似：\n\n![](https://ae01.alicdn.com/kf/HTB1YdVUSq6qK1RjSZFm7600PFXac.png)\n\n这样，不出意外的话，就已经成功了，你的仅支持 IPv6 的电脑已经该可以通过代理来访问非 IPv6 的网站了。\n\n## 连接测试\n\n### 网速测试\n\n正好手头最近入了一个原生支持 IPv6 的 VPS，贴一下与搬瓦工的对比，以下均在同一时段做的测试：\n\n![原生 IPv6](https://ae01.alicdn.com/kf/HTB1Q14Ege3tHKVjSZSg7604QFXac.png)\n\n![搬瓦工 + Tunnel Broker](https://ae01.alicdn.com/kf/HTB1xkAOS7voK1RjSZFw763iCFXay.png)\n\n原生支持 IPv6 的机器可以直接观看 2K 视频并且不会出现卡顿现象（可以看到已经缓冲了一分钟了），而使用 Tunnel Broker 的就没这么好了，不仅连接速度只有三分之一，而且无法较为流畅的观看 2K 视频，时不时会出现卡顿。考虑到 YouTube 的线路优化已经很强了，国内的视频或者直播应当只能观看 720p（码率最好不要超过 3000）甚至更低了，而前者直播时蓝光 8M 无压力。\n\n### 延迟与丢包测试\n\n首先是搬瓦工的，经过了 15 个节点，教育网的入口和出口丢包率很高：\n\n![搬瓦工 + Tunnel Broker](https://ae01.alicdn.com/kf/HTB1X9ZNS3HqK1RjSZFE763GMXXa0.png)\n\n这是原生 IPv6 的，经过了 19 个节点，同样教育网的入口和出口丢包率较高（但还不是最高的）：\n\n![原声 IPv6](https://ae01.alicdn.com/kf/HTB17MsKS3HqK1RjSZFg7617JXXaj.png)\n\n可以看到其原生自带 IPv6 的主机其实也用的是 HE 的 IPv6 网络（前 13 个节点都一样），那么看来是返程的时候出问题了：\n\n![原生的 IPv6 返程](https://ae01.alicdn.com/kf/HTB1tAUOS9zqK1RjSZFj762lCFXaU.png)\n\n![搬瓦工的返程](https://ae01.alicdn.com/kf/HTB1GPs0S7voK1RjSZFw763iCFXan.png)\n\n果然，问题出在返程上面，原生的 IPv6 并没有走 HE 的线路，丢包率为 0。而相比于浏览网页，在看视频时返程的网络状况会直接影响观看体验，这一点也确实在之前的网速测试中体现了。\n\n所以，购买建议是：\n\n如果你还没有购买 VPS 的话，建议购买原生自带 IPv6 连接的 VPS，使用体验会好很多，不过由于电脑是全局的代理，所以要注意 VPS 流量的使用哦~\n\n最后附赠一个国内的 IPv6 电视网站：[清华大学 IPTV](<https://iptv.tsinghua.edu.cn/v2/list/channel/%E9%AB%98%E6%B8%85%E9%A2%91%E9%81%93>)。\n\n参考：\n\n1. [给搬瓦工 KVM 版 VPS 配置 IPv6 支持（基于 Linux CentOS 7）](https://www.bandwagonhost.net/2144.html)\n2. [Project V 官方网站](https://www.v2ray.com/chapter_00/start.html)"},{"title":"Linux 与 Android 同步剪贴板的通用方案","subtitle":"","url":"/posts/d691e748/","date":"2019-01-12T04:01:23.000Z","updated":"2019-01-12T04:01:23.000Z","category":"实验室","tags":["Clipboard","剪贴板"],"content":"按照惯例，还是在每篇文章的开头扯几句不相关的：元旦前就从学校回家了，在家的十几天过得很是舒坦：闲的时候，上午玩两小时游戏或者看看直播，下午就看会 Coursera，晚上有时间就看部电影，没整段的空余时间就找朋友聊聊天、刷刷 V2EX；当然在不闲的时候也是做了一些事的，就比如本文将要说到的——让移动平台和桌面平台同步剪贴板的方案。\n\n<!--more-->\n\n我为什么想到做这个呢：两周前，我把用了一年半的 Manjaro 格式化了（忍受不了 KDE 巨多的 Bug，还有硬盘都被我用完了），装上了 Ubuntu，桌面环境选择了 Budgie——一个新出的 DE。比 GNOME 漂亮，比 KDE 稳定，稍加配置即可满足我这个强迫症的审美需求：\n\n![桌面截图](https://ae01.alicdn.com/kf/HTB15xNmaOzxK1RjSspj763S.pXaS.png)\n\n从 KDE 转成 Budgie 之后，最让我不习惯的就是手机和电脑再也不能愉快地共享剪贴板和文件了，当然我也在网上找了一些现成的解决方案，但体验都不佳，于是我便考虑自己造一个轮子。\n\n## 设计思路\n\n由于移动端（客户端）、桌面端（服务端）二者需要进行数据的双向传输，HTTP 协议肯定是无法做到了：于是选用了 WebSocket 作为底层的传输协议。同时，为了让适用性更广，桌面端开发选择了 Golang；移动端则使用 React Native 开发。但这两门高级的语言（Golang、JavaScript）都无法为剪贴板添加监听事件，于是我只好自己用轮询的方式对比当前剪贴板的内容与上一次内容的差异，再考虑是否发送数据。\n\n## 桌面端\n\n桌面端的开发语言选择 Golang 其实我是有些不情愿的：\n\n1. 太过高级：无法提供系统底层的 API（比如监控剪贴板）；\n2. 语法太过丑陋：我想把 log 信息封装一下，结果用 struct 封装了半天，代码反而看起来更「💩」了，还不如用 Switch，可 Switch 导致暴露出的接口又不够简洁 . . .\n\n其它语言我也找了个遍：Python 虽可监听剪贴板的变化（通过 gi 这个库），但这个库并没有办法跨平台，且我 Windows 没有安装编程环境，我也不想安装。\n\n总之，能监听剪贴板的无法跨平台，能跨平台的无法监听剪贴板。\n\nSo . . . 哪怕 Go 有万般不是，但在跨平台这一点的易用性上也足以让我抛弃其它的所有（纯静态链接库 + 交叉编译）。\n\n于是乎，\n\n「真香」。\n\n## 移动端\n\n其实我本想用 Flutter 来开发的，但遇到了一些问题：\n\n1. 在我电脑上无法热加载，这在修改样式的时候可太难受了；\n2. Dart 似乎无法在已有的 WebSocket 连接上绑定一个新的连接，即使原来的连接已经失效了（不知是 Bug 还是咋样）。\n\n于是我选择了 React Native。有了 React 的基础，上手确实很快，并且 JavaScript 写起来感觉还是挺爽的。\n\n之所以会有刚刚提到的（重新绑定 WebSocket 的）需求，是因为在不同的网络环境中，电脑的 IP 可能有所改变，而我暂时想不到一个方法让手机自动识别同一网络的哪一台电脑使用了共享剪贴板的工具（逐一扫描 IP？那也太丑陋了）。\n\n所以在初始化连接时需要手动输入一次电脑的 IP 地址，随后地址信息会被保存，之后就不用再输入了。\n\n## 使用\n\n只需保持这两个软件在后台，会自动监控剪贴板的内容并发送。\n\n![桌面端](https://ae01.alicdn.com/kf/HTB1nepnaIfrK1RkSnb4760HRFXaf.png)\n\n![移动端](https://ae01.alicdn.com/kf/HTB1dj0maN_rK1RkHFqDq6yJAFXam.jpg)\n\n## 下载\n\n由于代码写的有点不满意，功能也不太完善，等以后有空重构之后加上文件共享功能，会开源的。这里先放出各平台的可执行程序：[戳我👈](https://bit.ly/clipboard_shared)。\n\n---\n\n愿能有所帮助。"},{"title":"我的 2018 轨迹","subtitle":"","url":"/posts/e4e1357d/","date":"2018-12-27T02:52:16.000Z","updated":"2018-12-27T02:52:16.000Z","category":"碎碎念","tags":["2018","随笔"],"content":"实习回到学校十几天后，便开始思考年终总结怎么写，之所以这么早就开始构思，或许是我笃定在这 2018 最后的半个月内也不会发生什么值得记录的大事。当然我也期待着能发生什么事来冲击一下现有的生活——在校的时光实在是太安逸了，想来是应当正处于心理空窗期了。\n\n<!--more-->\n\n本次总结将会就学习、生活、工作（实习）三个方面来描绘一下今年的生活轨迹。\n\n## 学习\n\n我应该算是「兴趣驱动学习」的典范了：每当我抱着很强的目的性或功利性去学习的时候，总是坚持不了多久。Princeton 的算法课从两年前就开始学，学到现在也才把排序看完。\n\n不过今年在学习方面还是有不少收获的：借助 Coursera 这一平台，观看了 Node.js 的开发，Golang 的入门等网课。我在学习一门新语言的时候总会选择看视频，如果从一开始就看书的话，我会觉得有些乏味和枯燥，尤其是动辄上千页的技术类书籍，看厚度就有一种劝退感。而在入门后，想要深入了解一门的语言的底层，我才会选择翻阅一些书籍。\n\n除了学习新东西之外，对 Functional Programing（函数式编程，以下简称 FP）也有了更深刻地理解。比如，为什么 FP 中多以递归来代替 Imperative programming（命令式编程）中的循环语句。原因在于数学家和逻辑学家们验证递归的正确性比验证循环的正确性要容易得多。\n\n一个很简单的例子，分别用 Java 和 Haskell 实现快速排序：\n\nJava：\n\n```java\npublic class Sorter {\n    public static <T extends Comparable<? super T>> void quicksort(T[] list) {\n        quicksort(list, 0, list.length - 1);\n    }\n\n    private static <T extends Comparable<? super T>> void quicksort(T[] list, int low, int high) {\n        if (low >= high)\n            return;\n        int i = low - 1, j = high + 1;\n        T pivot = list[low];\n\n        for (;;) {\n            do {\n                ++i;\n            } while (list[i].compareTo(pivot) < 0);\n            do {\n                --j;\n            } while (list[j].compareTo(pivot) > 0);\n            if (i >= j)\n                break;\n            T tmp = list[i];\n            list[i] = list[j];\n            list[j] = tmp;\n        }\n\n        quicksort(list, low, j);\n        quicksort(list, j + 1, high);\n    }\n}\n```\n\nHaskell：\n\n```haskell\nquicksort :: (Ord a) => [a] -> [a]\n\nquicksort[] = []\n\nquicksort(pivot : rest) = \n    quicksort[x| x <- rest, x < pivot]\n    ++ [pivot]\n    ++ quicksort[x| x <- rest, x >= pivot]\n```\n\n以上两段代码，哪一段的正确性更容易验证？答案不言自明。\n\n对于前者，指定了计算的详细过程，而后者，仅指定了计算的规则（原则）。这也是 FP 的特点之一：不关心如何计算，更关心计算的结果（的正确性）。\n\n「正确」是 FP 设计的重中之重。究其根本在于 FP 的鼻祖 Lisp 与 λ 演算那密不可分的联系。\n\n## 生活\n\n生活方面似乎并没有什么改变，相比去年——好吧，并不是。我的体重告诉我比去年重了 ×× 斤。去杭实习不仅没瘦，反而重了。而且似乎睡得还更晚了，不过似乎「互联网依赖症」减轻了不少，比如本文初稿就是纯手写的。\n\n在读书方面，算是有了一些进步，今年在豆瓣读书上为 15 本书贴上了「已读」的标签（不过仍未达到两周一本的目标）。文学类和技术类都有，技术类对我影响最大的毫无疑问就是《流畅的 Python》这本书了，断断续续地看了近三个月，做了万余字的笔记。\n\n至于文学类嘛，《哲学家们都干了些什么》是让我眼前一亮：枯燥的哲学似乎在作者笔下都「皮」了起来。但印象最深地却是伊坂幸太郎的《金色梦乡》，等下，《白夜行》好像印象也很深刻，《解忧杂货店》构思也很巧妙（这么说来我果然很喜欢日系推理），钱锺书的《围城》也不错...好吧，文无第一，今年看的文学类书籍都非常不错。\n\n接下来就该到电影方面了：今年在豆瓣电影为 72 部电影（包括剧集）贴上了「已看」标签。比较喜欢的剧集似乎都是日剧（非自然死亡，胜者即是正义）；电影的话，《我不是药神》一枝独秀，在电影院里哭得还朝旁边的妹子借纸；动漫也看了不少：来自深渊（新番），怪化猫（旧番）都不错，属于能给灵魂带来冲击的番。\n\n谈话类节目仍然强推《圆桌派》，可惜第三季之后窦文涛似乎就跑路了。纪录片这块则必须让陈晓卿的《风味人间》安排上，对于一个吃货来说，本节目的美食引起了强烈不适。不过还是作为吃货，即使吃不着，退而求其次，能过过眼瘾也是一种享受。此外，本节目还会介绍与美食相关的风土，人情，文化，品味等，美食之所以被冠以「美」字，绝不仅仅在于它的味道，更在于人们赋予它的某种意义，或者说是其背后所蕴含着的丰富内涵，这才是其绵延不绝的生命力所在。\n\n## 工作\n\n如果说搭建这个博客是去年我做的最有意义的事，那么实习应该就是今年我所做的最有意义的事了。\n\n九月份时我并没有走校招，原因有两方面：一方面我并没有发现有什么企业校招 Python 岗（大部分都是前端和 Java）；另一方面是估计实习时间也不会太久，本学期期末学校肯定一大堆事，于是也没怎么考虑公司，面了一家，就进去了。\n\n我面的是 Python 岗，本以为进来之后也是写 Python。谁知阴差阳错上了 Node.js 的贼船，当然这有一部分的原因在于我：Leader 问我能不能用 Node.js，我说之前接触过一些，然后他就给了我几天时间让我熟悉一下。不过好在是从零开始写的，不用「接盘」前人的代码，倒是省了不少事。在公司待的两个半月时间内，也帮同事解决了不少 Python 问题，不过多是业务方面的逻辑。除此之外，收获最大的就是 Elasticsearch（以下简称 Elastic）的相关组件（我编写的 API 是直接与 Elastic 交互的）的部署和维护了，因为个人的项目很难直接接触到 Elastic 这一庞大的生态系统。\n\n不过我是有些认为面试的时候公司没有把我的水平面出来（颇有些怀才不遇的感觉），简历上写的大部分细节都没问。只是问了问笔试题，感觉有点憋屈。能力未充分得到挖掘带来的问题就是资源的浪费。一方面是职员能力的浪费（能力得不到体现），一方面是公司资源的浪费（项目进度跟不上，业绩无法按时达标），于是就会导致某些人上班只需要花费很少的时间即可完成公司的任务，剩下一堆可自由支配的时间，而另一些人不仅上班时间不够用，还需要加班才能勉强完成。在这个公司时，我应当时属于前者，虽然有些不好意思，但我在公司的空余时间还是会学些自己的东西。\n\n同时我也感觉写业务写久了，脑子里也只剩下业务了。对技术反而没什么提升，而对于当下的我来说，技术仍远比业务重要。正在这时候，学校要求我们回去准备毕设的事。于是，我辞职了，开始享受这为数不多的大学时光。\n\n如果说之前的我还对未来的道路存疑的话，那么这两个半月的实习生活让我开始明确了未来的道路——Python 开发相关。同时也明白：校园的时光虽然让人十分享受，但也总有毕业的那一天。如果说大学的象牙塔是我最后的天堂，那就让我从天堂里一步一步地走出来。\n\n---\n\n似乎该结尾了，我不想再像去年一样为我的 2019 立什么 Flag 了（去年的 Flag 一大半都没实现），不过我想毕业的年份应当过得比较有趣吧？"},{"title":"Elasticsearch 集群备份指南","subtitle":"","url":"/posts/92d76830/","date":"2018-10-27T13:55:12.000Z","updated":"2018-10-27T13:55:12.000Z","category":"分享境","tags":["Elasticsearch","备份","恢复","backup"],"content":"Elasticsearch 官方对其的定义是一种搜索引擎，但我更喜欢把它当作一种非关系型数据库来看待，而作为数据库来看待的话，保障其中数据的安全性和可靠性自然是重中之重了。\n\n首先声明，本文对 Elasticsearch 数据的备份是基于[官方提供的 API](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html)，其它的诸如 [elasticsearch-dump](https://github.com/taskrabbit/elasticsearch-dump) 等第三方工具暂且不谈。官方的提供的备份方式是一种 Snapshot，其中备份路径可以选择云端或本地，本文想就备份集群数据到本地写一份指南，并对遇到的问题做一些解答。 \n\n<!--more-->\n\n## 搭建集群文件系统\n\n为了创建一个 Elasticsearch 集群的 Snapshot，首先必须先搭建一个集群文件系统，用以确保集群的所有节点对同一个目录具有操作权限——这里推荐使用 NFS（Network File System）。\n\nNAS 需要指定集群的某一个节点的文件夹作为服务器来提供硬盘存储，也是 NAS 存储文件的实际位置，集群的其他节点作为客户端挂载服务端的共享文件夹。\n\n### 安装\n\n```shell\nsudo apt install nfs-kernel-server # 服务端\nsudo apt install nfs-common # 客户端\n```\n\n### 创建共享文件夹\n\n这里是我踩的第一个坑。**服务端的共享文件夹所有者必须也是运行 Elasticsearch 程序的用户**，不然 Elasticsearch 是无法将数据备份到该文件夹的，比如运行 Elasticsearch 的用户是 els 的话，可以用如下命令来创建共享文件夹：\n\n```shell\nsudo -u els mkdir /path/to/backups -p\n```\n\n### 修改配置文件\n\n在服务端的 `/etc/exports` 中添加以下内容：\n\n```ini\n/path/to/backups 192.168.1.1(insecure,rw,sync,no_subtree_check,no_root_squash,no_acl)\n```\n\n其中 `192.168.1.1` 就是服务器本机的 IP。括号内的是配置参数，稍稍解释一下：\n\n- `insecure`：允许客户端从大于 1024 的端口号连接。\n- `rw`：所有连接者都具有读写权限。\n- `sync`：将更改都提交到稳定存储之后再回复请求。\n- `no_subtree_check`：禁用子树检查。\n- `no_root_squash`：关闭 root 压缩。\n- `no_acl`：不要向客户端显示 ACLs。\n\n更多的参数可以参考[这里](https://linux.die.net/man/5/exports)。\n\n### 生效配置\n\n```shell\nexportfs -r\n```\n\n这时你可以使用 `showmount -e localhost` 来查看本机的挂载情况：\n\n```shell\n/path/to/backups 192.168.1.1\n```\n\n### 客户端\n\n注意，客户端也一定要使用运行 Elasticsearch 的用户的权限来创建相同的文件夹，这一点非常重要。然后把服务端的文件夹挂在到各个节点：\n\n```shell\nmount -t nfs 192.168.1.1:/path/to/backups /path/to/backups\n```\n\n没有报错的话，就挂载成功了。\n\n## Elasticsearch 配置\n\n需在每一个节点的 `elasticsearch.yml` 中加上一行：\n\n```yaml\npath.repo: [\"/path/to/backups\"]\n```\n\n然后重启 Elasticsearch。\n\n这时就可以尝试创建一个 Snapshot 的仓库了：\n\n```json\nPUT /_snapshot/my_backup\n{\n    \"type\": \"fs\",\n    \"setting\": {\n        \"location\": \"/path/to/backups\"\n    }\n}\n```\n\n如果没有报了权限错误的话，就 OK 了。\n\n如果报了权限错误，请检查 Elasticsearch 对该文件夹是否具有写权限。如果确认具有写权限，那么就需要把集群各节点运行 Elasticsearch 的用户的 UID 和 GID 统一起来，具体做法见附录。这里是我踩的第二个坑。\n\n## 创建一个备份\n\n你可以以如下命令来创建一个备份：\n\n```json\nPUT /_snapshot/my_backup/snap1?wait_for_completion=true\n{\n\t\"indices\": \"index_1,index_2\"\n}\n```\n\n其中 `wait_for_completion` 参数并不会马上返回结果，而是等备份完成之后再返回结果，如果备份的索引很多的话，可能会花费很多时间才返回，所以并不建议加上这个参数。可以为 `PUT` 加上请求体，指定索引，如上指定 `index_1`、`index_2` 两个索引备份，如果不加请求体的话会默认备份全部索引。\n\n当 Snapshot 正在生成中的时候，可以使用如下命令来获取备份的进度：\n\n```json\nGET /_snapshot/my_backup/snap1\n```\n\n其返回的 `state` 项的值即是备份进度条。\n\nElasticsearch 是采取增量备份的形式，但需注意，Snapshot 不可重复创建，也就是说 Snapshot 的名字不能相同。\n\n## 从备份中恢复\n\n可采取如下命令从 Snapshot 中恢复：\n\n```json\nPOST /_snapshot/my_backup/snap1/_restore\n```\n\n默认所有的索引都会恢复，当然你也可以指定索引：\n\n```json\nPOST /_snapshot/my_backup/snap1._restore\n{\n    \"indices\": \"index_1,index_2\"\n}\n```\n\n而有关恢复的进度，Elasticsearch 并不提供查询像备份进度那样的 API，所以只能使用 [indices recovery](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-recovery.html) 和 [cat recovery](https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-recovery.html) 来查询恢复进度。\n\n与备份和恢复更详细的讲解请参照[官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html)。\n\n## 附：更改 UID 和 GID 的方法\n\n首先假设各节点运行 Elasticsearch 的用户名为 `els`。先假设：他的旧 UID 为 1005，旧 GID 为 2000，要把他改成 UID 为 2005，GID 为 3000 的新用户。\n\n首先为 `els` 更改新的 UID 和 GID：\n\n```shell\nsudo usermod -u 2005 els\nsudo groupmod -g 3000 els\n```\n\n这就算完成了，可以用 `id els` 命令来查看用户的 UID 和 GID 是否被成功更改。\n\n当然，这只是把用户名的 UID 和 GID 做了简单的更改，还需要把原用户的所有文件、目录的所有者都改成新的，不然是无法成功运行 Elasticsearch 的，会报权限错误。\n\n以下命令来更改：\n\n```shell\nsudo find / -group 2000 -exec chgrp -h els {} \\;\nsudo find / -user 1005 -exec chown -h els {} \\;\n```\n\n其中 `-exec` 参数对每个文件执行 `chgrp` 和 `chown` 命令。`-h` 参数是对符号链接起作用，而不是应用文件。\n\n参考：\n\n- [Snapshot API not working](https://stackoverflow.com/questions/44955219/snapshot-api-not-working)\n- [elasticsearch backup and restore](http://smallasa.com/2017/03/09/elasticsearch-backup-and-restore/)\n- [How to Change a USER and GROUP ID on Linux For All Owned Files](https://www.cyberciti.biz/faq/linux-change-user-group-uid-gid-for-all-owned-files/)"},{"title":"Python 知多少（二）——继承","subtitle":"","url":"/posts/58dd3c61/","date":"2018-10-21T10:18:20.000Z","updated":"2018-10-21T10:18:20.000Z","category":"分享境","tags":["Python","继承","super","知多少"],"content":"好像又有一段日子没写技术类博文，翻了翻归档，发现最近一篇技术类文章已经是俩月多之前的事了，吓得我赶紧~~水~~写一篇的技术文章不然怕是要被人当成生活博主了。思来想去写些什么好，还是继续上次开的新坑，来聊聊 Python 中的继承。\n\n<!--more-->\n\n Python 作为一种具备多种编程范式的语言，面向对象自然也是它所具备的范式之一；而继承，作为面向对象程序设计的三大特性之一，其重要性也是不容忽视的。尤其这一特性在支持面向对象范式的语言里还有着不同的规则，如：C++ 同时支持普通继承和虚继承；Java 则是将其它语言中的 class 细分为 class 和 interface；还有 Python，「无痛地」支持多重继承。 \n\n## 多重继承 \n\n当一个语言支持多重继承时，至少需要解决这两个问题，以下图为例逐个分析 C++、Java、Python 对多重继承的支持情况：\n\n```markdown\n            A\n          /   \\\n         B     C\n          \\   /\n            D\n```\n\n1. 怎么处理共同的父类（基类、超类）\n2. 多个父类方法名重复的问题\n\n### C++\n\n首先看看 C++ 是怎么解决第一个问题的：C++ 在遇到这种情况时，最顶层的基类（A）会被创建两次，虽然可以通过将 A 设置为 B、C 的虚基类来解决，但这种虚继承是有副作用的：不只是在获取成员会更慢、占用内存更多，在和虚函数一起出现时会更难以理解：当 A、B、C、D 中都有一个虚函数 f 时， `D::f` 内部调用了 `B::f` 和 `C::f`；`B::f`和`C::f`内部都调用了`A::f`，于是 `A::f`就被调用了两次。当然也不是没有办法解决，[Template Parameters as Base Classes](https://books.google.com/books?id=PSUNAAAAQBAJ&lpg=PA767&ots=DrtrIigY4J&dq=27.4.%20Template%20Parameters%20as%20Base%20Classes&hl=zh-CN&pg=PA767#v=onepage&q&f=false) 就是 C++ 之父专门用于解决这个问题所开发的技术。\n\n第二个问题：如果这里的 B 和 C 同时实现了 `hello` 方法，同时 D 中没有实现 `hello` 方法，那么在调用 `d.hello()`（d 为 D 的 instance） 的时候会调用哪一个？编译器对于这种 Ambiguous base classes 的情况会直接报错，解决方法也简单粗暴，你必须显式指定 `d.B::hello()` 来调用 B 中的 `hello`。虽然以上两个问题在 C++ 中都解决的并不好，但也总归是解决了。下面来说说 Java。\n\n### Java\n\nJava 之父觉得 C++ 太难用了，于是他决定创造一门语言来取代 C++，这门语言需要保留 C++ 的优点，但又需要把 C++ 中较为混乱、复杂、危险的部分剔除（其中就包括了多重继承），于是，Java 就在这样的理念里诞生了。在 Java 诞生之初，对多重继承的支持少的可怜：一个 class 仅可继承（实现）多个 interface。本来是挺好的，但是在 Java 8 中为 interface 中的方法引入了 default 关键字，这就让 interface 里定义的方法可以有方法体了。\n\n那么 inteface 有了方法体之后，对这解决这两个问题有什么影响呢？将上例中的 A、B、C、D 换成四个 interface：\n\n第一个问题：Java 遇到了和 C++ 中的虚函数一样的问题，即 D 中如果想同时调用 B 和 C 中的某方法，且 B、C 中也调用了 A 的方法，那么 A 的该方法会重复运行两次。并且 Java 无法像 C++ 中使用模板技术来解决这个问题。\n\n第二个问题：Java 8 之前一个 class 可以实现多个 interface，即使 interface 有同名方法也没关系，毕竟 inteface 里定义的方法没有方法体，所以不会导致二义性。但有了 default method 之后，Java 反而无法处理这个问题了：D 不允许同时继承两个实现了 default 方法的接口（一个实现了，另一个没有实现也不行）。\n\nC++ 解决的不好，Java 压根就没解决。所以我认为 Java 在多重继承这一方面比 C++ 处理的更加不好。\n\n### Python\n\n终于到 Python 了，那么先来看看 Python 是如何解决第一个问题的：如果 D 中需要同时调用 B 和 C 中的 `hello` 方法，且 B、C 中也需要调用 A 的 `hello` 方法，那么仅需在 B、C、D 的该方法中写下 `super().hello()` 即可。因为继承图的缘故，Python 中的 `super()` 会沿着继承图顺序依次找寻 D 的所有超类。\n\n第二个问题：还是得益于继承图，当 D 中没有实现 `hello` 方法时，Python 会依据继承图顺序来寻找 D 的所有超类中是否有该方法，直到找到为止，而这个顺序也就是方法解析顺序。\n\nPython 完美的解决了这两个问题，这也是为什么我说 Python「无痛地」支持多重继承。\n\n既然这两个问题都是靠方法解析顺序解决的，那么它到底是个什么东西？看官先别急，下面会着重阐述。\n\n## 方法解析顺序\n\n方法解析顺序（Method Resolution Order，简写为 MRO），是描述该类自继承顶层超类的一种顺序，它在类中以 `__mro__` 属性存放，值是一个元组（`.mro()` 返回的则是一个列表，然而这列表并不可变），上例中的 D 的 MRO 为：\n\n```python\n>>> D.mro()\n[__main__.D, __main__.B, __main__.C, __main__.A, object]\n```\n\n这里的意思是：D 的最顶层超类为 `object`（新式类中所有类都继承自 `object`），其次是 A、C、B。\n\n下面来具体看看 Python 的代码是如何解决上文提到的第一个问题的：\n\n```python\nclass A:\n    def hello(self):\n        print(\"Hello from A\")\n\nclass B(A):\n    def hello(self):\n        print(\"Hello from B\")\n        super().hello()\n\nclass C(A):\n    def hello(self):\n        print(\"Hello from C\")\n        super().hello()\n\nclass D(B, C):\n    def hello(self):\n        print(\"Hello from D\")\n        super().hello()\n        \n>>> d = D()\n>>> d.hello()\nHello from D\nHello from B\nHello from C\nHello from A\n```\n\n在 D 中遇到的 `super()` 会沿着 D 的 MRO 依次向上寻找超类中的 `hello` 方法并执行，即依次执行 D -> B -> C -> A 这个顺序。\n\n那么为什么 Java 或 C++ 无法通过这种写法解决呢，原因在于 Java 的 `super` 在多重继承中必须指定父类是哪一个，因为编译器是无法获知你想要运行的是哪一个父类的方法。而一旦指定了父类（B），那么与这个父类同时继承的另一个父类（C）你也必须要指定，而这两个父类又具有相同的更高层次的父类（A），所以就导致了最顶层的父类（A）中的方法被调用了两次。\n\n下面来具体说说 Python 中的 `super` 类。\n\n## super 的作用\n\n在 Python 中某 class 使用了 `super()` 后，`super` 即会沿着最初调用 `super()` 的那个 class 的 MRO 向上寻找超类：\n\n```python\n>>> B.mro()\n[__main__.B, __main__.A, object]\n>>> C.mro()\n[__main__.C, __main__.A, object]\n```\n\n也就是说：在 B 中调用的 `super` 不会顺着 B 的 MRO 来向上寻找，而是从最初调用的 D 的 MRO 来向上寻找。那么 `super` 是怎么知道最初的 class 是哪一个呢？\n\n嘿嘿，你可能已经猜到了，没错，就是通过 `self` 这个参数来指定的：当我们调用 `d.hello()`时 ，实际上调用的是：`D.hello(d)`，而我们调用的 `super()` 也只是 Python 3 对 `super(a_class, a_instance)` （其实这里的 `instance` 也可以换成 `class`）的简写，所以其实 B、C、D 中的 `super()` 中的 `a_instance` 其实都是 d。 \n\n当我们以 `super(a_class, a_instance)` 调用时，这里的 MRO 即为 `a_instance.__class__` 的 MRO，而 `a_class` 必须为该 MRO 中的某一项，也就是说 `isinstance(a_instance, a_class) == True`。\n\n**简单来说**，`super()` 做的事就是：你提供给它一个 class 以及一个 instance，它返回从该 instance 的 MRO 中排在 class 之后的类里，查找方法的对象。\n\n说了这么多，那么这个 MRO 到底是怎么产生的？\n\n## C3 算法\n\n在 Python 2.3 之后，MRO 是由 C3 算法来计算得出的，而在 2.3 之前是按照如下规则计算：新式类是广度优先，经典类是深度优先。这里仅讨论 Python 2.3 版本之后的 MRO 计算方法，也就是 C3 算法：\n\n为表述方便，先做出如下规定：\n\n$$\n\\begin{aligned}\nhead([C_1,C_2,...,C_N]) &= C_1 \\\\\\\\\ntail([C_1,C_2,...,C_N]) &= [C_2, C_3,...,C_N]\\\\\\\\\nL[C(C_1,...,C_N)]&=[C]+merge(L[C_1],...L[C_N],[C_1,...,C_N])\\\\\\\\\n\\end{aligned}\n$$\n\n则用 C3 算法计算这个列表的线性化可以用公式 (3) 表示，其中的 C 是继承自 C1，C2，… CN 的类。\n\n对其中的 merge 操作可以解释为：\n\n1. 选取等号右边 merge 列表的第一项 L[C1] 为 K；\n2. 如果 head(K) 没有在 merge 中的任何列表的 tail 中出现（这时称 head(K) 为 `good head`），则把 head(K) 加入 C 的线性化列表中，并将 head(K) 从 merge 的所有列表中删除，重复 2；\n3. 否则，设置 merge 中的下一项 L[C2] 为 K，如果 head(K) 为 `good head`，重复 2；\n4. 重复以上操作直到所有的 class 都被移除或者已经找不到 `good head` 为止；如果找不到 `good head` 那么就抛出异常，否则创建成功。\n\n来看个例子吧：\n\n```python\nA = object\nclass B(A): ...\nclass C(A): ...\nclass D(C, B): ...\nclass E(C, D): ...\n```\n\n首先 L[A] = [A]，然后：\n$$\n\\begin{aligned}\nL[B]=[B]+merge(L[A],[A])=[B, A]\\\\\\\\\nL[C]=[C]+merge(L[A],[A])=[C,A]\n\\end{aligned}\n$$\n\n这两个等式很简单，没什么好说的，来看个稍微复杂一点的：\n\n\n$$\n\\begin{aligned}\nL[D]&=[D]+merge(L[C],L[B],[C,B])\\\\\\\\\n&=[D]+merge([C,A],[B,A],[C, B])\\\\\\\\\n&=[D,C]+merge([A],[B,A],[B])\\\\\\\\\n&=[D,C,B]+merge([A], [A])\\\\\\\\\n&= [D,C,B]\\\\\\\\\n\\end{aligned}\n$$\n\n稍微解释一下：\n\n第二行，设置 K 为 [C, A]，其中 C，也就是 head(K) 是一个 `good head`，那么就把 C 加入 D 的列表，并把 C 删去；\n\n第三行，这时设置 K 为 [A]，A 此时并不是一个 `good head`，因为他在 tail([B, A]) 中出现了，所以要设置下一项 [B, A] 为 K，此时 B 是一个 `good head`，那么就把 B 加入列表，并删除 B；\n\n第四行，这时 K 为 [A]，A 此时是一个 `good head`，加入列表，并删除 A，此时所有 class 都已经被移除，算法结束。\n\n来个错误的例子：\n\n$$\n\\begin{aligned}\nL[E]&=E+merge(L[C],L[D],[C,D])\\\\\\\\\n&=E+merge([C,A],[D,C,B,A],[C,D])\n\\end{aligned}\n$$\n\n这时算法好像没有办法继续往下走了：因为设置 K 为 [C, A]，head(K) 并不是一个 `good head`，那么就把 K 设置为 [D, C, B, A]，这时还是不行，因为 D 也在后面列表中的 tail 出现了。\n\n所以是无法选择 (C, D) 为基类来创建 E 的，如果你在解释器中执行一下代码，你就会发现，它报错了：\n\n```python\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: Cannot create a consistent method resolution\norder (MRO) for bases C, D\n```\n\n---\n\n以上，\n\n愿对你有所帮助。\n\n参考：\n\n- [The Python 2.3 Method Resolution Order](https://www.python.org/download/releases/2.3/mro/)\n- [Item 40：明智地使用多继承](https://harttle.land/2015/09/07/effective-cpp-40.html)\n- [Python: super 没那么简单 - Huang Huang 的博客](https://mozillazg.com/2016/12/python-super-is-not-as-simple-as-you-thought.html)"},{"title":"杭州见闻","subtitle":"","url":"/posts/2848ddef/","date":"2018-09-21T13:11:33.000Z","updated":"2018-09-21T13:11:33.000Z","category":"碎碎念","tags":["杭州","生活","旅游"],"content":"似乎很难说出为什么我对杭州这座城市如此「情有独钟」，以至于暑假就和同学计划着来杭州实习，虽然还是拖到了开学。出发之前也没有准备许多东西，只是简单收拾了一下衣服。所幸到达杭州后遇到的问题（比如租房、工作等）都比较顺利的解决了：遇到了很棒的宾馆老板、主动给我指路的老奶奶、很 Nice 的面试官（随后顺利入职）……这一切都让我对杭州这座城市更有好感，也让如今的我庆幸没有来错杭州。\n\n<!--more-->\n\n## 面试\n\n来杭州前，我和同学都约了面试，不同的是，他约了 5 场，我只约了 1 场。 在学校临走前的几天他都挺慌的，说 5 场万一都不合适怎么办，非要约 10 场差不多心里才有底，我就安慰他说没事，我才 1 场，我都不慌，你慌什么。他反而对我说，对啊，我要是你估计都慌得不敢去了，不知道你怎么这么有信心。\n\n当时的我也不知道为什么这么有信心，似乎根本没有想过万一在杭州找不到工作怎么办。就这样，我抱着三分紧张，两分忐忑，五分兴奋的心情，进行了我人生中第一次面试。\n\n面试中技术问题主要针对的是之前做的笔试题，而笔试题中大部分都是算法的，所幸虽然我虽好久没接触算法了，但也没有完全忘记。不过让我感到奇怪的是我简历中的项目反而问的不是很仔细，似乎公司更看重的是学习能力和思考方式，而说到学习能力我自然是不会虚谁了，毕竟现在掌握的技能大部分都是自学来的 :）\n\n技术问题过后就是较为老套的提问流程了，比如你为什么要来杭州啊，你对我们公司想要了解什么啊，你对自己未来的职业规划是怎么样的啊等等。与面试官的沟通交流较为顺畅，面试官也说我是来面试中很优秀的了，两天后，顺利的拿到了 Offer。公司名字就不透露了，在和瑞科技园。\n\n## 蟹黄汤包\n\n随后在等面试结果的一天里，让朋友领着逛了逛杭州。\n\n那天早上朋友说带我去吃蟹黄汤包（青芝坞那家），当时已经早上十点了，朋友准备早午饭一起在那里吃，而我当时已经吃过早饭了，就准备到美院的食堂去吃午饭（我十分庆幸没有去美院的食堂吃，走了一圈愣是没找到食堂在哪），但禁不住朋友一直说这里的蟹黄汤包多么好吃多么好吃，于是我也点了一份。\n\n等了差不多十几分钟，它才姗姗来迟。\n\n![蟹黄汤包](https://ae01.alicdn.com/kf/HTB1TBOGXiHrK1Rjy0Flq6AsaFXaE.jpg)\n\n外表乍一看和普通的汤包没什么区别，细看还是可以看出馅儿是偏黄一些的。我马上夹起一个就塞到了嘴里，差点没烫哭出来。朋友笑了，然后告诉我说汤包要先从褶子里把汤吸掉，要不然会很烫的。\n\n想我以前在学校的时候，哪吃过现蒸的汤包啊，食堂大妈早就蒸好了，然后拿布盖着保温，虽然算不上冷，但也绝对算不上烫。\n\n味道嘛，还算好吃。\n\n## 中国美院\n\n话说其实一开始我不是很想去美院的（但没办法，谁让相机在我朋友手上呢），因为我觉得学校嘛，再好看还能比旅游景点好看？直到我见到美院的大门那一刻我才知道我错了。\n\n前方多图预警（这个预警并没有什么卵用，因为当你点进这个页面的时候图片已经加载完毕了 :）\n\n![通向「幸福」的阶梯](https://ae01.alicdn.com/kf/HTB1kSeGXcnrK1RjSspkq6yuvXXab.jpg)\n\n![这好像是自习室](https://ae01.alicdn.com/kf/HTB186SIchnaK1RjSZFtq6zC2VXa1.jpg)\n\n![可能是幸存的「变形金刚」](https://ae01.alicdn.com/kf/HTB1mruHXojrK1RkHFNRq6ySvpXak.jpg)\n\n![博物馆的侧面](https://ae01.alicdn.com/kf/HTB1r7yGXcnrK1RjSspkq6yuvXXaJ.jpg)\n\n![我忘记这建筑是哪了](https://ae01.alicdn.com/kf/HTB1T0uHXh2rK1RkSnhJq6ykdpXaR.jpg)\n\n![另一个博物馆的外层围墙](https://ae01.alicdn.com/kf/HTB1VtaHXdzvK1RkSnfoq6zMwVXaO.jpg)\n\n![喵喵](https://ae01.alicdn.com/kf/HTB1Wa9HXojrK1RkHFNRq6ySvpXas.jpg)\n\n![山上的「宫殿」](https://ae01.alicdn.com/kf/HTB1ztKHXh2rK1RkSnhJq6ykdpXaT.jpg)\n\n![轮胎制椅子](https://ae01.alicdn.com/kf/HTB1t_iGXc_vK1RkSmRyq6xwupXao.jpg)\n\n![某建筑内部](https://ae01.alicdn.com/kf/HTB1LNWGXjzuK1RjSspeq6ziHVXa6.jpg)\n\n![超大的榕树](https://ae01.alicdn.com/kf/HTB1Pd9HXovrK1RjSszfq6xJNVXax.jpg)\n\n![竹制的避雨场所](https://ae01.alicdn.com/kf/HTB1XW5HXffsK1RjSszbq6AqBXXaw.jpg)\n\n![奇奇怪怪的东西](https://ae01.alicdn.com/kf/HTB1W7KGXoLrK1Rjy1zbq6AenFXaK.jpg)\n\n![一个伪装成火车头的咖啡店](https://ae01.alicdn.com/kf/HTB1xeGGXjzuK1Rjy0Fpq6yEpFXaw.jpg)\n\n![同上，不过换了一个滤镜](https://ae01.alicdn.com/kf/HTB17xCGXirxK1RkHFCcq6AQCVXaV.jpg)\n\n![校园的边界](https://ae01.alicdn.com/kf/HTB1almGXozrK1RjSspmq6AOdFXaT.jpg)\n\n（不知是因为杭州的美女多还是因为学艺术的女生都比较有气质，真的不愧是~~中国美女学院~~中国美术学院。）\n\n这次好像只逛了一半的校园，因为校园里面的建筑真的和迷宫一样，从一个建筑进去绕了一圈就不知道原先从哪出来的了，导致进校园和出校园都在同一侧，下次有机会还要去逛逛。\n\n## 工作\n\n我目前所在的公司是早上九点上班，下午六点下班，中午午休一小时，一周五天。除了中午休息时间有一点短之外，几乎完美了，而我除了第一、第二天在下午会稍稍犯困之外，后面几天都挺精神的（当然，代价是晚上十点半就要睡觉，这对我反而是好事，正好能调整到健康的作息时间 :)\n\n公司的同事都很年轻，办公氛围也比较轻松，不会像部分其它的公司那么压抑。那个 Nice 的面试官也成为了我目前所在项目组的 Leader。\n\n我现在的日常生活就是每天早上睡到八点起，洗漱一下，买个早饭走十几分钟去公司，中午和同事一起去食堂吃午饭，晚上回来之后就写写博客或者看部电影。呐，惬意的生活啊。\n\n今天也是第一周的最后一天班，早上去公司的时候发现桌上摆着一盒「蛋黄酥」，应该是中秋的礼物了。\n\n![蛋黄酥，还挺好吃](https://ae01.alicdn.com/kf/HTB1iCmHXorrK1RkSne1q6ArVVXaK.jpg)\n\n说到中秋，这应该是我第一个不在家过的中秋了吧，有些伤感。\n\n最后，还是祝大家中秋节快乐。"},{"title":"写给 21 岁的自己","subtitle":"","url":"/posts/d9253d8c/","date":"2018-08-28T16:00:00.000Z","updated":"2018-08-31T02:44:00.000Z","category":"碎碎念","tags":["21","成长","感想"],"content":"人类似乎总是对自己无法掌控的事物有些畏惧，比如时间。我就有些害怕时间的流逝，总觉得去年那篇[写给 20 岁的自己](https://blog.itswincer.com/posts/11ab0263/)的文章还历历在目，如今又到了该写这系列文章的时候了。我很早就开始构思这篇文章该写什么，却直到最近才了有些明确的思路。\n\n去年，我曾对自己说，希望可以「不在意别人的眼光，不为了生存而活，为了自己的热爱」那样真实的活着。所幸我应当是在大部分时候都做到了，因此这一年过得很自在。但怎么说呢，近来关于这个问题我却有些困惑了。\n\n<!--more-->\n\n前几天一朋友在群里说他辞职了。\n\n问：为啥啊？这工作不好吗？\n\n答：工作挺好的，划水都能拿 12k。\n\n更奇怪了，又问：划水都能拿这么高，还有啥不满意的？\n\n答：感觉生活没有目的，突然想辞职冷静一下。\n\n当时还不太能理解他的想法，因为在我看来这简直是梦寐以求的工作啊：划水意味着我就有更多的时间投入到我所喜爱的事情上，但我没有说出口，只是默默听着。他继续说辞职亲戚朋友都反对，但他还是辞了——「迷茫了，每天这么混，不知道该干什么」，他说。听他说完这句话时我就有点理解了，是啊，**没有以自我认可为目的的生活，又有什么可以阻止它慢慢滑向悬崖的另一侧呢**。\n\n---\n\n说来有些不好意思，我的自我认可很大一部分来自两部电影——《搏击俱乐部》和《三傻大闹宝莱坞》：做自己想做的事，不要做自己应该做的事情。具体解释就是我不想也没有必要活成别人眼中的自己。像别人一样告诉自己先买车、后买房、再结婚？这都是自己作，一辈子忙忙碌碌都不知道为什么而活，生命只有一次，为什么就不能为自己而活呢？做自己想做的事，不是很开心吗？\n\n而现在我的想法好像有了些许的改变：在社会福利好的发达国家，也许公民是真的可以做到我梦想的这样：看起来不求上进，赚到钱就花，遇到热爱的事情就去做，一辈子都过得很开心、很舒服。但是在中国不行。\n\n想成为自己、为自己而活当然没错。这也是电影想告诉我们的，但电影没有告诉我们的是，今天的自己是自己，明天的也是。十年后，三五十年后的都是自己。对于「自己」来说目前所有的选择都是自由的，可以选择自己所热爱的事，也可以按部就班地选择自己应该做的事。仅需记住目前做出的选择所造成的千差万别也是未来的自己所必须接受的。在中国如果按照我之前的那种想法去选择，可能并不会让三十年后的自己开心。当然，这种选择不能说是错的，更不应该被批判，只是说我们在自己没想清楚的时候可能会选择了以后的自己不想要的未来。\n\n写到这忽然有点明白卢梭的那句「人生而自由，却又无往不在枷锁之中」中的意味了。\n\n---\n\n关于我 21 岁的谈人生~~瞎扯淡~~就在这里告一段落了。确实，我没有像去年那样在全文中都很明确的表达出一个观点并以此作为我接下来一年生活的座右铭。反而是给了一个模棱两可的答案。但我想，相比去年，这个答案确实更好了——因为得出这个答案我思考得更全面了。或许我需要像阿甘一样，连续奔跑三年才知道自己为什么要奔跑。谁知道呢，也许我明天就想明白了，Life was like a box of chocolates. You never know what you're gonna get（译文：人呐，就都不知道（命运），自己就不可以预料）。\n\n用杨绛答复别人回信作为结尾吧：\n\n> 你们这些年轻人啊！ too young too simple, sometimes naive！你们啊，还是要提高自己的知识水平。\n\n啊不好意思，皮了一下，是下面这句：\n\n> 「你的问题主要在于读书不多而想得太多」——杨绛。\n\n最后，二十一岁快乐。\n\n送给自己。"},{"title":"博客折腾小记","subtitle":"","url":"/posts/50658b02/","date":"2018-08-22T03:31:58.000Z","updated":"2018-09-11T12:12:59.000Z","category":"博客栈","tags":["主题","博客","字体"],"content":"八个月前，我把建站之初就使用的 NexT 主题换成了 Material 主题，依稀还记得当时告诉自己：以后就好好写文章，绝对不再耗费时间在这没啥价值的事情上（让你立 Flag！后悔了吧？）。时隔半年多，如今发现对我来说好像不折腾比折腾还要难一些，原因嘛，自然是新鲜感与强迫症在作祟，这次折腾的起因就在于新鲜感——我看上了一个主题。\n\n<!--more-->\n\n## 优点与缺点\n\n这次更换的主题是 [inside](https://github.com/elmorec/hexo-theme-inside)，该主题相较于其它 hexo 主题的特殊之处就在于它的本质是采用 Angular 编写的 SPA（single page web application，单页应用程序）。优点就在于每次点击不同的链接只产生一个 HTTP 请求，返回的是一个 `.json` 文件，包含该页面的内容（内容已在 `hexo g` 时已经转成 HTML 格式了），而一旦接收到 `.json` 文件后，就会将文件的内容通过 `innerHTML` 属性嵌入页面。\n\n而缺点在于相较于普通的页面，可能对 SEO 不那么友好。因为阻止页面呈现的 JavaScript 可能会对用户体验造成不好的影响，而我为此在额外方面做了补足：添加了 27 个 `<meta>` 标签，用 Google Chrome 测试 SEO 那一项拿了 89 分，应该还算不错了（拿不到满分是因为部分字体小于 16px）。\n\n## URL 后缀\n\n采用 Angular 编写的 SPA 有一个 ~~Bug~~Feature，即在路由时会自动去掉 URL 结尾的斜线（slash），这就很尴尬了，因为我的博客 URL 是默认在结尾都有一个斜线的，比如：`posts/xxxxxx/`，我对此的解决办法是：\n\n1. ~~为每一个页面都添加一个 `canonical` 标记，其中标记的链接末尾都加上一个斜线；~~\n2. ~~但这样并不能解决 Google Analytics 的链接地址的问题，因为 Google Analytics 分析发送的 URL 是获取 HTTP 首部信息里的 referrer，为此我修改了发送 Google Analytics 的那部分代码：将每一个 URL 的尾部都加上了斜线；~~\n\n我在 Stack Overflow 上找到了更好的[解决方法](https://stackoverflow.com/questions/48425111/angular-5-allow-trailing-slash-in-routes)，原理是根据请求 URL 的每一个路由地址在末尾都加上斜线。\n\n但若想完美的解决这个问题，还需同时为每个匹配的路由路径在末尾都补足一个斜线（否则带斜线的 URL 一刷新就会出现路由无法匹配的情况）。\n\n```typescript\n...\n{ path: 'page/:page', component: VPostListComponent. resolve: { postList: PostListResolver }, data: { id: 'posts' } },\n// =>\n{ path: 'page/:page/', component: VPostListComponent. resolve: { postList: PostListResolver }, data: { id: 'posts' } },\n...\n```\n\n这样一来的话，斜线的问题算是解决了。（这部分也是我折腾耗时最多的部分。）\n\n## 用户体验\n\n我针对用户体验方面做了如下改进：\n\n- 字体\n\n  原主题的默认字体大小是 14px，我将正文修改成了 16px，代码字体修改为了 15px，这应该会比原主题看起来舒服一点。并且我移除了主题额外加载的字体文件，而纯粹改用 `font-family` 来呈现。参考了 [fonts.css](https://zenozeng.github.io/fonts.css/)。~~我能吞下玻璃而不伤身体。The quick brown fox jumps over the lazy dog.~~\n\n- Service Worker\n\n  原主题不带 Service Worker 功能，但我还是为我的博客注册了 Service Worker 功能。\n\n- 启用[盘古之白](https://github.com/vinta/pangu.js)\n\n  主要是为了解决中英文混排时的问题。因为研究显示，打字的时候不喜欢在中文和英文之间加空格的人，感情路都走得很辛苦，有七成的比例会在 34 岁的时候跟自己不爱的人结婚，而其余三成的人最后只能把遗产留给自己的猫。毕竟爱情跟书写都需要适时地留白。~~终于找到了我之前过得如此不得意的原因了，看来从此之后我可以走上人生巅峰了。~~\n\n- Disqus\n\n  原主题对 Disqus 的 identifier 和 url 识别有误，自己新增的页面会在在首部添加 `posts/` 字段，比如我的 `life/` 页面会变成 `posts/life/`，这并不是我希望的。我针对当前 URL 简单的做了一个判断，根据 URL 的不同来生成指定的 identifier。\n\n- API\n\n  我将原主题的 API 请求前缀改了一下，不从源站请求。因为我的网站是使用 Cloudflare 来~~减~~加速访问，但国内的速度却不佳，而我博客大部分用户还是国内的。将 API 请求源放在了国内的 CDN 后，会更大的提升页面的访问速度——访问页面几乎感觉不到页面的加载时间。\n\n## 个人喜好\n\n相较之前的 material 主题，我去除了 `localStorage` 功能，因为现在的博客内容需要用 JavaScript 来呈现，而放入 `localStorage` 的资源取出的速度是不如直接从 Service Worker 请求的速度来的快。\n\n同时我也移除了 lazyload-image 的功能，因为之前朋友告诉我说她从 RSS 阅读器阅读文章的时候图片没有显示，想了想应该是 lazyload 的 JS 没有加载所导致的，于是乎干脆去掉了，等以后有空的时候再试试 Angular 的 lazyload 是否也有这个问题。\n\n由于该主题文章的内容是以 `innerHTML` 呈现的，故 `<script>` 标签里的内容是不会运行的，导致我的音乐插件 Aplayer 无法加载，于是我另写了一个页面专门呈现单独的音乐插件，再以 `iframe` 嵌入当前页面，算是比较完美的一个解决方案了。\n\n## 尾巴\n\n这篇文章一发布，预示着我博客栈的目录收录的文章也已到达两位数（10 篇）[^1]，强迫症终于满足了。\n\n最后我想说：\n\n- 我真的再也不！想！写！前！端！了！\n- 这绝对是我最后一次折腾博客！\n- ~~真香！~~\n\n[^1]: 最近我将写得不是很满意的文章隐藏了起来（原本想删除的，后来想了想实在有些舍不得），有二十余篇，我的博客现在不提供这些文章的入口，你仍然可以通过我的 [MyBlog](https://github.com/WincerChan/MyBlog) 仓库查看这些文章。"},{"title":"Python 知多少（一）——不常见的数据结构","subtitle":"","url":"/posts/dbcdebb/","date":"2018-08-08T03:30:32.000Z","updated":"2018-08-08T03:33:32.000Z","category":"分享境","tags":["Python","数据结构","高级","知多少"],"content":"近来准备写几篇文章用于介绍 Python 较高级一些的特性，归为一个系列。本文是这个系列的第一篇文章，主要介绍一下内置的一些数据结构。\n\n对 Pythoner 而言，元组（tuple）、列表（list）、字典（dict）这三个应该最熟悉的数据结构了，恰当使用这三个数据结构的话的确可以应对大部分的使用场合了，但有时因为其它方面的问题（内存占用、插入效率、删除效率等），我们仍有必要学习其它不那么常见的数据结构。\n\n<!--more-->\n\n## 数组\n\n初学者可能会认为在 Python 里，列表（list） 就是数组（array），其实不然。数组应当是一系列类型相同的变量的集合，而 Python 中的列表却可以存放任何不同类型的数据。Python 里也是有数组这个概念的，与列表有所不同的是数组里数据的存放方式（类型）并不是 Python 的基础类型（int、float、char）等，而是数字的机器标识（说白了就是和在 C 语言中存储方式一样），也因此，在将数据存入和读取文件时效率会更高一些。\n\n`array.array` 支持的数据类型包括整数、浮点数、字符三种，其中创建每个数组需要一个类型码（Type code），用以标识在 C 语言中存放怎样的数据类型，比如 `array('l')` 这样创建的就是存放四个字节大小的整数，范围从 - 2^31 到 2^31 - 1（更多的类型码使用 help(array) 查看）。\n\n```python\nfrom array import array\nfrom reprlib import repr\nints = array('l', (i for i in range(10**7)))\n>>> repr(ints)\n\"array('l', [0, 1, 2, 3, 4, ...])\"\n# write to file\nwith open('ints.bin', 'wb') as fp:\n\tints.tofile(fp)\n\nints2 = array('l')\n# read from file\nwith open('ints.bin', 'wb') as fp:\n    ints2.fromfile(fp, 10**7)\n```\n\n数组支持列表的大部分操作（准确地说是支持所有和可变序列的有关的操作），包括 `pop()`、``insert()``、``extend()`` 等。\n\n```python\n>>> len(ints)\n10000000\n>>> ints[-1]\n9999999\n>>> ints.pop()\n9999999\n```\n\n在排序这里与列表有一点小区别，列表支持 `list.sort()` 这种就地排序的方法，但数组不支持，所以想对数组进行排序的话，得用 `sorted` 新建一个数组：\n\n```python\ntmp = array(ints.typecode, sorted(ints))\n```\n\n## 队列\n\n队列的特性是先进先出，虽然我们可以把列表当作队列来使用：``append()`` 来模拟进队列，``pop(0)`` 来模拟出队列：\n\n```python\nclass Queue:\n    def __init__(self, queue):\n        self.queue = list(queue)\n\n    def pop(self):\n        return self.queue.pop(0)\n\n    def push(self, num):\n        self.queue.append(num)\n\n    def __repr__(self):\n        return 'Queue<%s>' % self.queue\n\nq = Queue(range(5))\n>>> q\nQueue<[0, 1, 2, 3, 4]>\n>>> q.push(5)\n>>> q\nQueue<[1, 2, 3, 4, 5]>\n>>> q.pop()\n1\n```\n\n似乎看上去很完美，但是这种方法的弹出操作是很耗时的，因为删除列表的第一个元素会牵扯到移动列表里的所有元素。\n\n这里介绍标准库中两种不同的队列：\n\n### 双向队列\n\n`collections.deque` 类提供了一个双向队列，也就是说 `deque` 也完全可以栈来使用。它的 `append()`、``appendleft()`` 和 `pop()`、``popleft()`` 都是原子操作，这也意味这 `deque` 是线程安全的。`deque` 同样实现了所有和可变序列相关的操作。`deque` 可以接受一个可选参数（`maxlen`）表示队列可容纳元素的数量：\n\n```python\nfrom collections import deque\ndq = deque(range(5), maxlen=5)\n>>> dq\ndeque([0, 1, 2, 3, 4])\n>>> dq.append(5)\n>>> dq\ndeque([1, 2, 3, 4, 5])\n>>> dq.popleft()\n1\n>>> dq\ndeque([2, 3, 4, 5])\n>>> dq.appendleft(1)\ndeque([1, 2, 3, 4, 5])\n```\n\n需注意，一旦添加了 `maxlen` 属性，这个属性就无法修改了。当对一个已满的队列进行添加操作时（第 5 行），另一头的元素会被挤掉。\n\n### 单向队列\n\n（原谅我想不出一个好名字了，只能用单向队列来和刚刚介绍的双向队列做区分了）。\n\n`queue.Queue` 类提供的是一个单向的队列，它与上面双向队列最大不同除了它是单向的之外，还有对于队列已经满了或空了的情况下，还要对队列进行添加或删除操作的结果不同：在满员（为空）时，如果还向 `Queue` 中插入（取出）元素的话，它不会扔掉旧的元素来腾出位置，反而是会锁住——直到另外的线程移除了某个位置，这一特性很适合用做生产者——消费者的模型，尤其是当生产者的生产时间与消费者的消费时间不匹配的情况，比如：生产者的生产时间快于消费者的消费时间，如果采用 `deque` 的话，就会丢失生产者最早时候生产的数据（反之就会造成消费者从空队列中取出数据的情况）。\n\n```python\nfrom queue import Queue\nfrom threading import Thread\nimport logging\nimport time\n\nlogging.basicConfig(level=logging.INFO,\n                    format=('%(asctime)s %(message)s'))\n\nqueue = Queue(1)\n\n\ndef consumer():\n    time.sleep(.1)\n    queue.get()\n    logging.info('Consumer got 1')\n    queue.get()\n    logging.info('Consumer got 2')\n\n\ndef producer():\n    queue.put(1)\n    logging.info('Producer put 1')\n    queue.put(2)\n    logging.info('Producer put 2')\n    thread.join()\n    logging.info('Producer done')\n\n\nthread = Thread(target=consumer)\nthread.start()\nproducer()\n>>>\n2018-08-07 19:56:42,234 Producer put 1\n2018-08-07 19:56:42,335 Consumer got 1\n2018-08-07 19:56:42,335 Producer put 2\n2018-08-07 19:56:42,335 Consumer got 2\n2018-08-07 19:56:42,335 Producer done\n```\n\n消费者线程先等待了片刻是为了给生产线程留部分时间，使其在消费者从队列获取之前先将两个对象放入队列。然而，这里的缓冲区容量为 1，这就意味着生产线程在放入第一个数据后，会卡在第二个 `put` 方法那里，必须等待消费线程通过 `get` 方法把第一个数据消费之后，才能放入第二个对象。\n\n## 堆\n\n堆的性质是父节点（下标为 k）的值，总是小于（大于）等于其左（下标为 2k + 1）右（下标为 2k + 2）两个子节点的值。堆这种数据结构实际中多用于实现**优先级队列**（在 `queue` 模块中也有优先级队列的实现：`PriorityQueue ` ）：在队列中，优先级较高的元素**总**排在前面。\n\n`heapq` 模块可以在标准的列表之中创建堆结构：\n\n```python\nfrom heapq import heappush, heapify, heappop\n\nheap = []\nheappush(heap, 5)\nheappush(heap, 3)\nheappush(heap, 7)\nheappush(heap, 4)\n\n>>> assert heap[0] == min(heap)\n>>> heappush(heap, 2)\n>>> heap\n[2, 3, 7, 5, 4]\n>>> heappop(heap), heappop(heap), heappop(heap)\n(2, 3, 4)\n\nheap2 = [9, 8, 7, 6, 5, 4]\nheapify(heap2)\n>>> heap2\n[4, 5, 7, 6, 8, 9]\n```\n\n`heappush` 和 `heappop` 方法总会保持堆的性质，将数据插入或弹出，`heappop` 总会将堆中优先级最高的元素弹出。其中 `heapify` 可在线性时间内将列表转化为堆。\n\n## 内存视图\n\n内存视图（memoryview）可以在不需要复制内容的前提下，在不同的数据结构之间共享内存。当你需要在内存中处理大量二进制数据时，或者需要反复修改内存中某块数据的内容，内存视图可能会对你有很大帮助：因为在 Python 中，对字符串（str）和字节数组（bytesarray）进行切片都是会造成内存的复制，尤其是当需要对较大的数据进行切片的时候，所耗费的代价将会非常昂贵。\n\n```python\nfrom time import time\n\n\ndef mv_vs_bytes(factory, name):\n    for n in (100000, 200000, 300000, 400000):\n        data = b'x' * n\n        t0 = time()\n        b = factory(data)\n        while b:\n            b = b[1:]\n        print(name, n, time() - t0)\n\n\nmv_vs_bytes(lambda x: x, 'bytes')\nmv_vs_bytes(lambda x: memoryview(x), 'memoryview')\n\n\"\"\"\noutput:\nbytes 100000 0.15474176406860352\nbytes 200000 0.6353733539581299\nbytes 300000 1.5503427982330322\nbytes 400000 2.8593809604644775\nmemoryview 100000 0.008246183395385742\nmemoryview 200000 0.017104148864746094\nmemoryview 300000 0.025980710983276367\nmemoryview 400000 0.03431963920593262\n\"\"\"\n```\n\n可以看出，对 `bytes` 切片的时间复杂度是 O(n^2)，而对 `memoryview` 切片总能在线性时间内完成。\n\n当然，由于 `bytes` 本身是不可变（immutable）的字节序列，如果想对 `memoriview` 中的数据进行修改的话，就需要用 `bytearray` 的方式构造 `memoryview` 对象：\n\n```python\n# readonly\nb = b'Hello'\nmv_b = memoryview(b)\nassert mv_b.readonly == True\n>>> mv_b[0] = 73\nTypeError: cannot modify read-only memory\n\n# can write\nba = bytearray(b)\nmv_ba = memoryview(ba)\nassert mv_ba.readonly == False\n>>> mv_ba[0] = 73\n>>> mv_ba.tobytes()\nb'Iello'\n```\n\n由于 `memoryview` 使用了缓冲区协议（协议提供的是 C 语言级别的 API），导致 `memoryview` 只有在 CPython 中才能发挥它最大的作用。\n\n本系列全部文章可访问「[知多少](/search/?q=tags:知多少)」标签查看。\n\n参考：\n\n- [Fluent Python](https://www.oreilly.com/library/view/fluent-python/9781491946237/)\n- [Effective Python](https://effectivepython.com/)\n- [Less copies in Python with the buffer protocol and memoryviews](https://eli.thegreenplace.net/2011/11/28/less-copies-in-python-with-the-buffer-protocol-and-memoryviews)"},{"title":"基于 Socket 编写 HTTP 服务器","subtitle":"","url":"/posts/89381f22/","date":"2018-08-03T04:06:13.000Z","updated":"2018-08-03T04:06:13.000Z","category":"实验室","tags":["Socket","异步","HTTP","服务器"],"content":"在大二上《计算机网络》这门课的时候，由于并不是很喜欢这门课的老师，导致我在上课的大部分时间都在摸鱼~~（啊喂，学校教的哪门课你没在摸鱼啊？）~~。最近看了《[图解HTTP](https://book.douban.com/subject/25863515/)》这本书，借这本书正好也复习了一下应用层和传输层协议，毕竟现在的 Web 应用几乎都是在应用层的 HTTP 协议运行的，而 HTTP 又是基于传输层的 TCP 协议来实现的。\n\n<!--more-->\n\n我一直认为检验学习新知识是否牢靠最好的方法就是写一个小的实例，于是乎，借助于 Socket 模块（仅对 BSD Sockets API 进行封装），我也实现了一个静态的 HTTP 服务器，当然，比标准库提供的 SimpleHTTP 要强一点，因为我编写的支持并发。源码见[这里](https://github.com/WincerChan/Tiny-Http)。\n\n## Socket 服务器\n\n### Socket \n\nHTTP 协议是基于 TCP 协议来实现的，也就是说要实现 HTTP 服务器首先就需要先创建一个 TCP 连接，而一个完整的 TCP 连接是同时需要客户端和服务端的，而客户端和服务端的创建，就需要借助 Socket（套接字）了。\n\n通常创建一个 Socket 需要为其指定地址族（包括本机、IPV4、IPV6）、套接字类型（流式、数据报式，分别对应 TCP 和 UDP）\n\n```python\nfrom socket import AF_INET, SOCK_STREAM, socket\n\n# create a tcp socket\nsock = socket(AF_INET,SOCK_STREAM)\n# equal to\nsock = socket()\n```\n\n随后需要为该 `socket` 绑定一个 IP 地址和端口，并开始监听该地址（listen 可传入参数，表示排队连接的数量）：\n\n```python\nsock.bind(('0.0.0.0', 8888))\n\nsock.listen()\n```\n\n随后，就可以等待客户端发起连接请求了：\n\n```python\nconn, addr = socket.accept()\n```\n\n随后该连接会阻塞，直到 accept 到客户端的连接之后（客户端可使用 `telnet 0.0.0.0 8888` 来连接），随后程序就会继续运行，这时就可以通过 socket 连接来传输数据了，在 telnet 输入任何字符，随后在客户端接收，再响应请求：\n\n```python\n# accept 10 bytes data\nconn.recv(10)\n# send response\nconn.send(b'hello world')\n```\n\n### 封装\n\n我们后续编写 HTTP 服务器仍是基于这一套流程，只是在客户端请求和服务端应答的内容不一样，故而封装成一个类，方便继承，以下为一个回显服务端，从客户端接收到的任何消息都会将其返回：\n\n```python\nfrom socket import AF_INET, SOCK_STREAM, socket\n\n\nclass EchoServer:\n    def __init__(self, port=8888, addr='0.0.0.0', family=AF_INET,\n                 type_=SOCK_STREAM, backlog=0, init=True):\n        self.addr = addr\n        self.port = port\n        self.family = family\n        self.type_ = type_\n        self.backlog = backlog\n\n    def _echo(self, sock: socket):\n        while True:\n            try:\n                req_head = sock.recv(1)\n            except BrokenPipeError:\n                break\n            else:\n                if not req_head:\n                    break\n                sock.send(req_head)\n\n    def _run(self):\n        self.sock.listen(self.backlog)\n        while True:\n            sock, addr = self.sock.accept()\n            print('Connect by {} Port {}'.format(*addr))\n            self._echo(sock)\n\n    def __call__(self):\n        self.sock = socket(self.family, self.type_)\n        self.sock.bind((self.addr, self.port))\n        print('Listen in %s port.' % self.port)\n        self._run()\n\n```\n\n### 测试用例\n\n```python\n>>> serve = EchoServer()\n\n>>> serve()\n\n\"\"\"\ntelnet 0.0.0.0 8888\nTrying 0.0.0.0...\nConnected to 0.0.0.0.\nEscape character is '^]'.\nHello\nHello\nI'm Wincer.\nI'm Wincer.\n\"\"\"\n\nListen in 8888 port.\nConnect by 127.0.0.1 Port 45186\n...\n```\n\n## HTTP 服务器\n\n### HTTP 报文\n\n那么有了 TCP 连接，该怎么实现 HTTP 协议呢，其实很简单，HTTP 协议只是在传输的内容上做了规定：满足「报文首部」、「空行」、「报文主体」，这样通过服务器发出去就算是一个 HTTP 报文了，不信？试试就知道了。\n\n将上面的 EchoServer 中的 `_echo` 方法修改一下，让其返回以下数据：\n\n```python\ndata = \"\"\"HTTP/1.1 200 OK\nContent-Length: 11\n\nHello World\n\"\"\"\n\nclass EchoServer:\n    def _echo(self, sock):\n        try:\n            req_head = sock.recv(1)\n        except BrokenPiperError:\n            return \n        else:\n            if not req_head:\n                return\n            # 注意这里必须要将字符串编码成 bytes 才能发送。\n        sock.send(data.encode('utf-8'))\n        sock.close()\n    \n    \n>>> serve = EchoServer(8888)\n\n>>> serve()\nListen in 8888 port.\n```\n\n咳咳，准备好了吗，打开浏览器，输入 `http://0.0.0.0:8888`，如无意外，你就可以在屏幕上看见 `Hello World` 了。\n\n这就算最「小」的 HTTP 服务器了，不管向它发送什么请求，不管请求的是什么，它都会返回 `Hello World`：\n\n```bash\ncurl http://0.0.0.0:8888\nHello World\ncurl http://0.0.0.0:8889/\\?test\nHello World\ncurl -X OPTIONS http://0.0.0.0:8889/\\?test\nHello World\ncurl -X POST http://0.0.0.0:8889/\\?test\\&param\\=block\nHello World\n```\n\n这是因为我们还没有对请求报文首部进行分析，从而根据请求路径的不同或者请求方式的不同来返回相应的数据。\n\n### 响应请求\n\n既然要做一个静态的服务器，最少也应该分析 `GET` 请求，根据请求的 URL 作出响应，那么就需要增加额外的函数了：\n\n```python\nclass HttpServer(EchoServer):\n\tdef _echo(self, sock: socket):\n        try:\n            req_head = sock.recv(1024)\n        except BrokenPipeError:\n            return\n        else:\n            if not req_head:\n                return\n            head = self._get_head(req_head)\n            sock.send(head.encode('utf-8'))\n            self._send_body(sock)\n            logging.info('HTTP/1.1 %s GET %s' % (self.status, Signal.path))\n        sock.close()\n```\n\n我这里（在 `_echo` 中）增加了两个函数：`_get_head` 和 `_send_body`。作用分别是根据客户端的请求报文的首部来生成相应的服务端响应报文首部和根据客户端的请求 URL 发送响应的报文主体内容，比如，请求首部：\n\n```http\nGET /index.html HTTP/1.1\nHOST: 0.0.0.0:8888\nUSER-AGENT: curl/7.61.0\nAccept: */*\n```\n\n响应首部（可将请求的资源以 `rb` 模式打开，并读入内存，再作为响应报文主体发送）：\n\n```http\nHTTP/1.1 200\nContent-Length: 11\nContent-Date: Thu, 02 Aug 2018 03:58:09 GMT\nServer: TinyHttp\n\nHello World\n```\n\n有关这两个函数的具体实现，可以参考我这部分的[源码](https://github.com/WincerChan/Tiny-Http/blob/master/tinyhttp/http/server.py#L49-L70)。\n\n## 并发请求优化\n\n我们的服务器现在已经可以根据 GET 请求的 URL 来返回相应的报文了，很好，但现在的服务器不支持并发请求，也就是说必须先对前一个请求作出完整的响应，并将响应发送出去之后，才能处理下一个请求，造成这种后果最重要的一点原因就是：`socket.recv()` 和 `socket.send()` 都是阻塞型 I/O 函数，也就是说，CPU 会一直等待这两个函数执行完成才继续执行后面的代码。\n\n虽然在本地局域网内，作出大部分响应的时间都很快（毫秒级别），但我们仍有必要对阻塞型 I/O 函数进行优化，优化方法有两种：\n\n1. 在单独的线程中运行该阻塞型操作\n2. 把该阻塞调用转化为非阻塞的异步调用使用\n\n其中第一个方法很简单，借助 `threading` 模块即可实现，重写一下 `_run` 方法：\n\n```python\nclass ThreadHttpServer(HttpServer):\n    def _run(self):\n        self.sock.listen(self.backlog)\n        while True:\n            sock, addr = self.sock.accept()\n            Thread(target=self._echo, args=(sock,)).start()\n```\n\n而第二个方法就需要借助 Asyncio 这个库了（由于借助了 Asyncio 这个库，要求 Python 版本为 3.5+），该库重写了标准库 socket 中的阻塞 I/O 函数，将其改为了非阻塞形式的异步调用，由于该方法改动的地方太大，就不贴完整的代码了，可移步至这部分的[源码](https://github.com/WincerChan/Tiny-Http/blob/master/tinyhttp/async/asyncserver.py)。\n\n## 薛定谔的 BUG\n\n同我在[之前一篇博文](../8575e868/#%E5%AE%9E%E7%8E%B0)提到的类似，这次同样遇上了一些薛定谔的 BUG：\n\n### 大文件传输\n\n当以 `open` 函数打开某一个文件时，会把这个文件的内容读入到内存中，如果只是普通的文本或者图片倒是不会出现什么问题，但是一旦读入的文件过大（比如我就喜欢在电脑开启静态 HTTP 服务，然后在局域网内其它的设备打开共享的视频来播放），就会出现两个情况：\n\n1. 占用的内存空间过大，程序 gg；\n2. 成功读入内存，但花了很多时间读入内存，服务端又花了很多时间发送，客户端又花了很多时间接收；\n\n于是乎，大名鼎鼎的「generator（生成器）」终于派上了用场。将 `_get_body` 函数（请求的文件内容）中的 `open` 函数作为一个生成器，每读取一行（`readline()`）就 yield 一次，在 `_send_body` 函数中不断对 `_get_body()` 返回的数据进行迭代发送，这样既不会一次性全部读入内存，造成内存空间不足、又不会花费过多的时间在 I/O 上，一举两得，当然，为此你需要加上一个 `Content-Lenght` 的首部，用以告诉客户端什么时候接收完毕。\n\n### 目录与文件\n\n当请求的是目录时，URL 最尾端应当为 `/`，这时返回的应该是该目录下的 `index.html` 文件，如没有的话就返回该目录下的文件列表（同样的，列表中的目录应当以 `/` 在末尾标识），如果点击了该目录下的子目录，则应递归的显示子目录。\n\n但当以 `os.listdir` 列出文件列表时，并不会显式的将目录以 `/` 标识，而仍需我们手动判断，当请求同名目录但末尾没有 `/` 时，应当将状态码设置为 301，并在响应头部加上 `Location: https://localhost:8888/xxx/` 用以显式的指向目录。\n\n## 结语\n\n其实这个服务器在结构上并不复杂，甚至可以说简单，就是依据 Socket 建立 TCP 连接，再分析请求首部得到的 URL，用 `rb` 模式加载并作为响应主体返回，但也确实让我学习到了不少：比如说「面向对象」范式的好处，即在构建以 `TCP->HTTP->ThreadHTTP、AsyncHTTP` 这样自顶向下的结构时，继承（`ThreadHTTP` 继承于 `HTTP`，而 `HTTP` 又继承于 `TCP`）可以大大的减少代码量和提高可重用性；再比如说生成器，即惰性求值的好处（节省内存），这好像还是我第一次正式在代码中用到生成器。\n\n而这两点，想来只有自己在生产代码中遇到过，才能切实体会到好处。"},{"title":"Hitokoto（一言）API 2.0 正式上线","subtitle":"","url":"/posts/a5c39267/","date":"2018-07-16T03:48:15.000Z","updated":"2018-07-16T03:48:15.000Z","category":"分享境","tags":["一言","API","Hitokoto"],"content":"去年夏天的时候，用 Flask 开发了一个[简易版的一言](../f6e1eb2a/)，算是最初的 beta 版，部署在了 Heroku 上面（那时我还没购买服务器），由于 Heroku 免费版有时间池的限制，在我购置了服务器后就重新用 Go 重写了一下[部署在自己的服务器上](../b3085a7/#搭建-API)，算是 1.0 版，这两天又重新拾坑，开发出了 2.0 版本。\n\n<!--more-->\n\n## 前言\n\n在 1.0 版本使用了较长的时间后，基于以下考量，我还是重构了部分代码：\n\n1. 收录一言数太少：我没事的时候就喜欢刷新玩，经常发现眼熟的，毕竟也就不到一千条；\n2. 性能：由于使用的是 SQLite，在每秒请求数在 1000 的时候就 GG 了；\n3. 查询参数：返回不超过查询长度参数的一言，但翻了一大堆 API，都并没有提供这个功能；\n\n于是乎，本着「生命不死，折腾不止」的态度，2.0 版本诞生了。\n\n> 本 API 的[源码](https://github.com/WincerChan/Hitokoto)已开源至 GitHub，如有需要的可自行搭建。\n\n以下是 2.0 版本的更新日志：\n\n## 数量问题\n\n爬取数据时采用了异步爬虫，解决了 1.0 版本爬取时效率低下的问题，同时选取了 xxhash 作为散列函数，将一言主体 hash 后，得到的 64bit 的无符号整数作为主键，这样如果爬取到了重复的一言也不会插入数据库中。\n\n得益于异步爬虫的高效率，在很短的时间内，爬取到了足够的一言数。目前，数据库内共有 `15371` 条一言。以后数量还会不断地增加。[爬虫程序](https://github.com/WincerChan/Hitokoto-Spider)已托管至 GitHub。\n\n## 性能问题\n\n数据库更换成了 MySQL，以承受高并发访问，以下为建表语句：\n\n```sql\n+----------+---------------------+------+-----+---------+-------+\n| Field    | Type                | Null | Key | Default | Extra |\n+----------+---------------------+------+-----+---------+-------+\n| id       | bigint(20) unsigned | NO   | PRI | NULL    |       |\n| hitokoto | varchar(300)        | NO   |     | NULL    |       |\n| source   | varchar(64)         | NO   |     | NULL    |       |\n| origin   | varchar(12)         | NO   |     | NULL    |       |\n+----------+---------------------+------+-----+---------+-------+\n```\n\n## 参数问题\n\n2.0 版本共包含以下请求参数：\n\n### 编码格式\n\n格式为 `encode=`，包含以下四个参数值：\n\n- js：JavaScript 脚本，将一言插入 HTML 中第一次出现 `class = 'hitokoto'` 的标签中\n- json：JSON 格式的字符串，包含主体（hitokoto），出处（source）\n- text：一言句子的主体\n- 默认为：`×××××——「×××」`，即主体 + 出处\n\n### 字符集\n\n格式为 `charset=`，包含以下两个参数值：\n\n- utf-8：在 Header 中的 `content-type` 字段添加 `charset=utf-8`\n- gbk：同上\n\n### 长度\n\n格式为 `length=`，会随机返回一条不超过这个查询长度的语句。\n\n### 回调\n\n格式为 `callback=`，会根据回调参数的值返回对应的函数调用，其中函数的参数为一个字典，key 分别为 `hitokoto` 和 `source`。\n\n> **注意：callback 参数会覆盖掉 encode 参数**\n\n## 使用示例\n\n调用地址：`https://api.itswincer.com/hitokoto/v2/`\n\n例如，我想请求一个长度不超过 10 的一言，并以 JSON 格式返回：\n\n```bash\ncurl 'https://api.itswincer.com/hitokoto/v2/?encode=json&length=10'\n\n{\"hitokoto\":\"(눈_눈)\",\"source\":\"进击的巨人\"}\n```\n\n如果想在自己的网页使用的话，可以采取以下两种方法：\n\n### JS 方法\n\n只需要在想要展示的标签加上 `class='hitokoto'` 属性，随后在任何地方加上：\n\n```html\n<script src=\"https://api.itswincer.com/hitokoto/v2/?encode=js\"></script>\n```\n\n插入页面的显示结果是：××××××× ——「×××」形式。\n\n展示结果见侧栏。\n\n### 回调方法\n\n如果对 `encode=js` 返回的格式不满意，可自行定义页面展示的格式：比如以下代码仅展示一言的主体部分：\n\n定义标签和函数：\n\n```html\n<p class=\"hitokoto\"></p>\n<script>\n    // 定义回调函数名 showHitokoto\n    function showHitokoto(data){\n        // 比如我只想展示一言主体部分\n        var hitokoto = data.hitokoto;\n        // 插入 class=hitokoto 的标签\n        var dom = document.querySelector('.hitokoto');\n        Array.isArray(dom)?dom[0].innerText=hitokoto:dom.innerText=hitokoto;\n    }\n</script>\n```\n\n随后将请求地址加上参数 `callback=showHitokoto`：\n\n```html\n<script src=\"https://api.itswincer.com/hitokoto/v2/?callback=showHitokoto\"></script>\n```\n\n以上示例将会在 HTML 标签首个包含 `class='hitokoto'` 的标签内部插入仅包含一言主体的部分。\n\n## 尾巴\n\n你看到某句熟悉的一言从屏幕上显示的时候，勾起了之前第一次看到这句话时或感动、或开心、或难过的回忆，而某个陌生人也会因此和你一样陷入属于他的短暂回忆——想到这些不是很快乐吗？而我想那个陌生人一定也正想着同样的事情。我一直这样觉得。\n\n而这，应当就是文字赋予一言的最大作用了。"},{"title":"博客访问统计报告（2017.6.20-2018.7.4）","subtitle":"","url":"/posts/790223d2/","date":"2018-07-05T02:52:34.000Z","updated":"2018-07-08T02:51:52.000Z","category":"博客栈","tags":["博客","Google-Analytics","访问统计"],"content":"我的博客[建站至今](../4a17b156/)也一年有余了，本想着在一周年（今年 5 月初）之际写一篇文章纪念一下，顺便公布一下本博客在这一年的访问情况，可当时发现统计记录还没有满一年（我是在 2017 年 6 月底才开始使用的 Google 分析），于是就想干脆等到 6 月底再写。而前段时间又忙于准备期末考试，直到昨天放假回家，似乎才有时间写这一篇文章。\n\n<!--more-->\n\n## 前言\n\n首先我并不确定 Google 分析的准确性有多高，因为当我查看 Cloudflare 自带的分析功能时，得到的数据与 Google 分析的有很大很大的差别。以近一周的数据做对比：\n\n![左 Google，右 Cloudflare](https://ae01.alicdn.com/kf/HTB1sonpB8mWBuNkSndV763sApXaO.png \"左 Google，右 Cloudflare\")\n\n虽说 Cloudflare 统计了所有的 HTTP 请求，但**我博客实则只有 html 页面才会走 Cloudflare 的线路**，其它的静态资源我都放在 CDN 了。而 Cloudflare 对于近一周访问 html 页面给出的数据是占总请求数的 48%——约 3411 次，这应该是与 Google 的页面浏览量（540）作为对比（加上其余两个子网站的浏览量分别为 121、4），可以看到仍然有将近 7 倍的差距，用户数也有近 5 倍差距——我确实想不出一个合理的解释（根据 Cloudflare 给出的解释，可能是由于某些网络爬虫，故与基于 Javascript 的统计工具来说有较大出入）。\n\n但 Cloudflare 无法给出像 Google 分析那样包括平均会话、每次会话浏览数、跳出率等等指标，故本篇博客还是选取 Google 分析的数据进行分析。\n\n## 受众群体\n\n在过去的一年零两周内，本博客的基本访问情况如下图：\n\n![概览](https://ae01.alicdn.com/kf/HTB1RzYAKeOSBuNjy0Fd762DnVXaB.png)\n\n这期间，本博客一共迎来了 5,446 位用户，他们一共产生了 10,508 次会话以及 19,989 次浏览。平均每天 14 位用户、28 次会话、53 次浏览。\n\n图表中有一个较为凸出的高峰（5 月 29 日），原因是我在 V2EX 发了帖介绍自己写的一个[表情包生成工具](https://www.v2ex.com/t/458433#reply23)，这个工具中算是间接性的把用户引导至本博客了。\n\n## 流量获取\n\n![流量](https://ae01.alicdn.com/kf/HTB1.vYJKXuWBuNjSszb763S7FXaU.png)\n\n其中流量获取的来源主要是三部分：Referral（引荐）、Organic Search（搜索引擎）、Direct（直连）。\n\n![对比](https://ae01.alicdn.com/kf/HTB1VOjDtpooBKNjSZPh7632CXXaY.png)\n\n其中 Google 的流量占了大多数：36.80%，其次是本博客自身的引荐；本博客并没有添加百度站长的信息，并且主动屏蔽了百度蜘蛛的爬取，故并没有来自百度的流量。\n\n现在的 Google 分析为了保护用户隐私，已经无法显示用户查询的关键词了。\n\n## 地理位置\n\n![地理](https://ae01.alicdn.com/kf/HTB1BiGLB2iSBuNkSnhJ762DcpXak.png)\n\n毫无疑问，本博客的主要流量都来自于中国大陆，不过令我感到奇怪的是第二名是美国。\n\n![语言](https://ae01.alicdn.com/kf/HTB1jDv.Kh1YBuNjy1zc762NcXXaZ.png)\n\n在操作系统语言中：\n\n简体中文（zh-CN + zh-cn）占了 72.27%，较地理为中国大陆的 68.93% 多出了 3.34 个百分点；\n\n英语（en-US + en-us）占了 16.91%，较地理为美国的 11.06% 也多出了 5.85 个百分点；\n\n也就是说，并非只有美国地区的人才会使用英文，也并非中国地区的人才会使用中文。\n\n## 设备信息\n\n![浏览器](https://ae01.alicdn.com/kf/HTB1MG58jNtnkeRjSZSg760AuXXa4.png)\n\n首先看看浏览器的占用，由于本博客的类型更偏技术一些，故 Chrome、Safari、Firefox 的使用占据前三甲，其中 IE 的份额不足 0.4%，这意味着我并不需要照顾 IE 的用户，可以尽情使用各种新技术。\n\n第四的 Android Webview 应该是指 App（QQ、微信） 内置的浏览器。\n\n![操作系统](https://ae01.alicdn.com/kf/HTB1koW2tOMnBKNjSZFC7600KFXaT.png)\n\n操作系统毫无疑问是以 Windows 独占鳌头，其次是 Linux，我一直使用 Manjaro Linux 作为日常开发，比 Windows 方便许多，也没有 Windows 那么多 Bug，由于娱乐方式的缺乏，在 Linux 下开发也会更加专注。\n\n## 浏览页面\n\n![页面浏览](https://ae01.alicdn.com/kf/HTB1GsLSKk9WBuNjSspe761z5VXal.png)\n\n在本站可访问页面中（仅统计文章页面），浏览量的前六名分别是：\n\n1. [Linux 与 Windows 10 用 GRUB 引导教程](/posts/ad42f575/)\n2. [解除百度云下载限速](/posts/cfd78fa9/)\n3. [Spacemacs 生存指北](/posts/2aa541e6/)\n4. [Nextcloud 搭建私人云服务教程](/posts/bf0413ac/)\n5. [QQ 音乐外链解析](/posts/72171293/)\n6. [Sorry，会写代码真的能为所欲为](/posts/8575e868/)\n\n（唉，最满意的几篇文章浏览量反倒是挺低的，心情复杂.jpg。）\n\n##  后记\n\n自本博客运营至今共发布了 53 篇文章，其中自 17 年 9 月以来，发文的频率明显降低：首 4 个月发了 33 篇文章，17 年 9 月至今却只发了 20 篇。一方面是刚建站的时候事比较多；另一方面是相较于博客数量来说，更开始注重博客质量了。\n\n最初我选择运营独立博客，并非想从中得到什么实质性的好处，只是作为一种兴趣。而如今在快餐时代坚持写独立文章的人越来越少，这也无可厚非，毕竟短期内看不到结果的话，有些人就无法坚持了。我周围的人似乎对此（我写博客这件事）也表示不太理解，但我还是会一直做下去。我一直认为，只要能长期的投入一件事中，最终一定能从中获取到乐趣和满足感。\n\n我就是如此。"},{"title":"使用持续集成（CI）开发项目","subtitle":"","url":"/posts/f011ea9c/","date":"2018-06-09T02:22:34.000Z","updated":"2018-06-15T04:34:43.000Z","category":"分享境","tags":["CI","持续集成"],"content":"我的博客在建站后不久就使用了 [Travis CI](https://travis-ci.org/) 自动部署服务，即我只需要将修改的源码推送至 GitHub，Travis CI 会自动将我提交的代码拉取，在 Travis CI 端生成静态文件后，同步至我的服务器，这样可以减少一些麻烦的步骤：可以直接在 GitHub 端修改代码；不用等待生成静态文件、压缩静态文件的时间。<!--more-->\n\n## Circle CI\n\n虽然使用 Travis CI 是能简化部分开发流程，但这货和 GitHub 是一对一的，只支持在 GitHub 托管的项目，并不支持 Bitbucket 和 GitLab，而 GitHub 免费版在私人仓库这一方面是比不上 Bitbucket 和 GitLab 的（虽然我是学生，可以使用 GitHub 私人仓库，可我也不一直是学生呀），同时支持 Bitbucket 的和 GitHub 私人仓库的 CI 工具（自建的除外）好像真的也就 [CircleCI](https://circleci.com/) 了，这里之所以没有考虑 GitLab 是因为 GitLab 自带有 CI/CD，而且这家公司给我的印象实在不太好（包括之前的删库事件，以及莫名奇妙的 Bug）。\n\n在了解 CircleCI 后发现比 Travis CI 真是强不少（CircleCI 是基于 Docker 和 Workflows 设定模式的），不过在网上并没有很完善的中文教程~~（虽然官方英文文档已经很完善了）~~。所以如果你懒得翻官方文档的话，继续往下看我这篇文章就好了🤓。\n\n## 选择仓库\n\nCircleCI 支持 GitHub 和 Bitbucket 帐号的登录，授权登录完成后，就可以添加 Projects 了，支持 GitHub 和 Bitbucket 的公有及私有仓库。这里以我的 [Meme-generator](https://github.com/WincerChan/Meme-generator) 仓库为例。\n\n选完仓库后，就可以开始配置 CircleCI 了。\n\n## 准备工作\n\n### 添加 SSH 密钥\n\n[Meme-generator](https://github.com/WincerChan/Meme-generator) 仓库用到 SSH 密钥的地方有两处：\n\n1. 从 GitHub 克隆仓库\n2. 将编译后的静态文件推送至我的服务器\n\n如果你是用来推送至 GitHub 的话，可以直接用 GitHub 提供为该仓库提供的 Token 密钥，第一点也可以使用 HTTPS 方式克隆，就可以省去添加 SSH 密钥这个步骤。\n\n点击 CircleCI 个人主页的 JOBS 菜单项，随后点击仓库名称右边的齿轮按钮 -> 点击 `SSH Permissions` -> 点击蓝色的 `Add SSH Key` 按钮，将**私钥**（看清楚了，是私钥）粘贴进去（超级良心有木有啊，比 Travis CI 将私钥加密上传这种土办法不知道高到哪里去了）。\n\n### 添加 IP 至 known\\_hosts\n\n添加 SSH 密钥后，还需要将服务器的 IP 添加至 known_hosts 列表，否则每次部署的时候都会让你确认以下消息：\n\n```bash\nThe authenticity of host '××.×××.×××.×××' can't be established.\nECDSA key fingerprint is SHA256:7hkfahfla8VeiuyF/TLHKfhakgcJ0sHjaLxDyIKlfhak9fuaofoa.\nAre you sure you want to continue connecting (yes/no)?\n```\n\n同 Travis CI 类似，CircleCI 在运行的过程中也是不接受命令行输入的（当然运行完成后就更不行了），所以我们需要提前将 IP 写入 known\\_hosts（在 CircleCI 中如何做？继续往后看）：\n\n```bash\nssh-keyscan $SSH_IP >> ~/.ssh/known_hosts\n```\n\n在该仓库的管理页面中的 `Environment Variables` 选项卡中添加 SSH_IP 的环境变量。\n\n## 配置文件\n\n### 简单的例子\n\n由于我的配置文件太过长了，先以一个简化版为例：\n\n```yaml\nversion: 2\njobs:\n  build:\n    docker:\n      - image: circleci/node:10.4.0\n    steps:\n      - checkout\n      - run:\n          name: Install Dependence\n          command: |\n            yarn install && yarn build\n      - run:\n      \t  name: Deploy\n      \t  command: |\n      \t    echo \"Denpendence installed.\"\n```\n\n首先指明 CircleCI 的版本号——2.0（1.0 在 18 年 9 月之后就停止支持了）。\n\n其次，为 Docker 指定 image（[这是](https://circleci.com/docs/2.0/circleci-images/)官方已经构建完成的镜像列表），可以指定多个 image。先前提到过，CircleCI 并不默认像 Travis CI 那样提供 Linux 虚拟机镜像，推荐使用的是 Docker（当然你也可以指定工作方式为 Machine），这是官方针对 Docker 和 Machine 的[对比报告](https://circleci.com/docs/2.0/executor-types/#overview)。\n\n随后在 `steps` 里面是需要运行的指令：\n\n1. `checkout` 是一个用于检查配置路径的源代码的特殊步骤，并可以通过 SSH 来 clone 远程仓库的代码（如果你已经添加了 SSH 私钥的话，不然就只好手动 clone 了），详解见[官方文档](https://circleci.com/docs/2.0/configuration-reference/#checkout)\n2. `run:` 后面接的是 bash 命令，`name` 该任务的名称，`command` 为具体 bash 的指令\n\n### 安装额外命令\n\n需要注意的是，如果你需要将生成的静态文件同步至服务器所用的 `rsync` 命令是没有被安装的，只有[这些命令](https://circleci.com/docs/2.0/circleci-images/#pre-installed-tools)是被安装在所有镜像中的。\n\ndocker 镜像预装的系统是 Ubuntu，可采取 `apt-get` 命令来安装需要的软件包：\n\n```yaml\nrun: \n  name: Update System\n  command: |\n    sudo apt-get update && sudo apt-get install rsync\n```\n\n### 设置缓存\n\nCircleCI 建议的 Workflows 中建议将整个工作流分割成不同的子作业，比如说以 Yarn 项目为例，可以分成 `build` 和 `deploy` 两个流程。其中 `build` 用以安装依赖和生成待部署的静态文件；`deploy` 用以将生成的静态文件部署至服务器。\n\n可以看出，静态文件是横跨两个作业的，所以我们需要将包含静态文件的文件夹缓存下来（当然你也可以选择不使用 Workflows，这样就只需创建一个工作就好了），在 `build` 工作中缓存采取如下命令：\n\n```yaml\nsteps:\n  - restore_cache:\n    keys:\n      - build-v1-{{ checksum \"package.json\" }}\n    paths:\n      - \"build\"\n```\n\n以上命令是将 `build` 文件夹以 `key-value` 形式缓存，其中 `key` 选择的是 `package.json` 的哈希值。这里的文件名最好选择仓库自带的文件。更多 `key` 的形式可以参考[这里](https://circleci.com/docs/2.0/caching/#using-keys-and-templates)。\n\n在 `deploy` 工作中恢复缓存采取以下命令：\n\n```yaml\nsteps:\n  - checkout\n  - restore_cache:\n    keys:\n      - meme-v1-{{ checksum \"package.json\" }}\n```\n\n注意在 `restore_cache` 之前一定要有 `checkout` 命令。\n\n### 完整的示例\n\n直接放 [Meme-generator](https://github.com/WincerChan/Meme-generator) 项目的配置代码了：[点我](https://gist.github.com/WincerChan/04b5e1ee8a1fbc8bc2e078d2c354bd7b)。\n\n每次构建完成后，commits 列表的画风就变成这样了：\n\n![CircleCI 构建](https://res.cloudinary.com/wincer/image/upload/v1530858045/blog/ci_project/circleci_construction.png)\n\n点击 Details 就会显示每次构建的详细过程。\n\n## 后记\n\n虽然本文名为「使用持续集成（CI）开发项目」，但实际却好像只介绍了 CircleCI，当然我的意思不是钦定 CircleCI 作为最好的持续集成系统，我没有说 CircleCI 是最好的持续集成系统，没有任何这个意思。但你一定要问我为什么选 CircleCI，它现在对 Bitbucket 和 GitHub 的私人仓库支持最完善，我怎么能不支持它呢？\n\n参考：\n\n- [2.0 Docs](https://circleci.com/docs/2.0/)"},{"title":"Sorry，会写代码真的能为所欲为","subtitle":"","url":"/posts/8575e868/","date":"2018-05-27T02:34:21.000Z","updated":"2018-05-27T02:35:20.000Z","category":"实验室","tags":["表情包","Javascript"],"content":"前一段时间「这个仇我先记下了」的表情包突然火了，导致我也萌生了自己写一个表情包生成工具的想法，毕竟我是重度表情包玩家😌。其实之前我就很喜欢做表情包，不过是用的 PS 等软件，有些麻烦，而且改 GIF 也不太方便。\n\n于是乎，我决定也蹭一波热度，也写了一个，最初是只有「记仇」这个静态表情包的，现在加上了王境泽、为所欲为、打工是不可能打工的等等动图，模板后续还会添加，如果有好的素材可以私我。<!--more-->\n\n## 思路\n\n当然网上也有一些表情包生成器，比如「[sorry](https://github.com/xtyxtyx/sorry)」，但界面我不太喜欢，而且我觉得这类较为简单的处理没必要借助服务器端渲染合成，直接在浏览器端渲染就好了，~~毕竟 JavaScript 算是一门「万能的语言」~~。\n\n核心思路是采用 omggif 对 GIF 进行解码，再用 Canvas 将文字绘制在每一帧上，最后再用 gif.js 将每一帧合成，再渲染后输出成 Blob 文件对象（[现在不支持 Blob 的浏览器应该没有了吧？](https://caniuse.com/#search=blob)），传递给 IMG 标签进行显示。\n\n这是解码过程：\n\n```javascript\n// 解码\nlet gifReader = new omggif.GifReader(buffer);\t\n// 获取帧\nlet frameZero = girReader.frameInfo(0)\t\t\t\n// 获取帧的宽高，绘制 Canvas 的时候会用到\nlet [width, height] = [frameZero.width, frameZero.height]\t\n\nlet imageBuffer = new Uint8ClampedArray(width * height * 4)\ngifReader.decodeAndBlitFrameRGBA(frameNum, imageBuffer);\n// 生成图像数据，供 Canvas 使用\nlet imageData = new window.ImageData(imageBuffer, width, height)\n```\n\n这是绘制过程：\n\n```javascript\nctx.putImageData(imageData, 0, 0)\n// 这是字幕的白边\nctx.strokeText(caption, width / 2, height - 5, width);\n// 这是字幕的主体\nctx.fillText(caption, width / 2, height - 5, width)\n```\n\n这是编码（渲染）过程：\n\n```javascript\nlet gif = new GIF({\n    workers: 3,\n    quality: 10,\n    width: imageWidth,\n    height: imageHeight,\n})\n\n// Canvas 的数据加入帧\ngif.addFrame(ctx, {\n    copy: true,\n    delay: frameInfo.delay,\n    dispose: -1\n})\n// 开始渲染\ngif.render()\n// 渲染完成\ngif.on('finished', Blob => {\n    gifUrl = window.URL.createObjectURL(Blob);\n    img.src = gifUrl;\n})\n```\n\n以上是动图的设计思路，静态图就显得简单多了，采用 dom-to-img 绘制就行了，但是在 Edge 上似乎是无法使用的，作者提到似乎是因为添加了 foreignObject 标签，导致 toDataUrl() 在 Edge 上无法工作，所以 Edge 用户只能使用动图部分了。\n\n其实核心思路很简单，gif.js 和 omggif 提供的 API 也不复杂，但我还是花了将近一周的时间，因为这是我首次使用 React 开发应用，所以有大半时间都花在了学习 React 上，然而写出来的结果还是偏「Pure JavaScript」一些。\n\n[本项目](https://github.com/WincerChan/Meme-generator)采用 [create-react-app](https://github.com/facebook/create-react-app) 构建，CSS 框架采用了 [bulma](https://github.com/jgthms/bulma)，部分动图模板来自 [sorry](https://github.com/xtyxtyx/sorry)。\n\n## 实现\n\n刚刚有提到，我在设计该工具的时候大部分时间都没有花在核心思路部分，而是花在了——我称为「薛定谔的 Bug」上，即：你在设计该工具的蓝图的时候，没有设想到会出现这些 Bug，而实际编程中，也不一定会遇到，只有你亲自编写了，才知道这 Bug 是否会出现。\n\n我在这次编程中就遇到了四个「薛定谔的 Bug」：\n\n### Blob 文件对象\n\n关于静态图部分，我设计了两个按钮：「戳我预览」和「戳我下载」，其实本应该只需要一个下载按钮就够了，因为我使用 contenteditable 属性以编辑 p 标签。和生成的预览图几乎没什么差别，那么为什么要设计两个呢？就是因为 Blob 对象（后续思考了一下，虽然可以先行判断浏览器是否支持 Blob 下载，但针对动态图还是需要预览修正的，故为了设计上的统一性，还是将预览按钮保留了）。\n\n其实大部分人应该是没有听说过这个名词的（包括我），但它还真的不是一个新玩意，甚至都不是 HTML5 新增的 API，相比于 HTML5 在 2014 年才完成标准制定，在 [MDN](https://developer.mozilla.org/zh-CN/docs/Web/API/Blob) 上查到 Blob 对象在 2010 年就被主流浏览器支持了（Chrome 5、Firefox 4、Opera 11.1），但，如今大部分手机浏览器却仍不支持 Blob 文件下载协议。\n\n所以只好提供一个预览按钮来供不支持 Blob 文件下载协议的浏览器长按进行保存。\n\n### 服务器问题\n\n由于我的服务器是在国外，而且还套了一层 Cloudflare，故而在某些情况下，加载动图会非常慢，尤其是在晚上（大约花费 1min，而且居然还没断，我真是很佩服 Cloudflare 的稳定性）。\n\n当然图片的加载问题还不算大，可以放在[支持跨域的图床](https://sm.ms)上，由 `fetch` 调用，问题最大的是 Web Worker（合成 GIF 的时候需要使用），但这个 Web Worker 的地址在 Chrome 下**只允许**同域名下的脚本，即使是公共 CDN 上允许跨域都不行。\n\n这里采用还是借助 Blob 对象，巧妙的规避这一限制：\n\n```javascript\nlet tmpWorker = await fetch(url),\n    workerSrcBlob = new Blob([await tmpWorker.text()], {     workerBlobURL = window.URL.createObjectURL(workerSrcBlob);\n```\n\n### React Router 404 错误\n\n在将代码生成「production build」时，遇到了一个 Bug，有时访问二级路由会出现 404，多次复现后，终于确定了：\n\n在访问二级路由时，如果是正常从一级页面点击跳转的，则会正常访问；\n\n但如果是直接访问二级路由或者是在二级路由刷新页面，则会出现 404；\n\n但是这个 Bug 在「development build」中是没有的，原因在于当你点击路由时，并不是直接向服务器发起请求，而是由 react-router 路由库给出路由网址，故而刷新二级路由页面或者直接访问二级路由页面服务器是无法正确响应的。\n\n以下是解决办法，在 Nginx 中添加 `try_files` 语句：\n\n```nginx\nserver {\n    location / {\n        try_files $uri /index.html\n    }\n}\n```\n\n### GIF 渲染\n\n当我解决了以上问题的时候，我发给室友首先试用，看到了「戳我预览」这个按钮，他就以「单身十八年」的手速猛戳了四五下，随后标志着渲染进度条就「鬼畜」了起来。因为他猛戳的那几下相当于在后台启动了好几个渲染程序，不仅会让进度条「鬼畜」起来，如果你以更快的手速戳的话（单身八十年？）还会让 CPU 负担加重，甚至会卡死，当然我是没有试过。其实这 Bug 算是无伤大雅的，本不太需要修复，~~因为不像其它生成器拿服务器做后端，可能会造成服务器宕机，我的纯前端写的~~。但我本着人道主义情怀、不让我的 Bug 陪我过夜的心理，以及最重要的强迫症，还是决定修复这个 Bug。\n\n其实很简单，设置一个全局变量 `finished`，在渲染的过程中，该变量为 `false`，渲染完毕后设置成 `true`，再将渲染过程放置在 `if(finished)` 内就解决了。\n\n## 教程\n\n见[本项目的 Wiki](https://github.com/WincerChan/Meme-generator/wiki)。\n\n## 结语\n\n本工具还有很多需要改进的地方，比如 React 的写法不够规范、没有完全实现静态动态资源分离、用户自定义添加模板等等，这些我在空闲时间里都会一点点的改进。\n\n目前在实用的角度来说，该工具已经可以投入使用了，剩下的细节就需要慢慢雕琢了。:)\n\n参考：\n\n- [xtyxtyx/sorry](https://github.com/xtyxtyx/sorry)\n- [纯 JS 实现在前端制作 GIF 表情包的网站](https://blog.csdn.net/xfgryujk/article/details/79889942)\n- [Histories](https://react-guide.github.io/react-router-cn/docs/guides/basics/Histories.html)"},{"title":"Python 字典的原理及高级用法","subtitle":"","url":"/posts/4f2b4bfb/","date":"2018-05-12T01:23:02.000Z","updated":"2018-05-12T04:36:13.000Z","category":"分享境","tags":["Python","字典"],"content":"算算时间有段时间没写技术类的文章了，部分原因是最近过得确实比较忙。当然，也并没有忙到完全抽不出时间写博客，根本原因还是没有找到啥好的写作素材，随随便便糊弄一篇我又有点不好意思发上来，于是乎，就一直搁置到现在。\n\n<!--more-->\n\n对于字典这一基础的数据结构来说，其对 Python 的程序重要性是无可替代的，在《代码之美》一书中，作者是这么描述的：\n\n> 字典这个数据结构活跃在所有 Python 程序的背后，即便你的源码里并没有直接用到它。——A.M.Kuchling\n\n在 Python 程序里，无论是模块、函数、还是对象，均有自己的「命名空间」，而这命名空间即为一个字典（dict），key 就是变量名，value 就是变量值，除去「命名空间外」，对象的函数（方法）关键字也是存放在字典中，此时的 key 就是函数（方法）名，value 就是该函数（方法）的引用。可以采用 \\_\\_builtins\\_\\_.\\_\\_dict\\_\\_ 来查看这些函数（方法）。\n\n## 字典的原理\n\nPython 的字典是依据[散列表](https://zh.wikipedia.org/wiki/%E5%93%88%E5%B8%8C%E8%A1%A8)（也叫哈希表）来实现的，首先简单介绍一下散列表的原理。\n\n散列表中的每一个单元称为表元。在 dict 的实现里，每个 key-value 均占用一个表元，其中 key 为**键的引用**（这里是键的引用，而不是键本身，因为 key 可以为任意可散列对象），value 为值的引用。因为是引用：表元大小均一致，所以可通过偏移量来读取某个表元。\n\n在 Python 中，散列函数由 hash() 方法出任，当我们查询 my_dict[search_key] 时，Python 会调用 hash(search_key) 来计算 search_key 的散列值，并将这个值的低几位数字当作偏移量，在散列表中查找表元，具体是几位，需要根据散列表的大小来决定。若表元为空，则说明 search_key 不存在，抛出 KeyError 异常。若非空，则表元会有一对 found_key:found_value，这时若 search_key == found_key 为真，那么就返回 found_value。\n\n如果 search_key 和 found_key 不相等，这种情况成为散列冲突，发生这种情况是因为散列表只把该元素映射到了只有几位数字上。为了解决散列冲突，算法会在散列值中另外取几位，用新得到的数字做偏移量再次寻找。\n\n## 创建字典\n\n创建一个字典有许多方式：\n\n```python\na = dict(one=1, two=2, three=3)\nb = {'one': 1, 'two': 2, 'three': 3}\nc = dict(zip(['one', 'two', 'three'], [1, 2, 3]))\nd = dict([('two', 2), ('one', 1), ('three', 3)])\ne = dict({'three': 3, 'one': 1, 'two': 2})\n>>> a == b == c == d == e\nTrue\n```\n\n在刚刚的原理中说到，由于字典的索引是根据 hash() 函数来获得的，所以 dict 其实是无序的，这也解释了为什么上面代码中的等式会成立。\n\n## 字典推导\n\n没错，在 Python3+ 里，推导式不再是列表的特性了。\n\n```python\nnumbers = range(5)\nnumbers_square = {number: number ** 2 for number in numbers}\n```\n\n## 键查询\n\n最简单的方法是采用下标方式来查询。即：my_dict[key]，这也是推荐的方法，但这是 key 存在的情况，而现实中，一定会遇到 key 不存在的时候，这时就会 raise 一个 KeyError。以下有几种解决办法：\n\n### 用 get 来获取\n\n```python\nmy_id = {'name': 'wincer'}\n>>> my_id.get('name')\n'wincer'\n>>> my_id.get('age', 'default')\n'default'\n```\n\n若 key 存在，则返回对应的 value，若 key 不存在，且传入第二个参数，那么返回该参数，若无第二个参数，则返回 None。\n\n### 用 defaultdict 预先设置缺省（推荐）\n\n```python\nfrom collections import defaultdict\n\nmy_id = defaultdict(list)\nmy_id.update({'name': 'wincer'})\n>>> mydict['name']\n'wincer'\n>>> mydict['age']\n[]\n```\n\ndefaultdict 需要指定一个 factory，当查询 key 不存在时，会创建一个空的 factory 返回。推荐使用这种方式来处理 key 不存在的情况，因为该方法不仅可用于读取 value 值，还可随时用 append 来更新 value。同时需注意：**defaultdict 中的参数只会在 \\_\\_getitem\\_\\_ 中被调用。如 dd 是一个 defaultdict，k 是一个不存在的键，dd[k] 用 factory 来创造一个默认值，但 dd.get(k) 却仍会返回 None。**\n\n### 使用 \\_\\_missing\\_\\_ 方法\n\n当我们调用 my_dict[key] 时，**如果 key 是一个字符串**，我们会需要用 my_dict['name'] 来获取，如果你觉得比较麻烦，想直接用 my_dict[name] 的话，可以采用如下方法：\n\n```python\nfrom collections import UserDict\n\n\nclass StrKeyDict(UserDict):\n    def __missing__(self, key):\n        if isinstance(key, str):\n            raise KeyError(key)\n        return self[str(key)]\n\n    def __contains__(self, key):\n        return str(key) in self.data\n\n    def __setitem__(self, key, item):\n        self.data[str(key)] = item\n\nd = StrKetDict([('1', 'one'), ('2', 'two')])\n>>> d[2]\n'two'\n```\n\n### 使用 \\_\\_getattr\\_\\_ 方法（不推荐）\n\n有时我们可能更懒，想要用类属性类似的 my_dict.name 方法来获取 value，这时，可以使用 \\_\\_getattr\\_\\_ 方法：\n\n```python\nfrom collections import UserDict\n\n\nclass AttrDict(UserDict):\n    def __getattr__(self, attr):\n        return self[attr]\n    \nd = AttrDict([('name', 'wincer'), ('age', '20')])\n\n>>> d.name\n'wincer'\n```\n\n并不推荐这样做，因为在 dict 实现中，并没有要求 key 一定为合法标识符，只需要是可散列对象即可，而上面的写法一旦 key 不为合法标识符，会 raise 一个 SyntaxError：\n\n```python\nd.update({(0): 'zero'})\n>>> d[(0)]\n'zero'\n>>> d.0\nSyntaxError: invalid syntax\n```\n\n如果非常想使用 . 来获取 value 的话，建议使用 namedtuple\n\n当然这也就意味着必须使用合法标识符了：\n\n```python\nfrom collections import namedtuple\nID = namedtuple('ID', 'name age')\nme = ID('wincer', 20)\n>>> me.name\n'wincer'\n\nID = namedtuple('ID', '(1, 0) age')\nValueError: Type names and field names must be valid identifiers: '(1'\n```\n\n### 实现 switch ... case 结构\n\n同样借助键查询，可以实现 Python 中没有的 switch ... case 结构：\n\n```python\ndef foo(x):\n    data = {\n        0: 'zero',\n        1: 'one',\n        2: 'two',\n    }\n    return data.get(x, None)\n```\n\n所以说 Python 不设计 switch ... case 语句是有原因的，看上面的实现，比 switch ... case 不知道高到哪里去了。\n\n## dict 和它的小伙伴们\n\n### OrderedDict\n\n在添加键的时候会按顺序添加，同时 .popitem 是会删除并返回字典的最后一个元素而不是像 dict 里面一样可能会删除任意元素。\n\n### Counter\n\n这个映射会给键一个计数器，每次更新键时都会增加这个计时器，所以这个类型可以用以给可迭代类型计数：\n\n```python\nfrom collections import Counter\n\nct = Counter('hfkjahfkakhf')\n>>> ct\n\nCounter({'a': 2, 'f': 3, 'h': 3, 'j': 1, 'k': 3})\nct.update('fdjlahkla')\n>>> ct\nCounter({'a': 4, 'd': 1, 'f': 4, 'h': 4, 'j': 2, 'k': 4, 'l': 2})\n\n>>> ct.most_common(2)\n[('h', 4), ('f', 4)]\n```\n\n### UserDict\n\n用法见键查询。\n\n### 不可变映射\n\n在 Python 3.3 后的版本，types 模块引入一个名为 MappingProxyType 的类。如果给这个类一个映射，它会返回一个只读的映射视图。但它是动态的，如果原映射改动，那么它也会相应改动。\n\n```python\n>>> int.__dict__\nmappingproxy({'__abs__': <slot wrapper '__abs__' of 'int' objects>,\n              '__add__': <slot wrapper '__add__' of 'int' objects>,\n              ...})\n\nfrom types import MappingProxyType\nd = {1: 'A'}\nd_proxy = MappingProxyType(d)\n\n>>> d_proxy[2] = 'x'\nTypeError: 'mappingproxy' object does not support item assignment\n\nd[2] = 'B'\n>>> d_proxy[2]\n'B'\n```"},{"title":"《代码整洁之道》读书笔记","subtitle":"","url":"/posts/65e48179/","date":"2018-04-19T10:11:12.000Z","updated":"2018-04-19T12:34:21.000Z","category":"文字阁","tags":["笔记","代码"],"content":"> 相对于任何宏伟愿景，对细节的关注甚至是更为关键的专业性基础。首先，开发者通过小型实践获得可用于大型实践的技能和信用度。其次，宏大建筑中最细小的部分，比如关不紧的门、有点儿没铺平的地板，甚至是凌乱的桌面，都会将整个大局的魅力毁灭殆尽。这就是整洁代码之所系。\n\n<!--more-->\n\n本书「序」中的这段话完美的诠释了作者写本书的意义。（简评在最后）\n\n## 序\n\n1. 神在细节之中。\n2. 5S 哲学包括以下概念：\n   - 整理（Seiri）\n   - 整顿（Seiton）\n   - 清楚（Seiso）\n   - 清洁（Seiketsu）\n   - 身美（Shitsuke）\n\n## 整洁代码\n\n1. 有人也许以为，关于代码的书有点落后于时代——代码不再是问题：我们应当关注模型和需求。……扯淡！我们永远抛不掉代码，因为代码呈现了需求的细节。在某些层面上，这些细节无法被忽略或抽象，必须明确之。将需求明确到机器可以执行的细节程度，就是编程要做的事。而这种规约正是**代码**。\n\n2. 勒布朗（LeBlanc）法则：**稍后等于永不**（Later equals never）。\n\n3. 多数人都知道一幅画是好还是坏。但能分辨优劣并不表示懂得绘画。能分辨整洁代码和肮脏代码，也不意味着会写整洁代码！\n\n4. **Bjarne Stroustrup（C++ 语言发明者）**：我喜欢优雅和高效的代码。代码逻辑应当直截了当，叫缺陷难以隐藏；尽量减少依赖关系，使之便于维护；依据某种分层战略完善错误处理代码；性能调至最优，省得引诱别人做没规矩的优化，高处一堆混乱来，整洁的代码只做好一件事。\n\n5. **Grady Booch（《面向对象分析与设计》作者）**：整洁的代码简单直接。整洁的代码如同优美的散文。整洁的代码从不隐藏设计者的意图，充满了干净利落的抽象和直截了当的控制语句。\n\n6. **Ron Jeffries（《极限编程实施》作者）**：简单代码，依其重要顺序：\n   - 能通过所有测试；\n   - 没有重复代码；\n   - 体现系统中的全部设计理念；\n   - 包括尽量少的实体，比如类、方法、函数等。\n\n7. **Ward Cunningham（Wiki 发明者）**：如果每个例程都让你感到深合己意，那就是整洁代码。如果代码让编程语言看起来像是专为解决那个问题而存在，就可以称之为漂亮的代码。\n\n8. 光把代码写好可不够。必须时时保持代码整洁。\n\n## 有意义的命名\n\n1. **名副其实**：变量、函数或类的名称应该已经答复了所有的大问题。它该告诉你，它为什么会存在，它做什么事，应该怎么用。\n\n2. **避免误导**：应当避免使用与本意相悖的词。别用 accountList 来指称一组账号，除非它真的是 List 类型。用 accountGroup 或 bunchOfAccounts，甚至 accounts 都会好一些。\n\n3. **做有意义的区分**：以数字系列命名（a1、a2，……aN）是依义命名的对立面。这样的名称纯属误导——完全没有提供正确信息；没有提供导向作者意图的线索。\n\n   ```java\n   public static void copyChars(char a1[], char a2[]) {\n       for (int i = 0; i < a1.length; i++) {\n           a2[i] = a1[i];\n       }\n   }\n   ```\n\n   如果参数名改为 source 和 destination，这个函数就会像样许多。\n\n4. **使用读得出来的名称**：\n\n   ```java\n   private Date genymdhms; // 生成日期，年、月、日、时、分、秒\n   private Date generationTimestamp;\n   ```\n\n5. **使用可搜索的名称**：窃以为单字母名称**仅**用于短方法中的本地变量。名称长短应于其作用域大小相对应。\n\n6. **避免思维映射**：不应当让读者在脑中把你的名称翻译为他们熟知的名称。\n\n7. **类名**：类名和对象名应该是名词或名词短语，如 Customer、WikiPage。避免使用 Manager、Data 这样的类名。\n\n8. **方法名**：方法名应当是动词或动词短语，如 postPayment、deletePage 或 save。\n\n9. **每个概念对应一个词**：给每个抽象概念选一个词，并且一以贯之。\n\n10. **别用双关语**：避免将同一单词用于不同目的。\n\n## 函数\n\n1. 函数的第一规则是要短小。第二条规则是还要更短小。\n\n2. 函数应该做一件事。做好这件事。只做这一件事。\n\n3. 别害怕长名称。长而具有描述性的名称，要比短而令人费解的名称好。长而具有描述性的名称，要比描述性的长注释好。\n\n4. 最理想的参数数量是零（零参数函数），其次是一（单参数函数），再次是二（双参数函数），应尽量避免三（三参数函数）。如果函数看来需要两个、三个或三个以上参数，就说明其中一些参数应该封装为类了。\n\n5. 函数要么做什么事，要么回答什么事，但二者不可兼得。函数应该修改某对象的状态，或是返回该对象的有关信息。\n\n6. 重复可能是软件中一切邪恶的根源。许多原则与实践规则都是为控制与消除重复而创建。\n\n7. 我写函数时，一开始都冗长而复杂。有太多缩进和嵌套循环。然后我打磨这些代码，分解函数、修改名称、消除重复。我缩短和重新安置方法。有时我还拆散类。\n\n8. 大师级程序员把系统当作故事来讲，而不是当作程序来写。他们使用选定编程语言提供的工具构建一种更为丰富且更具表达力的语言，用来讲那个故事。\n\n## 注释\n\n1. **Brian W. Kernighan 与 P. J. Plaugher**：别给糟糕的代码加注释——重新写吧。\n2. 注释的恰当用法是弥补我们在用代码表达意图时遭遇的失败。注意，我用了「失败」一词。我是说真的。注释总是一种失败。我为什么要极力遍地注释？因为注释会撒谎。\n3. **好注释**：\n   1. 法律信息\n   2. 提供信息的注释\n   3. 对意图的解释\n   4. 阐释\n   5. 警示\n   6. TODO\n\n## 格式\n\n1. 你今天编写的功能，极有可能在下一版本中被修改，但代码的可读性却会对以后可能发生的修改行为产生深远影响。\n2. **垂直格式**：\n   1. 关系密切的概念应该相互靠近。\n   2. 变量声明应尽可能靠近其使用位置。\n   3. 实体变量应该在类的顶部声明。\n   4. 若某个函数调用了另外一个，就应该把它们放到一起，而且调用者应该尽肯能放在被调用者上面。\n3. **横向格式**：\n   1. 应该尽量保持代码行短小。死守 80 个字符上限有点僵化，至多在 100 或 120 个字符。\n   2. 赋值操作符周围加上空格字符，以此加上强调目的。\n   3. 不在函数名和左圆括号之间加空格。\n   4. 源文件是一种继承结构，而不是一种大纲结构。类中的方法相对该类缩进一个层级。方法的实现相对方法声明缩进一个层级。\n\n## 对象和数据结构\n\n1. 过程式代码便于在不该动既有数据结构的前提下添加新函数。面向对象代码便于在不改动既有函数的前提下添加新类。\n\n2. 得墨忒耳率认为，类 C 的方法 f 只应该调用以下对象的方法：\n\n   - C\n   - 由 f 创建的对象；\n   - 作为参数传递给 f 的对象；\n   - 由 C 的实体变量持有的对象。\n\n   方法不应调用由任何函数返回的对象的方法。换言之，只跟朋友谈话，不与陌生人谈话。\n\n3. 对象曝露行为，隐藏数据。便于添加新对象类型而无需修改既有行为，同时也难以在既有对象中添加新行为。数据结构曝露数据，没有明显的行为。便于向既有数据结构添加新行为，同时也难以向既有函数添加新数据结构。\n\n## 错误处理\n\n1. 错误处理很重要，**但如果它搞乱了代码逻辑，就是错误的做法**。\n2. 在某种意义上，try 代码块就像是事务。catch 代码块将程序维持在一种状态，无论 try 代码块中发生了什么均如此，所以，在编写可能抛出异常的代码时，最好先写出 try-catch-finally 语句。\n3. 你抛出的每个异常，都应当提供足够的环境说明，以便判断错误的来源和处所。\n4. 对异常可以依据其来源分类：是来自组件还是其他地方？或依其类型分类：是设备错误、网络错误还是编程错误？不过，当我们在应用程序中定义异常类时，最重要的考虑应该是**它们如何被捕获**。\n5. 返回 null 值，基本上是在给自己增加工作量，也是在给调用者添乱。只要有一处没检查 null 值，应用程序就会失控。在方法中返回 null 值是糟糕的做法，但将 null 值传递给其他方法就更糟糕了。\n\n## 边界\n\n1. **学习性测试**（learning tests）：不要在生产代码中试验新东西，而是编写测试来遍览和理解第三方代码\n2. 使用尚不存在的代码，将尚未开发完毕的 API 从中隔离出来。自己通过使用符合应用程序的接口，一旦 API 被定义出来，再将二者对接。\n3. 通过代码中少数几处引用第三方边界接口的位置来管理第三方边界。\n\n## 单元测试\n\n1. TDD 三定律：\n   1. 在编写不能通过的单元测试前，不可编写生产代码。\n   2. 只可编写刚好无法通过的单元测试，不能编译也不算通过。\n   3. 只可编写刚好足以通过当前失败测试的生产代码。\n2. 脏测试等同于——如果不是坏于的话——没测试。\n3. 测试代码和生产代码一样重要。它可不是二等公民。它需要被思考、被设计和被照料。它该像生产代码一般保持整洁。\n4. 整洁的测试有什么要素？有三个要素：可读性、可读性和可读性。\n5. 整洁的测试遵循以下 5 条规则：\n   1. **快速（Fast）**：测试应该够快。\n   2. **独立（Independent）**：测试应该相互独立。\n   3. **可重复（Repeatable）**：测试应当可在任何环境中重复通过。\n   4. **自足验证（Self-Validating）**：测试应该有布尔值输出。\n   5. **及时（Timely）**：测试应及时编写。\n\n## 类\n\n1. 类的第一条规则是类应该短小。第二条规则是还要更短小。\n2. 单一权责原则（SRP）认为，类或模块应有且只有一条加以修改的理由。\n3. 系统应该由许多短小的类而不是少量巨大的类组成。每个小类封装一个权责，只有一个修改的原因，并与少数其他类一起协同达成期望的系统行为。\n4. 通常而言，方法操作的变量越多，就越黏聚到类上。如果一个类中的每个变量都被每个方法所使用，则该类具有最大的内聚性。\n5. 开放-闭合原则（OCP）：类应当对扩展开放，对修改封闭。\n6. 依赖倒置原则（DIP）：类应当依赖于抽象而不是依赖于具体细节。\n\n## 系统\n\n1. 软件系统应将启始过程和启始过程之后的运行时逻辑分离开，在启始过程中构建应用对象，也会存在相互缠结的以来关系。\n2. 可以使用抽象工厂模式让应用自行控制何时创建对象，但构造的细节却隔离于应用程序代码之外。\n3. 依赖注入（Dependency Injection）：对象不应负责实体化对自身的依赖。反之，它应当将这份权移交给其他「有权力」的机制，从而实现控制的反转。\n4. 我们应该只去实现今天的用户故事，然后重构，明天再扩展系统、实现新的用户故事。这就是迭代和增量敏捷的精髓所在。\n5. 面向方面编程（aspect-oriented）：被称为方面的模块构造指明了系统中哪些点的行为会以某种一致的方式被修改，从而支持某种特定的场景。\n\n## 迭进\n\n1. 简单设计规则 1：运行所有测试：遵循有关编写测试并持续运行测试的简单、明确的规则，系统就会更贴近 OO 低耦合度、高内聚度的目标。\n2. 简单设计规则 2：重构：在重构过程中，可以应用有关优秀软件设计的一切知识。提升内聚性，降低耦合度，切分关注面，模块化系统性关注面，缩小函数和类的尺寸，选用更好的名称等。\n3. 不可重复：「小规模复用」可大量降低系统复杂性。\n4. 表达力：做到有表达力的最重要方式却是尝试。\n5. 尽可能少的类和方法。\n\n## 并发编程\n\n| 名词     | 基础定义                                                     |\n| -------- | -----------------------------------------------------------|\n| 限定资源 | 并发环境中有着固定尺寸或数量的资源。例如数据库连接和固定尺寸读/写缓存等 |\n| 互斥     | 每一时刻仅有一个线程能访问共享数据或共享资源                 |\n| 线程饥饿 | 一个或一组线程互相等待执行结束。                             |\n| 死锁     | 两个或多个线程互相等待执行结束。                             |\n| 活锁     | 执行次序一致的线程，每个都想要起步，但发现其他线程已经「在路上」。 |\n\n1. 对象是过程的抽象。线程是调度的抽象。\n\n2. 并发是一种解耦策略。它帮助我们把做什么（目的）和何时（时机）做分解开。\n\n3. 并发软件的中肯说法：\n\n   - 并发会在性能和编写额外代码上增加一些开销；\n   - 正确的并发是复杂的，即便对于简单的问题也是如此；\n   - 并发缺陷并非总能重现，所以常被看做偶发事件而忽略，未被当做真的缺陷看待；\n   - 并发常常需要对设计策略的根本性修改。\n\n5. 生产者-消费者模型：一个或多个生产者线程创建某些工作，并置于缓存或者队列中。一个或者多个消费者线程从队列中获取并完成这些工作。生产者和消费者之间的队列是一种限定资源。\n\n6. 读者-作者模型：当存在一个主要为读者线程提供信息源，但只是偶尔被作者线程更新的共享资源，吞吐量就会是个问题。增加吞吐量，会导致线程饥饿和过时信息的积累。协调读者线程不去读取正在更新的信息，而作者线程倾向于长期锁定读者线程。\n\n7. 宴席哲学家：许多企业级应用中会存在进程竞争资源的情形，如果没有用心设计，这种竞争会遭遇死锁，活锁，吞吐量和效率低等问题。\n\n本书后几章主要侧重于讲解 Java 代码的一些例子，对其它语言帮助不大，在这里就不做整理了。\n\n---\n\n正如我在[上一篇读书笔记](../a6c2a51d/)中所说的：每一本中都会充斥着许多作者的自己的观点、看法，而唯有价值观相符合或相接近的人才会觉得本书写得很不错，上一本《黑客与画家》是，这本《代码整洁之道》也是，你可能很难认为变量的命名需要有那么考究，函数的长短有那么重要，心里想着程序能运行就没事，甚至连 WARNING 都忽视掉，这类人想必并不是本书的目标群体。而本书的目标群体在开头已经注明了：你想成为一个更好的程序员。其实我觉得目标群体还可以加上一小撮人：有强迫症的程序员——比如我。\n\n我曾经看自己四个月前的代码能羞愧得钻进地里，心想着怎么能写出这么烂的[代码](https://gist.github.com/WincerChan/362331456a6e0417c5aa1cf3ff7be2b7/revisions)。这四个月固然有我对该门语言较高层级的数据结构更加熟悉，能更熟练的操作它们，但更多的是编程观念的改变：需要用心来写代码，不要简单敷衍了事，不要认为程序只要能运行就算成功。程序毕竟还是写给人看的，就算不是为了别人，看着意义明确的变量，缩进优美的段落，结构分明的函数，想必自己心里也会很舒畅的。"},{"title":"Nextcloud 搭建私人云服务教程","subtitle":"","url":"/posts/bf0413ac/","date":"2018-03-31T07:03:31.000Z","updated":"2018-04-01T11:03:34.000Z","category":"分享境","tags":["云服务","NextCloud","VPS"],"content":"我一直很不相信国内的那些云服务提供商（尤其是在李彦宏发表的讲话「中国用户对隐私问题没那么敏感，在个人隐私方面更加开放，一定程度上愿用隐私换方便和效率」后），因为怕隐私得不到保障，故而我的一些隐私数据都是存放在国外的云盘（如 Dropbox、Drive 等）上。<!--more-->\n\n可这俩在国内都被墙了，而手机翻墙总是显得有些不够方便，与是我就琢磨着自己搭建一个云服务，随后就发现了 Nextcloud 这一开源云服务。而网上的教程都太过复杂了，对新手太过不友好，于是乎——一篇近乎傻瓜式的 Nextcloud 教程诞生了。\n\n## 安装\n\n这里采用 Docker 容器方式来安装 Nextcloud，这样就不用担心各种环境依赖了（Nextcloud 的依赖简直多得吓人，而 Dockerfile 会帮你把依赖都配置好）\n\n### 安装 Docker\n\n> 注：Docker 仅支持 64-bit 的系统\n\nDocker 现已被各大发行版的仓库收入，采用正常安装命令即可：\n\n```bash\nyum -y install docker\n```\n\n随后，启动 Docker 守护进程：\n\n```bash\n# systemctl\nsystemctl start docker\n# Service\nservice docker start\n```\n\n### 安装 NextCloud\n\n#### 自动安装\n\n有了 Docker 后，就可以几行代码安装 Nextcloud 了：\n\n```bash\n# clone nextcloud 的 docker 容器\ngit clone https://github.com/nextcloud/docker.git\n# 耐心等待安装\ndocker run -d -p 8080:80 nextcloud \n```\n\n安装完成后先别忙着启动，`docker ps -a -q` 查看一下容器的 id，是一串 12 位的字符串，为了便于记忆，重命名一下：\n\n```bash\ndocker rename ××× nextcloud     # ××× 即为容器 id\n```\n\n随后就可以采用如下命令启动了：\n\n```bash\ndocker start nextcloud\n# 测试\ncurl http://localhost:8080\n```\n\n这样，就完成了 Nextcloud 的安装工作。\n\n#### 手动安装\n\n方法一只能安装最新版的 Nextcloud，而最新版缺少部分功能，如：无法添加 Drive 和 Dropbox 的外置存储。如果你对外置存储不是很 care 的话，那就按照方法一安装就可以了。\n\n```bash\ngit clone https://github.com/nextcloud/docker.git\ncd docker/12.0/apache\n```\n\n这里采用官方编写的 Dockerfile 手动构建，所以时间会花得比较久。\n\n```bash\ndocker build -t nextcloud .\n```\n\n这时候用 `docker images` 应该可以看到刚刚创建的镜像了，随后创建容器：\n\n```bash\ndocker create -v /var/www/html/apps/:/var/www/html/apps -v /var/www/html/config/:/var/www/html/config -v /var/www/html/data/:/var/www/html/data -p 127.0.0.1:8080:80/tcp --name nextcloud nextcloud\n```\n\n稍稍解释一下参数：\n\n- -v 后面是地址，前半部分是 VPS 的地址，后半部分是容器内的地址\n- -p 后面是端口号\n- --name 后面是容器名称\n- 最后的 nextcloud 是镜像名称\n\n## 配置\n\n### Nginx 配置\n\n由于 NextCloud 已经占用了 8080 端口，这里采用 Nginx 做反向代理，将域名直接解析至 8080 端口。\n\n```nginx\nserver {\n  listen 80;\n  server_name cloud.example.com;\n  location / {\n    proxy_pass http://localhost:8080;\n  }\n}\n```\n\n重启 Nginx 服务后，就可以通过 cloud.example.com 来访问云服务了。\n\n### NextCloud 配置\n\n```bash\n# 进入容器内的 bash\ndocker exec -i -t nextcloud bash\n```\n\n#### 重定向 overwritehost\n\n有时候 NextCloud 会自己定向至本地的 8080 端口，所以需要手动重写正确的地址：如果提示不能定位软件包，先执行 `apt-get update`。\n\n```bash\nvim config/config.php\n# 加上下面这行\n'overwritehost' => 'cloud.example.com',\n```\n\n重启，让配置生效：\n\n```bash\ndocker restart nextcloud\n```\n\n### MySQL 配置\n\n~~由于我 VPS 的内存比较小，所以并没有启用 MySQL/MariaDB 数据库（怕爆内存），而是采用了 SQLite，反正也是我一个人用，问题不大。~~\n\n开启了 MySQL 后发现内存也就多了 20M（但性能的提升可不是一点半点），遂还是改成 MySQL 了：\n\n1. 安装 MySQL（这里采用 MariaDB 分支）\n\n   ```bash\n   yum -y install mariadb-server mariadb-client\n   # 设置一下 root 密码等\n   mysql_secure_installation\n   ```\n\n2. 开启 daemon 服务\n\n   ```bash\n   systemctl start mariadb\n   systemctl enable mariadb\n   ```\n\n3. `mysql -uroot -p` 登录 MySQL\n\n   ```sql\n   # 创建 nextcloud 数据库\n   CREATE DATABASE nextcloud CHARACTER SET = utf8 COLLATE = utf8_general_ci;\n   # 创建 nextcloud 的用户\n   CREATE USER nextcloud IDENTIFIED BY 'admin123';\n   # 赋予对数据库所有的权限\n   GRANT ALL ON nextcloud.* TO nextcloud;\n   ```\n\n\n\n### 初始设置\n\n1. 打开 https://cloud.example.com\n\n2. 创建管理员帐号和密码\n\n3. 数据库就选择 MySQL/MariaDB，其它参考下表：\n\n|  名称  |     值      |\n| :--: | :--------: |\n| 用户名  | nextcloud  |\n|  密码  |  admin123  |\n| 数据库名 | nextcloud  |\n|  地址  | 172.17.0.1 |\n\n**注意：这里的地址千万不要填写成了 localhost 或者 172.0.0.1，因为这里的地址需要容器内与外部通信。**\n\n点击完成后，等待几秒就可以使用了。\n\n## 挂载外部云盘\n\n由于我 VPS 的容量只有 10g，故而放不了过多的视频，就考虑采用外部存储的方法，将 Drive、Dropbox 挂载至 Nextcloud 外部存储或者 VPS。\n\n> 注：Nextcloud 13 已经取消对 Drive、Dropbox 外部存储的支持（这时候你也可以选择把 Drive 直接挂载至 VPS 本地目录，再通过外部存储链接至挂载目录来完成）。\n\n### 启用外部存储插件\n\n在应用页面，启用 `External storage support` 插件：如果提示：「没有安装 “smbclient”无法挂载 “SMB / CIFS”, “SMB / CIFS 使用 OC 登录信息”. 请联系您的系统管理员安装」\n\n解决办法：\n\n### 安装 smbclient\n\n```bash\n# 进入容器的内的 console\ndocker exec -i -t nextcloud bash\napt-get install libsmbclient-dev\n```\n\n这里简单说一下，不管你的 VPS 原本的系统是 CentOS、RedHat、Debian，统一都用 apt-get 安装，因为现在处于的是 docker 容器内的系统，与 VPS 的系统是分离的。\n\n接着再安装 smbclient：\n\n```bash\npecl install smbclient\n```\n\n同时会提示：「You should add \"extension=smbclient.so\" to php.ini」，这里又被小坑一把，网上大部分教程所说的 `/etc/php.d/php.ini` 并不存在，在 docker 容器内部该文件是在：\n\n```bash\nvim /usr/local/etc/php/conf.d/docker-php-ext-intl.ini\n# 加上下面这行\nextension=smbclient.so\n```\n\n随后重启 Nextcloud 服务就应该就 OK 了。\n\n随后如果你安装的 Nextcloud 是 13 版本及以上的话，就只有考虑用 [box](https://www.box.com/) 提供的 [WebDAV](https://community.box.com/t5/Upload-and-Download-Files-and/WebDav-with-Box/ta-p/310) 来作为外置存储了，不过只有 10G 的容量，且最大文件限制是 250MB。如果是用的 12 版本及以下的话，就可以考虑采取 Drive 作为外置存储了：\n\n### 获取 API\n\n1. 访问 [Google 开发者平台](https://www.orgleaf.com/go.php?url=https://console.developers.google.com)：\n\n2. 点击「启用 API 和服务」\n\n3. 点击「Google Drive API」\n\n4. 点击「启用」\n\n5. 点击左侧的凭据 -> OAuth 同意屏幕：\n\n   ![oauth 示例](https://ae01.alicdn.com/kf/HTB1F7e1KkKWBuNjy1zj763OypXaf.png)\n\n   按照以上格式填写，点击保存\n\n6. 随后创建凭据：\n\n   应用类型选择**网页应用**，其它的参考以下：\n\n   ![url 配置](https://ae01.alicdn.com/kf/HTB1mgtydi6guuRjy0Fm7610DXXan.png)\n\n   点击创建后，会弹出悬浮框告诉你 ID 和 Key。\n\n\n### 配置 Nextcloud\n\n登录 Nextcloud，转至管理页面，点击「外部存储」，选择 Google Drive，填入 API 和 Key，点击授权，若授权时出现 400 错误，那么是重定向的 URI 出问题了，再添加如下一条：\n\n```ini\nhttps://cloud.example.com/index.php/settings/admin/externalstorages\n```\n\n如果提示「此应用未经过验证」，点击高级 -> 转至 example.com，忽略掉就行。\n\n![外置存储](https://ae01.alicdn.com/kf/HTB1OjWeKXmWBuNjSspd762ugXXaE.png)\n\n当出现了绿色按钮，就表示配置成功了。\n\n参考：\n\n- [Docker image of Nextcloud](https://github.com/nextcloud/docker#how-to-use-this-image)\n- [用 Docker 和 Nginx 搭建自己的云服务器（Nextcloud）](https://oing9179.github.io/blog/2017/03/Setup-Nextcloud-using-Docker-and-Nginx/)\n- [连接 Google Drive 教程](https://www.orgleaf.com/903.html)\n- [FreeNAS 10 NextCloud 開啟外部儲存媒體的 SMB 功能](https://www.brilliantcode.net/486/freenas-10-nextcloud-use-smb-as-external-storage/)"},{"title":"没有希望的事儿，还有坚持的必要吗","subtitle":"","url":"/posts/18b98ea6/","date":"2018-03-21T02:47:45.000Z","updated":"2018-03-21T10:39:42.000Z","category":"碎碎念","tags":["感想","成长"],"content":"「你说，没有希望的事，还有坚持的必要吗？」\n\n确实是没想到，看国产青春剧也能看出了共鸣。<!--more-->\n\n\n![拼接截图.jpg](https://ae01.alicdn.com/kf/HTB1zLRQKaSWBuNjSsrbq6y0mVXaB.jpg)\n\n![拼接截图 (1).jpg](https://ae01.alicdn.com/kf/HTB1c_1MKqmWBuNjy1Xaq6xCbXXaP.jpg)\n\n忘记很早之前在哪看到过一句话：人会长大三次。第一次是在发现自己不是世界中心的时候；第二次是在发现即使再怎么努力，终究还是有些事令人无能为力的时候；第三次是在明知道有些事可能会无能为力，但还是会尽力争取的时候。\n\n最初看这句话还没什么感觉，最近看了「最好的我们」后，突然就触动了。\n\n那种触动，想来就是怎么也绕不开的「成长」了：自己做了想做的事，而生活却没有给自己想要的结果。于是乎，以后再遇见了想做的事，开始犹豫了，开始畏缩了，开始计较得失了，因为有了之前的经历，担心自己做了，却也得不到自己想要的结果。\n\n你当然可以说是因为自己长大了，会计较得失了、不会像小时候一样：想干什么就去干什么。是啊，第二次成长的你知道了有些事情即使再怎么努力，也不会得到满意的结果，于是干脆就不去做了。\n\n可目前处于不明成长阶段的我啊，又觉得凡事要是都仔细衡量得失后再去想做还是不做的话，那人生想必会少掉许多乐趣、会错过许多事情。\n\n---\n\n我果然还是不适合看电视剧，花了一个月时间才把《最好的我们》看完（小时候那种看电视剧甚至广告时间都不愿意转台生怕错过衔接部分的劲儿都不知道哪去了，以后有时间还是多看看电影和书），听说还有几部青春剧也挺不错（《你好，旧时光》、《一起同过窗》等），就不看了，虽说确实能勾起高中时的那些或苦涩或美好的回忆，可那些回忆却再也不可得了。\n\n也不想总是陷在回忆里，毕竟我，到底是已经长大了。"},{"title":"QQ 音乐外链解析","subtitle":"","url":"/posts/72171293/","date":"2018-03-07T04:23:06.000Z","updated":"2018-03-08T09:39:51.000Z","category":"实验室","tags":["音乐解析","Javascript","网易云"],"content":"## 起因\n\n大概在五天前，忽然发现一直在用的网易云解析不能用了，去作者的项目查看才知道原来是网易云更换了新的接口，旧接口的请求现在统一返回 403。于是乎，便萌生了自己写一个接口的想法。\n\n<!--more-->\n\n其实网易云的外链获取目前还是有几种可用方案，比如：\n\n1. [云音乐直链生成器](https://m1.jixun.moe/)\n2. 手动替换：`https://music.163.com/song/media/outer/url?id=[].mp3`，将中括号改为歌曲 id，即为外链\n\n这两种方法其实大同小异，都会 302 至歌曲的缓存地址，但也存在一个身为强迫症的我无法忍受的缺点——~~缓存地址的协议是 `HTTP `（从云音乐官网现在还有大量的 Mixed Content 就可以看出网易对这方面并不上心），而且自己将协议修改成 `HTTPS` 后访问部分歌曲又会有机率出现 403，这可真是逼死我了~~现在第二个方法已经会直接 302 至  HTTPS 协议了。于是决定暂时放弃掉网易云，换其他家的顶着。\n\n我又用回了网易云接口，并编写了一个 [API 文档](https://api.itswincer.com/cloudmusic/)，欢迎使用。\n\n## QQ 音乐\n\n考虑了一圈，还是决定选 QQ 音乐。在网上也找到了 QQ 音乐所提供的接口：\n\n- 请求地址：`https://c.y.qq.com/base/fcgi-bin/fcg_music_express_mobile3.fcg`\n- 参数，有三个：\n  1. songmid：歌曲页 Url 的 `https://y.qq.com/n/yqq/song/[].html` 括号部分\n  2. filename：歌曲名 `'C00' + songmid + '.m4a' `\n  3. guid：随机生成的数字串 `int(random() * 2147483647) * int(time() * 1000) % 10000000000`\n\n综上，歌曲的请求地址为：`https://c.y.qq.com/base/fcgi-bin/fcg_music_express_mobile3.fcg?format=json&cid=205361747&uin=0&songmid=[smid]&filename=[filename]&guid=[guid]`\n\n向这个地址请求后，会得到一个 JSON 格式的数据文件，包含了我们需要的信息：vkey\n\n```bash\ncurl 'https://c.y.qq.com/base/fcgi-bin/fcg_music_express_mobile3.fcg?format=json&cid=205361747&uin=0&songmid=[smid]&filename=[filename]&guid=[guid]'\n{\"code\":0,\"cid\":205361747,\"userip\":\"××.××.××.××\",\"data\":{\"expiration\":80400,\"items\":[{\"subcode\":104001,\"songmid\":\"000uhMwj387EBp\",\"filename\":\"C00000uhMwj387EBp.m4a\",\"vkey\":\"B6BB8F604606DFDC82FD81CE33BC9C0277365D4B8B1BC8BCC909E408EAC9822315B2B9D021F42B495FA14AADCB598B21BCDB867931B7A953\"}]}}\n```\n\n得到了最重要的 `vkey` 字段后，就可以解析出歌曲的「真实链接」了：\n\n`https://dl.stream.qqmusic.qq.com/[filename]?vkey=[vkey]&guid=[guid]&uin=0&fromtag=66`\n\n你可能注意到返回的信息中还包含了 `expiration` 字段。是的，`vkey` 只有在该时间段内才有效，当然这个问题很好解决，可以把该程序部署至服务器，而从服务器发起请求获取链接后 302 至歌曲链接。\n\n而当我满心欢喜的把这个脚本向服务端部署的时候，却失败了：原因是接口的请求地址只支持国内的（想来是因为 QQ 音乐只拿到了在大陆地区的版权），而我的服务器在美国，这个问题就有些难解决了（我没有国内的服务器）。\n\n于是我想另辟蹊径。\n\n## 纯 JS 解析\n\n既然服务端无法解析，那就用 JS 在用户端解析。\n\n但又带来了另一个问题——跨域。\n\n目前跨域请求比较好的解决方案有两种：CORS 和 JSONP，其中 CORS 需要服务器端设置 `Access-Control-Allow-Origin`，所以也就只有使用 JSONP 了。\n\n> 注意：跨域请求失败原因浏览器端阻止显示，并非服务器端无法返回数据\n\n使用 JSONP 时要求服务端返回的是满足 [JSONP 模式](https://zh.wikipedia.org/wiki/JSONP#%E5%8E%9F%E7%90%86)的文件，不能是纯 JSON 文件，举个例子：\n\n```javascript\nvar url1 = \"https://lab.itswincer.com/jsonp/without-callback.js\";\nvar url2 = \"https://lab.itswincer.com/jsonp/with-callback.js\";\nfunction foo(data) {\n    alert(`Hi, I am ${data.name}`);\n}\nvar script = document.createElement('script');\nscript.setAttribute('src', url1);\ndocument.body.appendChild(script);\nscript.setAttribute('src', url2);\ndocument.body.appendChild(script);\n```\n\n其中 `without-callback.js` 返回的是纯 JS 文件，`with-callback.js` 返回的是满足模式的 JS 文件。可以运行上面代码看看结果。\n\n本想直接用现成的 `ajax`，考虑到并非所有的网站都引入了 jQuery，而为 `ajax` 就引入一个那么庞大的库又有些没必要。\n\n于是就自己封装了一个 `getJSONP()` 接口来搭配 `getMusic()` 使用。\n\n项目已开源，具体的代码见[这里](https://github.com/WincerChan/QQMusic-Parse)，有很详细的注释。\n\n### 使用\n\n为了使接口更干净，没有使用 callback 函数，而是使用了 ES7 的新特性 async、await。尝试过使用 Babel 等工具转换成兼容更好的 ES5 代码，但是并没有成功，故而浏览器的兼容可能存在问题。\n\n引入[这个 JS 文件](https://cdn.jsdelivr.net/gh/wincerchan/QQMusic-Parse@0.3/parse.min.js)：\n\n接口：`await getMusic()`，如下图：\n\n![示例](https://res.cloudinary.com/wincer/image/upload/v1530844981/blog/qqmusic_parse/sample.png)\n\n> 注意：在调用 getMusic() 的时候一定要加上 await 关键字，否则返回的就是一个 Promise 对象了\n\n### 配合 Aplayer\n\n由于使用了 ES7 的新特性：async 和 await，故而 Aplayer 的配置文件也需要稍加改动：需要将原配置信息放至包含 `async` 关键字的函数内，随后调用这个函数，如下：\n\n```javascript\nasync function syncHand() {\n    new Aplayer(...);\n}\nsyncHand();\n```\n\n## 结语\n\n越来越认同保罗 · 格雷厄姆那句「黑客就像画家，工作起来是有心理周期的有时候，你有了一个令人兴奋的新项目，你会愿意为它一天工作 16 个小时。等过了这一阵，你又会觉得百无聊赖，对所有事情都提不起兴趣。」话了，简直就是我的写照：这四天大约花费了 30 小时（当然有很大一部分缘由是之前没怎么学过 JavaScript，修改一下别人的代码还行，自己写就有点「捉襟见肘」了），而估计后几天又会陷入「空窗期」了。\n\n而 JavaScript 又是一门有很多~~坑爹~~特性的语言，也让我把初学者的坑基本上都踩完了（还是写 Python 爽）。同时也感觉学习新东西的最好、最快的方法就是实战，换句话说，抱着解决问题的目的去学习所学到的知识远比你抱着单纯学习目的所学的知识要更快、更牢靠。"},{"title":"一台 VPS 的正确打开方式","subtitle":"","url":"/posts/b3085a7/","date":"2018-02-22T11:38:04.000Z","updated":"2018-04-02T06:26:04.000Z","category":"分享境","tags":["VPS","Nginx","API","SSH"],"content":"其实像 Hexo 这样的静态博客框架本不需要服务器的，GitHub Pages 就提供免费的托管服务、且不限流量，但内心那点不安分因素总是撩拨着我：比如可以自定防护规则、可以搭建私有 Git 服务、可以搭建自己的 API（这个比较重点）、还能自己搭建 SS 服务，于是乎就买了一台 VPS。<!--more-->\n\n由于我的博客使用了 [Cloudflare](https://www.cloudflare.com/) 作为 CDN 服务商，而国内的电信和联通用户是默认解析到 Cloudflare 的美西结点，只有移动用户是解析到香港节点，所以为了 API 的快取速度（即：本机 -> Cloudflare -> VPS -> Cloudflare -> 本机），将服务器选在了洛杉矶，每年 20$、1T 流量、10G 固态、512M 内存，搭建一个静态博客和几个 API 足够了。\n\n## 简化 SSH 登录\n\nSSH 的安全验证有两种级别：\n\n1. 基于密码：知道帐号和密码，就可以登录到远程主机，这种方式无法避免「中间人」攻击\n2. 基于密钥：创建一对密钥，并把公钥放至服务器，每次通信都会检验密钥，从而可以避免「中间人」攻击\n\n这里介绍第二种方法。\n\n### 生成密钥\n\n如果在使用 GitHub 的时候已经生成过，那么这一步可以略过\n\n```bash\nssh-keygen\t\t\t\t\t\t# 默认生成长度为 2048 位的 RSA 密钥\nssh-keygen -b 4096\t\t\t\t# 可以通过添加参数 -b 设定长度\n```\n\n随后就会生成一对密钥，默认为：id_rsa（私钥）、id_rsa.pub（公钥）\n\n### 上传至服务器\n\n使用 ssh-copy-id 命令\n\n```bash\nssh-copy-id username@server-addr\n```\n\n需要输入远程服务器的登录密码，随后 id_rsa.pub（公钥）会自动上传至服务器的 `~/.ssh/authorized_keys` 文件中\n\n随后再进行 SSH 连接时，就不需要再输入密码了\n\n### 简化 IP\n\n虽不用输入密码，但仍需要输入服务器登录名和 IP 地址，所以需要将配置写入 `~/.ssh/config` 中：\n\n```yaml\nHost wincer\t\t\t\t# 这里填写简化名称\n  HostName ××.××.××.××\t# 服务器 IP\n  Port 22\t\t\t\t# 端口号\n  User root\t\t\t\t# 远程登录用户名\n```\n\n随后再进行 SSH 连接时，输入 `ssh wincer` 就可以登录了\n\n`scp` 命令也可以简化成以下：\n\n```bash\nscp FILENAME wincer:PATH \n```\n\n## 作为 GitHub Pages\n\n目前我的博客仍然在[该仓库](https://github.com/WincerChan/MyBlog)的 master 分支上保留有静态文件，仅作备份。\n\n### 添加 DNS 记录\n\n首先为 DNS 解析添加一条 「A 记录」，记录值为 VPS 所分配的 IP\n\n![A 记录](https://res.cloudinary.com/wincer/image/upload/v1530857776/blog/vps_open_mode/a_record.png)\n\n### 更改 Nginx 配置\n\nSSH 登录后，编辑 Nginx 的配置文件 `vim /etc/nginx/nginx.conf`：\n\n```nginx\nserver {\n  listen\t\t80;\n  server_name\tblog.itswincer.com;\n  index \t\tindex.html;\n  root \t\t\t/data/www/hexo;\n}\n```\n\n可部署多个子域名，只需将 `server_name` 和 `root` 替换成相应的子域名和文件夹就可以了\n\n可以先创建一个 `index.html`  测试一下，访问 `blog.itswincer.com`  看看是否成功\n\n### 加密 CI 配置\n\n\n这一步可选，你也可以手动用 `scp` 命令将每次 `hexo g` 生成的静态文件上传至服务器，只不过略微麻烦。\n\nTravis CI 的终端并不能支持用户输入密码，而 GitHub 的 Token 又无法在自己的服务器使用，故而只能采取[简化 SSH 登录](#简化 SSH 登录)这步中类似的方法，即用私钥（即 id_rsa）去确认登录的身份，而将私钥公开至 GitHub 又是很危险的，所以我们需要将私钥加密：\n\n```bash\ngem install travis\t\t# 需要安装 gem，自备梯子\ntravis login\t\t\t# 输入 GitHub 的账户密码\ntravis encrypt-file ~/.ssh/id_rsa --add\t\t# 加密私钥，同时解密命令会添加至 travis.yml\n```\n\nTravis CI 上的 known_hosts 只添加了 GitHub 下的三个域名，在使用 SSH 登录时，会提示是否添加该主机，同样因为终端无法输入，所以需现将服务器的 IP 与端口号添加至 known_hosts：\n\n```yaml\naddons:\n  ssh_known_hosts: ××.××.××.××\n```\n\n> 这里忍不住吐槽一下 Travis CI 的加密：居然无法同时加密两个文件，而官方提供的方法是先把需要加密的文件压缩后加密，再解压。\n\n## 搭建 API\n\nHexo 这类静态博客所需的内存其实是挺少的，只需在后台运行一个 Nginx 进程就可以了，只运行一个 Nginx 进程时用「搬瓦工」的管理面板查看发现一共内存才使用了 40M，才用了不到 10%，所以就想着可以将之前写的「一言」API 放到我的服务器上，毕竟 Heroku 在国内访问还是挺不稳定的。\n\n之前是用 Python3 写的，后来发现 VPS 自带的 Python 版本居然是 2.7，深知其中坑的我就没打算再用 Python 了，于是就是用 Node.JS 写了一个，本地调试了一下，就扔到服务器上了。第二天早上起来一看，发现内存占用居然到了 110M，一查看原来都是 Node 的占用，其中每一个 API 请求，平均就会多占用 2M 的内存，而且这个请求所占用的内存并不会释放，这样下去怕是没两天服务器就要爆内存了。\n\n后来我也想过解决办法，比如用 PM2 这个工具来限制运行的内存，超过就重启 Node 环境，也想过定时重启服务器，再转念一想，我是大爷诶，凭啥要我去迁就辣鸡 Node.JS 的内存管理，你不行那我换一个具有垃圾回收的语言不就好了，那就 Java？好像也不太行，毕竟服务器就那么点硬盘，JDK 和 JRE 不知道要占用我多少空间，再者说来毕竟我可是 「Java 黑」。\n\n那么就归纳一下我的需求：「占用内存小、部署方便、有垃圾回收（不会爆内存）、~~不要 Java~~」，然后考虑到编译型程序比解释型程序占用的内存更小，所以也就没考虑 Ruby & Python，满足这些要求的好像也只有 Golang 了。\n\n写了那么久的动态类型语言，突然要我写静态类型语言还真是有点不适应。在网上找了个例子，自己捣鼓了一个下午，就写出来了，算是一个勉强遵循「RESTful」风格的 API，开始还有日志功能，后来想想没必要，Nginx 也可以监控端口的访问日志，就删去了。\n\n然后在 Nginx 配置端口\n\n```nginx\nserver {\n  listen\t\t80;\n  server_name\tapi.itswincer.com;\n  location / {\n    add_header Content-Type 'application/javascript';\n    proxy_pass http://localhost:520;\n  }\n}\n```\n\n而且 Golang 的部署也是很方便，将 *.go 拷贝就行了。跑了几天，内存占用稳定在 10M 上下。\n\n[该项目](https://github.com/WincerChan/hitokoto)已托管至 GitHub。\n\n## 搭建 SS\n\n搬瓦工的 SS/SSR 搭建可以说是非常的方便了：\n\n1. 先进入 KiwiVM 面板\n2. 在左侧点击 `Shadowsocks Server` 按钮\n3. 再点击 `install Shadowsocks Server` 按钮\n\n大约半分钟后，会提示已经安装完成：\n\n![安装](https://res.cloudinary.com/wincer/image/upload/v1530857869/blog/vps_open_mode/ss_install.png)\n\n再点击 `Go back` 按钮，回到以下界面，再点击 `Start`：![配置](https://res.cloudinary.com/wincer/image/upload/v1530857945/blog/vps_open_mode/ss_sample.png)\n\nSS 服务配置完成了，将以上信息填入 SS 客户端即可使用。\n\n不过由于服务器是在美西，所以无论怎么优化（BBR），延迟都会在 160ms 以上，当然这对浏览网页看视频来说也没有什么影响。\n\n> 注意：**当你使用 VPS 翻墙时，会同时计算上行、下行流量，也就是说如果翻墙使用 1G 流量，其实等于使用了 VPS 的 2G 流量**。\n\n## 搭建私有云笔记\n\n我最近有在思考私有云笔记的必要性，毕竟有了博客，那云笔记的作用可能就鸡肋了一点。但我还是选择了搭建。我的想法是：博客用于存放、发布一些较正式的文章，而笔记可以休闲一点（类似作文和日记的区别）。\n\n回到正题，目前来说，体验好的云笔记要么需要会员、要么存在诸多功能限制，而我又不想多浪费钱，那么选择一个支持多设备（其实主要是解决手机设备）的同步方案并借助私有的服务器架设自然也就是最好的解决办法了。我选择了 [Nextcloud 作为解决方案](../bf0413ac/)，并借助他的 WebDAV 功能作为多端同步工具。\n\n手机端笔记软件选择的是[易码](https://www.coolapk.com/apk/me.tshine.easymark)，支持 Markdown 语法和 WebDAV 同步，电脑端可以选择直接用浏览器访问 Nextcloud，可以在线 Markdown 编辑和预览，当然也可以选择用 Nextcloud 同步至本地文件夹，并用其它编辑器打开就可以了。"},{"title":"《黑客与画家》读书笔记","subtitle":"","url":"/posts/a6c2a51d/","date":"2018-01-26T09:11:29.000Z","updated":"2018-01-31T12:02:59.000Z","category":"文字阁","tags":["笔记","黑客与画家"],"content":"去年年底那会，花了大概一周多时间，阅读完了《黑客与画家》这本书，收获颇丰。可惜当时确实没多少时间整理出读书笔记，期末考试结束后，回到家中，本想着有时间能好好补一下博客，结果回家之后也没有想象中的空闲，看着「搬瓦工」把每年 20$ 的套餐补货了，于是就购置了一台服务器，将博客源码从 GitHub 上转移到了自己的服务器上，还拿 Golang 重写了一下「一言」的 API（扯远了，服务器的事等以后再开一篇博客说说），还补了一部早已加入想看列表却一直没看的番——「反叛的鲁路修」（嘻嘻 😌）。\n\n直到今天，才终于有时间能把这篇读书笔记给整理出来了，笔记是直接在 Kindle 上标注的，然后用「[Clippings.io](https://www.clippings.io/)」这个工具导出（为什么 Kindle 不能开发一个好用一点的笔记管理系统呢！？）。\n\n好在 azw3 版本在 Kindle 上的体验还不错，即使有代码段排版也没有垮掉，所以决定原谅你。\n\n（👇以下为文摘）\n\n---\n\n1. 在一个人产生良知之前，折磨就是一种娱乐。\n\n2. 程序写出来是给人看的，附带能在机器上运行。（这句话的出处是在《SICP》这本书的卷首语，作者引用了）\n\n3. 如果有必要的话，大多数物理学家有能力拿到法国文学的博士学位，但是反过来就不行，很少存在法国文学的教授有能力拿到物理学的博士学位。\n\n4. 人们喜欢讨论的许多问题实际上都是很复杂的，马上说出你的想法对你并没有什么好处。\n\n5. 小时候，每个人都会鼓励你不断成长，变成一个心智成熟、不再耍小孩子脾气的人。但是，很少有人鼓励你继续成长，变成一个怀疑和抵制社会错误潮流的人。\n   如果自己就是潮水的一部分，怎么能看见潮流的方向呢？你只能永远保持质疑。\n\n6. 不服从管教，其实是黑客之所以成为优秀程序员的原因之一。\n\n7. 公民自由并不仅仅是社会制度的装饰品，或者一种很古老的传统。公民自由使得国家富强。\n\n8. 经济学里有一条拉弗曲线（Laffer curve），认为随着税率的上升，税收收入会先增加后减少。我认为政府的力量也是如此，随着对公民自由的限制不断上升，政府的力量会先增加后减小。\n\n9. 极权主义制度只要形成了，就很难废除。（咳咳）\n\n10. 一定数量的盗版对软件公司是有好处的。不管你的软件定价多少，有些用户永远都不会购买。如果这样的用户使用盗版，你并没有任何损失。事实上，你反而赚到了，因为你的软件现在多了一个用户，市场影响力就更大了一些，而这个用户可能毕业以后就会出钱购买你的软件。\n\n11. 首先，管理企业其实很简单，只要记住两点就可以了：做出用户喜欢的产品，保证开支小于收入。\n\n12. 一个大学毕业生总是想「我需要一份工作」，别人也是这么对他说的，好像变成某个组织的成员是一件多么重要的事情。更直接的表达方式应该是「你需要去做一些人们需要的东西」。即使不加入公司，你也能做到。公司不过是一群人在一起工作，共同做出某种人们需要的东西。真正重要的是做出人们需要的东西，而不是加入某个公司。\n\n13. 要鼓励大家去创业。只要懂得藏富于民，国家就会变得强大。让书呆子保住他们的血汗钱，你就会无敌于天下。\n\n14. 财富是用工作成果衡量的，而不是用它花费的成本衡量的。如果我用牙刷油漆房屋，屋主也不会付给我额外工资的。\n\n15. 好设计是艰苦的设计。如果观察那些做出伟大作品的人，你会发现他们的共同点就是工作得非常艰苦。如果你工作得不艰苦，你可能正在浪费时间。\n\n16. 并非所有的痛苦都是有益的。世界上有有益的痛苦，也有无益的痛苦。你需要的是咬牙向前沖刺的痛苦，而不是脚被钉子扎破的痛苦。解决难题的痛苦对设计师有好处，但是对付挑剔的客户的痛苦或者对付质量低劣的建材的痛苦就是另外一回事了。\n\n17. 等到你逐渐对一件事产生热情的时候，就不会满足于模仿了。\n\n18. 「你用什么语言并不重要，重要的是你对问题是否有正确的理解。代码以外的东西才是关键。」这当然是一派胡言。各种语言简直是天差地别。\n\n19. 语言设计者之间的最大分歧也许就在于，有些人认为编程语言应该防止程序员干蠢事，另一些人则认为程序员应该可以用编程语言干一切他们想干的事。\n\n20. 允许你做某事的语言肯定不差于强迫你做某事的语言。\n\n21. 它们（指某些语言）的内核设计得并非很好，但是却有着无数强大的函数库，可以用来解决特定的问题。（你可以想象一辆本身性能很差的小汽车，车顶却绑着一个飞机发动机。）有一些很琐碎、很普遍的问题，程序员本来要花大量时间来解决，但是有了这些函数库以后，解决起来就变得很容易，所以这些库本身可能比核心的语言还要重要。所以，这些奇特组合的语言还是蛮有用的，一时间变得相当流行。车顶上绑着飞机发动机的小车也许真能开，只要你不尝试拐弯，可能就不会出问题。（内心 OS：我可没有针对 C++ 😏）\n\n22. 当我说 Java 不会成功时，我的意思是它和 Cobol 一样，进化之路已经走到了尽头。\n\n23. 如果摩尔定律依然成立，一百年后计算机的运行速度将是现在的 74 乘以 10 的 18 次方倍（准确地说是 73 786 976 294 838 206 464 倍）。\n\n24. 即使最后只是略微快了 100 万倍，也将实质性地改变编程的基本规则。如果其他条件不变，现在被认为运行速度慢的语言（即运行的效率不高）将来会有更大的发展空间。\n\n25. 效率低下的软件并不等于很烂的软件。一种让程序员做无用功的语言才真正称得上很烂。\n\n26. 自下而上的编程方法意味着要把软件分成好几层，每一层都可以充当它上面那一层的开发语言。这种方法往往会产生更小、更灵活的程序。它也是通往软件圣杯——可重用性（reusability）——的最佳路线。\n\n27. 罗伯特·莫里斯和我都很了解 Lisp 语言，我们相信自己的直觉，找不出任何不使用它的理由。我们知道其他人都用 C++ 或 Perl 开发软件，但是我们不觉得这说明了什么问题。如果别人用什么技术，你也用什么技术，那么你大概只能使用 Windows 了（日常黑 Windows）。\n\n28. 编程语言的特点之一就是它会使得大多数使用它的人满足于现状，不想改用其他语言。\n\n29. 如果从图灵等价（Turing-equivalent）的角度来看，所有语言都是一样强大的，但是这对程序员没有意义。\n\n30. 最不用担心的竞争对手就是那些要求应聘者具有 Oracle 数据库经验的公司，你永远不必担心他们。如果是招聘 C++ 或 Java 程序员的公司，对你也不会构成威胁。如果他们招聘 Perl 或 Python 程序员，就稍微有点威胁了。至少这听起来像一家技术公司，并且由黑客控制。如果我有幸见到一家招聘 Lisp 黑客的公司，就会真的感到如临大敌。\n\n31. 你的经理其实不关心公司是否真的能获得成功，他真正关心的是不承担决策失败的责任。\n\n32. 黑客欣赏的一个特点就是简洁。黑客都是懒人，他们同数学家和现代主义建筑师一样，痛恨任何冗余的东西或事情。\n\n33. 简洁性是静态类型语言的力所不及之处。只要计算机可以自己推断出来的事情，都应该让计算机自己去推断。举例来说，hello-world 本应该是一个很简单的程序，但是在 Java 语言中却要写上一大堆东西，这本身就差不多可以说明 Java 语言设计得有问题了。\n\n    ```java\n    public class Hello {\n      public static void main(String[] args) {\n        System.out.println(\"Hello, world!\");\n      }\n    }\n    ```\n\n    如果你从来没没有接触过编程，看到上面的代码可能会很奇怪，让计算机显示一句话为什么要搞得这么复杂？有意思的是，资深程序员的反应与你一样。\n\n34. 语言设计者应该假定他们的目标用户是一个天才，会做出各种他们无法预知的举动，而不是假定目标用户是一个笨手笨脚的傻瓜，需要别人的保护才不会伤到自己。如果用户真的是傻瓜，不管你怎么保护他，他还是会搬起石头砸自己的脚。\n\n35. 对黑客来说，选择编程语言的时候，还有一个因素比简洁更重要，那就是这种语言必须能够帮助自己做到想做的事。\n\n（👇以下为简评）\n\n---\n\n这本书算是我从去年 7 月以来看完的第一本书了（《计算机程序的构造和解释》这本书太难了，看了前两章就没时间看，到还书的日期了），主要也在于作者 Paul Graham 的行文十分流畅，阮一峰的翻译也很到位，没有什么阅读障碍，还有「读至好几处都有一拍大腿，哎呀妈呀我也是这么想的啊」的想法，读完之后，思想也似乎豁然开朗了些。\n\n关于第六章——「如何创造财富」，财富的获得是看你最终的结果，不是看你的付出（过程）。你做出了别人需要的产品，没人在乎你是做了三天还是三十天，他并不会因为你只做了三天就完成而少付给你报酬，更不会因为你是三十天完成而多给你报酬。还有关于「财富并不是固定不变的」这个理论，他给出了一个例子：你拥有一辆老爷车，你可以不去管它，也可以自己动手把它修葺一新这样的话，你就创造了财富：世界上因此多了一辆新的车，财富就变得多了一点，如果你把车卖掉，你得到的卖车款就会比以前更多，与此同时，你并没有使任何人变得更贫穷。正因为这个理由，他也建议我们多多创业，但也给我们泼了一盆「凉水」：创业的付出与回报总体上是成比例的，但是在个体上是不成比例的，不要把创业过于神话，但创业的确给了我们更多的可能。\n\n还有就是关于编程语言的争论，作者似乎和我一样很喜欢黑 Java，认为 Java 是「进化之路已经走到了尽头」，因为编程语言并不应该限制程序员去做某些事情，即使这些事情是有害的。同时也抛出了另一个很新颖的说法：关于一百年以后，我们该使用什么样的编程语言？按照摩尔定律：预计 18 个月会将芯片的性能提高一倍，那时候电脑的运行速度将是现在的 73 786 976 294 838 206 464 倍，所以他认为现在某些因为运行速度略慢但编程起来更舒服的语言在未来反而是主流，即有更大的发展空间，同时作者似乎很推崇动态类型语言，因为写起来比静态类型语言方便、看起来也比较简洁。作者也不止一次的推崇了 Lisp，甚至不惜黑 Oracle 数据库、C++、Java（见上面第 30 条）。\n\n最后，这本书算是 Paul Graham 的一本随笔文集，其中自然充斥着许多作者的价值观，如果这些价值观与你的价值观符合，那么你就会像「捡到宝」一样的对待这本书，反之，你会认为这本书的观点完全是和「邪教信条」一般，很庆幸，我是前者。\n\n---\n\n处于马上步入社会的我啊，在迷茫的时候，不妨也多阅读几本好书。"},{"title":"豆瓣电影 Top 250 数据分析","subtitle":"","url":"/posts/7a8186a0/","date":"2018-01-21T02:24:29.000Z","updated":"2017-12-24T12:27:29.000Z","category":"分享境","tags":["豆瓣","电影","数据"],"content":"## 前言\n\n前段时间忙于备考，博客有段时间没更新了。其实早就有写这篇博客的想法了，原因嘛——我是比较喜欢看电影的，而且近来也对数据分析颇感兴趣，于是花了一天时间，先是爬取数据，再分析整理，数据可视化。\n<!--more-->\n\n其实豆瓣对爬虫的防范算是比较高级了，即使伪造了 Cookie，还是会封禁 IP（还好我的代理 IP 多😏），甚至还会把你的帐号暂时冻结，其实要不是有一些电影词条必须登录才可见，也不用伪造 Cookie 这么麻烦。\n\n## 爬取\n\n之前爬取都是用的正则匹配，这次首次接触了「[Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html)」这个库，相见恨晚啊，不多说，先上代码：\n\n```python\ndef get_info(url):\n    movie = {}\n    proxies = {'https': \"socks5://127.0.0.1:1080\"}\n    info = get(url, cookies=read_cookie(), proxies=proxies).text\n    soup = BeautifulSoup(info)\n    try:\n        # get movie name\n        name = soup.find(property='v:itemreviewed').get_text()\n        movie['name'] = name.split(' ')[0]\n\n        # get movie year\n        year = soup.find(class_='year').get_text()\n        movie['year'] = year[1:-1]\n\n        # get movie info\n        info = soup.find(id='info').get_text().replace(' ', '').split('\\n')\n        info = [x for x in info if x is not '']\n        for item in info:\n            if '导演:' in item:\n                movie['director'] = item[3:].split('/')\n            if '主演:' in item:\n                movie['actors'] = item[3:].split('/')\n            if '类型:' in item:\n                movie['type'] = item[3:].split('/')\n            if '国家/地区:' in item:\n                movie['region'] = item[8:].split('/')\n            if '语言:' in item:\n                movie['language'] = item[3:].split('/')\n            if '片长:' in item:\n                time = [\n                    search(r'[\\d]*', x).group() for x in item[3:].split('/')\n                ]\n                movie['time'] = sorted(time, reverse=True)[0]\n\n        # get top250 info\n        movie['rank'] = soup.find(class_='top250-no').get_text()\n\n        movie['number'] = soup.find(property='v:votes').get_text()\n\n    except Exception as e:\n        print(e)\n    return movie\n```\n\n其中片长取得是无删减版的片长，即不同版本中最长的。\n\n地区、导演、语言等由于会出现多项内容，采取列表存放。\n\n**以下统计数据截止至 2018/01/20**\n\n## 导演\n\n![电影导演统计](https://res.cloudinary.com/wincer/image/upload/v1530858719/blog/douban_movie_analytics/director.png)\n\n其中由「宫崎骏」和「克里斯托弗·诺兰」贡献最多，均为 7 部，具体为：\n\n宫崎骏（日本）：\n\n- 《千与千寻》，上映年份为「2001」，排名为 No.6\n- 《龙猫》，上映年份为「1988」，排名为 No.17\n- 《天空之城》，上映年份为「1986」，排名为 No.33\n- 《哈尔的移动城堡》，上映年份为「2004」，排名为 No.45\n- 《幽灵公主》，上映年份为「1997」，排名为 No.80\n- 《风之谷》，上映年份为「1984」，排名为 No.106\n- 《魔女宅急便》，上映年份为「1989」，排名为 No.189\n\n克里斯托弗·诺兰（英国）：\n\n- 《盗梦空间》，上映年份为「2010」，排名为 No.9\n- 《星际穿越》，上映年份为「2014」，排名为 No.25\n- 《蝙蝠侠：黑暗骑士》，上映年份为「2008」，排名为 No.32\n- 《致命魔术》，上映年份为「2006」，排名为 No.61\n- 《记忆碎片》，上映年份为「2000」，排名为 No.132\n- 《蝙蝠侠：黑暗骑士崛起》，上映年份为「2012」，排名为 No.168\n- 《追随》，上映年份为「1998」，排名为 No.170\n\n## 演员\n\n![电影演员统计](https://res.cloudinary.com/wincer/image/upload/v1530858744/blog/douban_movie_analytics/actor.png)\n\n其中由「张国荣」贡献最多（前三居然都是香港地区的演员），有 8 部，分别是：\n\n- 《霸王别姬》，导演为「陈凯歌」，上映年份为「1993」，排名为 No.2\n- 《春光乍泄》，导演为「王家卫」，上映年份为「1997」，排名为 No.77\n- 《射雕英雄传之东成西就》，导演为「刘镇伟」，上映年份为「1993」，排名为 No.88\n- 《倩女幽魂》，导演为「程小东」，上映年份为「1987」，排名为 No.113\n- 《东邪西毒》，导演为「王家卫」，上映年份为「1994」，排名为 No.131\n- 《英雄本色》，导演为「吴宇森」，上映年份为「1986」，排名为 No.140\n- 《纵横四海》，导演为「吴宇森」，上映年份为「1991」，排名为 No.149\n- 《阿飞正传》，导演为「王家卫」，上映年份为「1990」，排名为 No.183\n\n## 地区\n\n![电影地区统计](https://res.cloudinary.com/wincer/image/upload/v1530858784/blog/douban_movie_analytics/region.png)\n\n其中「美国」地区一枝独秀，超过半数以上电影的制片地区均为「美国」，且远超第二名「英国」。\n\n- 美国：140 部\n- 英国：34 部\n- 日本：32 部\n- 香港：26 部\n- 法国：26 部\n- 德国：20 部\n- 中国大陆：16 部\n\n## 片长\n\n![电影片长](https://res.cloudinary.com/wincer/image/upload/v1530858819/blog/douban_movie_analytics/length.png)\n\n| 统计名称 | 数值         |\n| ---- | ---------- |\n| 中位数  | 118.0      |\n| 均值   | 124.0      |\n| 众数   | 98.0（10 次） |\n| 标准差  | 34.1       |\n| 极差   | 218.0      |\n\n其中片长最长的电影为《指环王3：王者无敌》，导演是「彼得·杰克逊」，片长为 263 mins，排名是 No.30。\n\n其中片长最短的电影为《萤火之森》，导演是「大森贵弘」，片长为 45 mins，排名是 No.150。\n\n## 年份\n\n![电影年份](https://res.cloudinary.com/wincer/image/upload/v1530858844/blog/douban_movie_analytics/years.png)\n\n| 统计名称 | 数值         |\n| ---- | ---------- |\n| 中位数  | 2002.0     |\n| 均值   | 1998.6     |\n| 众数   | 2004（13 次） |\n| 标准差  | 15.6       |\n| 极差   | 85         |\n\n其中距今最久远的电影是《城市之光》，导演是「查理·卓别林」，年份为 1931 年，排名是 No.210。\n\n其中距今最接近的电影有 5 部，均为 2016 年上映：\n\n- 《疯狂动物城》，导演是「拜伦·霍华德」等，制片国家为「美国」，排名为 No.43\n- 《看不见的客人》，导演是「奥里奥尔·保罗」，制片国家为「西班牙」，排名为 No.83\n- 《摔跤吧！爸爸》，导演是「涅提·蒂瓦里」，制片国家为「印度」，排名为 No.104\n- 《海边的曼彻斯特》，导演是「肯尼思·洛纳根」，制片国家为「美国」，排名为 No.151\n- 《你的名字。》，导演是「新海诚」，制片国家为「日本」，排名为 No.245\n\n嘿嘿，没想到吧，贡献电影最多的年份并不是「Top 250」前四名中有三部的 1994 年，而是 2004 年。\n\n\n## 评分\n\n![电影评分统计](https://res.cloudinary.com/wincer/image/upload/v1530858864/blog/douban_movie_analytics/grade.png)\n\n| 统计名称 | 数值        |\n| ---- | --------- |\n| 中位数  | 8.70      |\n| 均值   | 8.78      |\n| 众数   | 8.7（44 次） |\n| 标准差  | 0.27      |\n| 极差   | 1.40      |\n\n其中最高分为 9.6 分，为两部电影所获得：\n\n- 《肖申克的救赎》，导演为「弗兰克·德拉邦特」，评分人数为 952814 人，排名为 No.1\n- 《控方证人》，导演为「比利·怀尔德」，评分人数为 99908 人，排名为 No.41\n\n其中评分最低的电影为《疯狂的石头》，分数是 8.2 分，导演为「宁浩」，评分人数为 312083 人，排名为 No.230\n\n可以看出豆瓣在进行「Top 250」排名时，并不是仅看评分，其中评分人数也占了很大的一部分比重，且似乎还有一些其它的因素，比如《血战钢锯岭》这部电影，评分 8.7，评分人数为 310624 人，却并没有上榜，同为评分 8.7，评分人数为 314940 的电影《看不见的客人》排名却早已进前百（No.83）。\n\n最后，本人并非专业电影人士，无法针对以上数据提出建设性的建议，所做统计也仅仅是出于爱好，也愿自己能在闲暇时间里，多看几部电影。"},{"title":"再见，2017","subtitle":"","url":"/posts/5873b0c0/","date":"2017-12-29T02:46:06.000Z","updated":"2018-01-21T03:34:38.000Z","category":"碎碎念","tags":["2017","随笔"],"content":"关于 2017 年，其实还真的有挺多想说的，也早就有想写一篇博客的想法了，差不多到今天才抽得出时间写。\n\n前几天和朋友聊天时谈到关于今年最有成就感的一件事，我想了一会，应该是搭建了这样一个博客。<!--more-->\n当初搭建博客的初衷其实很单纯：就是为了好玩，谁知从此就沉迷于此了。在之后的写博客的过程中甚至产生了一种当一个作家也还不错的想法（当然前提是我的文章还有人看😋），现在想想，与高中时期相比，我的想法是发生了一些转变（在高中时期的我是绝不可能产生这种想法的）。正如开始所说的，现在遇到点什么事就想写下来，在往年，我一直没有写年末总结的习惯。这种「创作欲」，类似作家：将自己内心的想法写成作品，实则是把自己的内心剖析给别人看。也渐渐有些明白卡尔·雅斯贝尔斯的那句「文学和科学相比，的确没什么用处，但文学最大的用处，也许就是它没有用处」的意思了。\n\n---\n\n买了 kpw3 后，我很乐意培养自己的阅读习惯。大学时间其实还是比较宽松的，但我反而不能每天抽出一小时阅读时间。有时候看书没看两分钟，随便手机一个通知消息就能让我转移注意力——这也是我的缺点：当自己没有全神贯注的时候，很容易被其它的事情所吸引注意力（这也算我很迫切想改掉的一个坏习惯），也导致看了近两周才把《黑客与画家》这本书看完（书推过两天会补上）。\n\n是太浮躁了，也太焦虑了，或许是因为到了大三，面临找工作的压力，这压力不仅体现在看书上，有时我就莫名想快些完成正在做的事情，后来多次发现快速完成的事情必然是敷衍的，而事后一旦想起这件「敷衍」的事情，会更加浮躁。其实这样并不好，道理古人都说给我们听了：「欲速则不达」，以后我会尽量放慢自己做事情的速度，投入自己的内心，问问自己真正想要的是什么。\n\n---\n\n今年有过一段恋情，对我产生了一些影响，有好，也有坏，让我成长了许多，也意识到了自己的不足。是的，一段感情之后一定会让你成长的。我在这个过程中有开心、难过、有挂念一个人，甚至有些「病态」的想法——不论好坏，这些特殊的情感都是之前没有体会过的。\n\n恋爱的时候，双方的关系一定需要去协商、磨合，这也会让你学会更好的与人沟通，同时你会发现有些问题如果脱离恋爱范围的话根本就不是问题。在一段恋情过后，我们获得的不仅仅是恋情，还有更好的、获得了成长的自己。你会更了解自己，也更了解你需要找一个什么样的人。\n\n要有自己的生活，要坚持做自己。要学会去爱，但要先学会爱自己。\n\n---\n\n接下来说说工作。\n\n其实我很反感工作——即学校安排给你作为学生所必须学习的课程，所以这学期的课我基本没怎么去，因为去了我也不会听：我无法强迫自己去听那些完全没有兴趣的课程，那有点像是别人强迫要你去做的事情，我天生是一个「猫型人格」（即：你让我向左转，我会不由自主的向右转，同时心里还有一点歉疚），所以有些不由自主地抗拒。\n\n在[之前写的那篇文章](../11ab0263/)中就说到，我想更加追随自己内心的意愿去活着。具体到工作的说法就是：我想开始「不以找到工作为目的的学习」，学习自然指的是编程。\n\n> 编程这么有趣的事，竟然还有钱赚      ——by c++ 之父\n\n我喜欢编程，我愿意将自己的时间花费在上面做一些有趣的小程序，即使这在旁人看来对以后的工作没有什么帮助，我不想抱着太强的目的性、太多的功利心去学习，因为这样，会让学习变味。同时我也乐于看着指尖下的一串串字符到显示器上显示出成果，会有一种小小的满足感。\n\n---\n\n最后，小小说一下对 2018 年的展望（这绝对不是 FLAG！）\n\n- 希望继续读书的习惯\n- 希望做事情的时候更专注\n- 希望能多吃水果、生活作息规律\n- 希望学会使用 To-Do list（如果能有效治愈我的拖延症的话）"},{"title":"从 GnuPG 的使用谈谈密码学","subtitle":"","url":"/posts/4aa5d46d/","date":"2017-12-11T01:26:16.000Z","updated":"2017-12-24T11:35:22.000Z","category":"分享境","tags":["GPG","密码学","安全"],"content":"## 前言\n\n我是一个很注重隐私的人，所以对密码学也就很感兴趣，这学期本着想进一步了解密码学的念头选了一门应用密码学的选修课（其实是为了混学分），虽说也没去过几次，但总想着这门课都快结束了总不能像没上过一样。这次借着 GnuPG（以下简称 GPG） 软件的使用也聊聊目前现代密码学中以密钥性质进行区分的两大加密方式。\n\n<!--more-->\n\n## 对称密钥加密\n大概半年前，写过一个暴力破解加密压缩文件的程序，说白了就是跑字典，不断的试密码，这只能破解常用密码，一旦用户采用随机生成的密码就无从下手。我们平时所用到的压缩加密大多都是对称性加密，即我们用同一字符串对文件进行加密，又用同一字符串进行解密（此时为了保证安全，密码需越复杂越好）。\n\n> 明文 <--\\> 密钥 <--\\> 密文\n\n对称加密很方便也很快速，但是也带来了一个很大的缺点，由于加密和解密用的都是同一密钥，在传输的过程中，要求双方取得相同的密钥，这会大大降低加密的安全性（注意：这里所说的不安全不是说对称加密算法不安全，而是从密钥的获取程度来说的，即密钥知道的人越少越安全）。\n\n在如今的互联网时代，通信双方分隔异地且素为谋面，则对称加密要求事先交换共同密钥的安全性也无法得到保障。\n\n## 公开密钥加密\n那么为了解决对称加密的安全隐患，非对称加密诞生了。\n与对称加密不同的是，非对称加密的加密和解密所需要的密钥是不同的，而且知道了其中一方，想推导出另一方（需要解决一个数学难题），在量子计算机时代来临之前，基本是不可能完成的。\n因此公开其中一个密钥，并不会对密钥对的安全性有影响。\n我们常说，公钥可以公开，私钥需要保密，但其实公钥和私钥在生成过程上，并无什么不同。并不是因为公钥公开后，解密出私钥困难，如果公开的是私钥，解密出公钥也同样困难。也就是说我们将一对密钥公开的那部分叫公钥，另一部分叫做私钥。并不是因为公钥，才能公开，私钥，就必须保密。\n\n> 明文 <--\\> 公钥 <--\\> 密文 <--\\> 私钥 <--\\> 明文\n\n前一段时间很火的勒索病毒就是采用的非对称加密中的 RSA-4096 加密算法。\n想具体了解 RSA 加密原理的话，[点击这里](http://www.ruanyifeng.com/blog/2013/06/rsa_algorithm_part_one.html)。\n由于公钥加密在计算上相当复杂，导致其加密速度相对于对称加密来说慢。\n\n### 数字签名\n\n其中对称加密还有一个用处：数字签名。\n对称加密的公钥和私钥在使用顺序上并没有什么要求，你可以用公钥加密，私钥解密，这就是非对称加密算法，同样可以用私钥加密，公钥解密，而这就成为数字签名。\n由于私钥是发送者保存的，发送者用私钥加密后的信息，任何拥有该发送者的公钥的人都可以解密该信息。如果接收用发送者公开的公钥解开了，那么说明这个信息是确实是发送者发送的（没有被篡改，也不是伪造的）。公众也可以信赖这条信息确实来自与该用户，用户无法否认。\n\n一般来说，不直接对消息进行签名，而是对消息的哈希值进行签名，并将签名附赠在消息一起发送。\n\n总结一下二者的优点与缺点：\n\n- 对称密钥加密（使用最广泛的 AES）：加解密速度很快，强度也足够，但问题在于寻找一个安全通道让通信双方交换密钥很困难\n- 公开密钥加密（使用最广泛的 RSA）：加解密速度很慢，但可以解决通信双方安全通道的问题\n\n故现在多将二者结合使用：需要加密的主体内容使用对称加密，对称加密的密钥使用非对称加密。\n\n## GPG 教程\n下面说说如何使用 GPG 软件加密文件。\n\nGPG 支持的算法有很多：\n\n> 公钥：RSA, ELG, DSA, ECDH, ECDSA, EDDSA\n>\n> 对称加密：IDEA, 3DES, CAST5, BLOWFISH, AES, AES192, AES256,\n>\n> ​     TWOFISH, CAMELLIA128, CAMELLIA192, CAMELLIA256\n>\n> 散列：SHA1, RIPEMD160, SHA256, SHA384, SHA512, SHA224\n>\n> 压缩：不压缩，ZIP，ZLIB，BZIP2\n\n### 对称加密\n\n使用对称加密很简单，只需要一行就可以：\n\n```bash\ngpg --cipher-algo [对称加密算法名称] -c FILENAME\n```\n\n随后会让你输入两次密码，就会生成一个 FILENAME.gpg 的文件在同目录下。\n\n解密：\n\n```bash\ngpg -o FILENAME -d FILENAME.gpg\n```\n\n更多参数请输入 `gpg -h` 自行查阅。\n\n### 非对称加密\n\n#### 生成密钥\n\n（这里如果输入的是 `--gen-key` 的话，会省去一些步骤：自动设置密钥尺寸为 2048 位、有效期限为 2 年、注释留空）：\n\n```bash\ngpg --full-generate-key\n```\n\n回车后，出现以下文字：\n\n```bash\ngpg (GnuPG) 2.2.3; Copyright (C) 2017 Free Software Foundation, Inc.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\n请选择您要使用的密钥种类：\n   (1) RSA and RSA (default)\n   (2) DSA and Elgamal\n   (3) DSA (仅用于签名)\n   (4) RSA (仅用于签名)\n您的选择？ \n```\n\n选择 1：\n\n```bash\nRSA 密钥长度应在 1024 位与 4096 位之间。\n您想要用多大的密钥尺寸？(2048)\n```\n\n选择 4096：\n\n```bash\n请设定这把密钥的有效期限。\n         0 = 密钥永不过期\n      <n>  = 密钥在 n 天后过期\n      <n>w = 密钥在 n 周后过期\n      <n>m = 密钥在 n 月后过期\n      <n>y = 密钥在 n 年后过期\n密钥的有效期限是？(0) \n```\n\n如果想设置 5 年过期，输入 5y，我这里是自己私人用，选择 0，随后会让你确认以上信息正确与否，输入 y，系统会要求你提供一下个人信息：\n\n```bash\nYou need a user ID to identify your key; the software constructs the user ID\nfrom the Real Name, Comment and Email Address in this form:\n    \"Heinrich Heine (Der Dichter) <heinrichh#duesseldorf.de>\"\n\n真实姓名：\n电子邮件地址：\n注释：\n```\n\n注释这一栏可以留空。\n\n随后：\n\n```bash\n您选定了这个用户标识：\n    \"×××××× <××@×××.com>\"\n\n更改姓名(N)、注释(C)、电子邮件地址(E)或确定(O)/退出(Q)？\n```\n\n输入 o，会弹框提示设置一个密码，用于保护私钥。\n\n与此同时，系统也会提示：\n\n```bash\n我们需要生成大量的随机字节。这个时候您可以多做些琐事(像是敲打键盘、移动\n鼠标、读写硬盘之类的)，这会让随机数字发生器有更好的机会获得足够的熵数。\n```\n\n几秒后，系统就会提示密钥已经生成。\n\n#### 导出密钥\n\n显示系统的私钥：\n\n```bash\ngpg -K\n```\n\n显示系统的公钥：\n\n```bash\ngpg -k\n```\n\n删除密钥：\n\n```bash\ngpg --delete-keys [uid]\ngpg --delete-secret-keys [uid]\n```\n\n其中 uid 可以使用邮箱代替，下同。\n\n导出公钥：\n\n```bash\ngpg -o public.key --export [uid]\n```\n\n导出私钥：\n\n```bash\ngpg -o private.key --export-secret-keys\n```\n\n这样导出的 key 文件是二进制，不可读，加上 --armor 参数可以保存为 ASCII 码形式。\n\n导入密钥：\n\n```bash\ngpg --import [key 文件]\n```\n\n#### 加密\n\n```bash\ngpg -r [uid] -o FILENAME.gpg -e FILENAME\n```\n\n-r 指定用户的公钥，如自己使用改为自己邮箱即可，-o 指定加密后输出文件名称。\n\n#### 解密\n\n```bash\ngpg -o FILENAME -d FILENAME.gpg\n```\n\n会让你输入密码，即用于保护私钥的密码。\n\n参考：\n\n- [公开密钥加密](https://zh.wikipedia.org/wiki/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86)\n- [GPG 入门教程](http://www.ruanyifeng.com/blog/2013/07/gpg.html)"},{"title":"Web 性能优化（一）——使用 localStorage","subtitle":"","url":"/posts/a9d193c6/","date":"2017-11-30T07:09:34.000Z","updated":"2018-09-04T11:39:24.000Z","category":"实验室","tags":["优化","localStorage","Web"],"content":"## localStorage 的意义\n\n为了针对我的网站提供更好的浏览体验（或者说更接近原生 App 的用户体验），在之前我就已经[开启了 Service Worker 技术](https://itswincer.com/posts/a0df572f/)，针对离线或者网速慢的情况下改善用户体验。但只有少数几个浏览器支持 （Chrome、Firefox、Opera），对目前手机端用户数最多的 QQ 浏览器、UC 浏览器却没有支持，也就是说该方法针对 QQ 浏览器和 UC 浏览器并没有什么实际优化。\n\n<!--more-->\n\n而且对于 Service Worker，它并不能减少你的 HTTP 连接数量，只是拦截你的请求，减少 Stalled、Request sent 和 TTFB 的时间，见下图：\n\n![左边从 SW 加载，右边正常加载](https://res.cloudinary.com/wincer/image/upload/v1530845454/blog/web_optimization1/contrast.png \"左边从 SW 加载，右边正常加载\")\n\n针对以上两个问题，本博客采用另一种 HTML5 新技术 —— localStorage。\n\n## localStorage 简介\n\nlocalStorage 是在 HTML5 中新引进的一项存储技术，（如果不被清除）存储没有时间限制，但是有大小限制，一般（不同浏览器的限制有所差别）对于每个域名是 5 MB，对于存储一些纯字符串脚本，足够了。且目前[大部分主流浏览器](https://caniuse.com/#search=localStorage)均支持此项技术。\n\n但是需要注意，Service Worker 是可以将所有的 HTTP 请求全部拦截，无论服务器的 Response Headers 中的 Content-Type 是什么类型都可以拦截从本地加载。而 localStorage 仅能存储静态资源（JavaScript/CSS）。\n\n而存储在 localStorage 的中的静态资源所带来的优点就在于再次加载时不需要发起 HTTP 请求（Queueing、Stalled、Request sent、TTFB、Content Download 这些都不需要），这可以大大改善不支持 SW 技术的浏览器在访问我网站时的浏览体验。\n\n## 本博客的实践\n\n本博客采用的是 [basket.js](https://github.com/addyosmani/basket.js/) 方案，将 JavaScript 在 localStorage 中，利用 localStorage 的特性，减少 HTTP 连接的次数，以达到改善页面加载体验的目的。\n\n> 目前（2018/09）得益于[新主题的 SPA 特性](/posts/50658b02/)，我已经移除 localStorage 的功能了：一方面是因为用户每次点击并不用重新请求 JavaScript 和 CSS 和 HTML，存储 JavaScript 有些没必要；另一方面是 localStorage 还存在安全隐患，故暂时去除 localStorage。\n\n为了避免每次刷新页面 main.css 加载先后页面出现抖动的问题，默认不将 main.css 放入 localStorage 中存储。\n\n另一个问题是 NexT 在设计之初就很依赖于 js（会加载大量的 js 文件），而这些 js 文件的加载顺序是有要求的，jquery 必须优先被加载，否则就会出现奇怪的 bug，好在 basket.js 提供了控制加载先后顺序的方案。\n\n## 危险性\n\n在[这篇知乎回答](https://www.zhihu.com/question/28467444)中，很详细的列出了 localStorage 的优点和缺点。\n\n其中最危险的是网站出现 XSS 漏洞，就会被人利用将恶意代码注入到 localStorage 中，导致即便修复了 XSS 漏洞存储的代码依然是被篡改的。\n\n好在 basket.js 可以提供将 localStorage 中的代码重新从网络加载的问题。具体见[官方文档](https://addyosmani.com/basket.js/)。"},{"title":"这盛世可如你所愿？","subtitle":"","url":"/posts/d67271d8/","date":"2017-11-24T06:10:04.000Z","updated":"2018-07-06T07:55:34.000Z","category":"碎碎念","tags":["政治","国情","严肃向"],"content":"抱歉，本文已加密，请至网站输入密码后阅读。"},{"title":"Poker 机械键盘开箱与简评","subtitle":"","url":"/posts/72474942/","date":"2017-11-02T05:56:40.000Z","updated":"2017-11-23T11:38:26.000Z","category":"碎碎念","tags":["开箱","键盘","评测"],"content":"> 一入外设深似海，从此钱财是路人。\n\n## 初识\n\n第一次知道外设这个概念，是在高中的时候，在网上偶然逛到机械键盘贴吧，只是当时忙于准备高考，而外设又价格不菲，于是念头便搁置了。\n\n后来上了大学，买了笔记本，敲着笔记本自带的键盘「 shit 」一般的手感，才想到我应该买一把机械键盘了。于是就在网上找，看到一个段子说：\n\n年轻人千万别碰哪些东西？\n\n1. 毒品\n2. 游戏显卡\n3. Hi-Fi 耳机\n4. 固态硬盘\n5. 机械键盘\n6. Steam Origin Uplay\n7. . . .\n\n<!--more-->\n\n当时大一，看到这个段子就笑了一笑，面对从一百多到一千多价位不等的机械键盘，还是比较理智的，听人说凯华轴的手感也是最接近 Cherry 轴的，于是就买了贼鸥 87，用了快两年，这期间：鼠标换了两个，耳机也买了两个，键盘却一直在用这一个，最近有几个键不灵了，正好趁着双十一，想着干脆换一把新的。心中对 Poker 那独特的键位种草已久，可惜京东没有 Poker II 的红轴版本，于是便入手了一代。\n\n## 外观\n\n不愧是「二手东」，这饱经沧桑的包装盒：\n\n![Poker 外包装](https://res.cloudinary.com/wincer/image/upload/v1530844580/blog/poker_unpacking/packaging.jpg \"Poker 外包装\")\n\n关于包装盒，去拿快递的时候还发生了一个小插曲：当时京东的人问我手机尾号，我告诉了她，然后又问我是什么东西，我说是一把键盘，然后他就去找，找了半天，没找到，然后就问另一个人，说：“尾号是 6 的快件都在这里了吧，怎么没有键盘啊？”，然后转头问我：“键盘应该是挺大的吧？”，我说：“不，不大，挺短的”，然后她又去找小一点的包裹，结果一找就找到了。\n\n回到寝室，迫不及待的拆开了包装：\n\n![Poker 包装内容](https://res.cloudinary.com/wincer/image/upload/v1530844624/blog/poker_unpacking/package_contents.jpg \"Poker 包装内容\")\n\n这便是全家福了，包含：键盘本体、USB 连接线、RGB 的大键键帽、说明书、拔键器。\n\n其中连接线带有屏蔽磁环，做工也算精良。\n\n## 60%\n\nPoker 这一系列，最大的特点应当就是 60% 尺寸的设计了，准确来说是 61 键。相对于普通 87 键的键盘，尺寸更加玲珑小巧，省去了方向键和功能键，改为用 `FN` 的组合键来实现相应功能。方向键是用 `Fn` + WASD 来实现，不过，对于用 Spacemacs 的我来说，没啥影响，哈哈。\n\n![键盘本体](https://res.cloudinary.com/wincer/image/upload/v1530844657/blog/poker_unpacking/ontology.jpg \"键盘本体\")\n\n真正拆开的时候才发现 60% 尺寸带来的冲击有多么大。\n\n说到组合键，`Fn` 与组合键的功能在侧刻上都已标注：\n\n![Poker 的侧刻](https://res.cloudinary.com/wincer/image/upload/v1530844715/blog/poker_unpacking/side_engraved.jpg \"Poker 的侧刻\")\n\n`Fn` 与数字键组合就是 F1~F12。`Fn` + N、M、< 分别是音量 -、+、静音等。\n\n## 轴和键帽\n\n说道机械键盘的核心，应当就是轴体和键帽了。\n\n### 轴体\n\n轴体方面，采用的是 Cherry 原厂轴体，大键也是卫星轴设计。手感嘛，自然是没话说了。我这里购买的是红轴的版本，毕竟用了两年，还是红轴最为顺手。\n\n![Cherry 红轴](https://res.cloudinary.com/wincer/image/upload/v1530844769/blog/poker_unpacking/cherry_axis.jpg \"Cherry 红轴\")\n\n### 键帽\n\n键帽采用的是 PBT 材质，对于 ABS 来说，PBT 的好处就是绝不会打油。\n\n![键盘 + 手托](https://res.cloudinary.com/wincer/image/upload/v1530844798/blog/poker_unpacking/hand_rest.jpg \"键盘 + 手托\")\n\n而且这款 PBT 键帽比我之前在网上购入的 PBT 键帽手感要更胜一筹，对着光看起来还闪着微弱的光，挺有意思。\n\n在上图键 F、G、H 的侧面，可以看到有三个数字，分别是 15ms、0.1s、0.5s，这是允许用户调整按下键帽时的响应速度。这一点也是比较新奇。\n\n## 背部\n\n![正面'遗照'](https://res.cloudinary.com/wincer/image/upload/v1530844838/blog/poker_unpacking/front.jpg \"正面'遗照'\")\n\n相对与小巧玲珑的正面来说，背部就没有那么精致了：\n\n![键盘背部](https://res.cloudinary.com/wincer/image/upload/v1530844860/blog/poker_unpacking/back.jpg \"键盘背部\")\n\n四周是四个黑色的防滑垫，没有撑脚，可能是为了缩减体积来作出的取舍（当然键盘也设计成了前高后低的人体工学形状），防滑垫对我来说用处不大，因为我是把键盘放在鼠标垫上使用的。\n\n中间那块金属铭牌上刻着一句英文：「**The keyboard to cheer you up**」（用这把键盘让你高兴起来！）\n\n可能会注意到在底部的右侧有四个很小的指拨开关，作用分别是：\n\n- 开关 1：CAP = 左 WIN；CAP 灯 = 左 WIN 灯\n- 开关 2：右 CTRL = `~\n- 开关 3：左 WIN = 左 FN\n- 开关 4：写保护键盘\n\n## 编程功能\n\n这一功能也算是 Poker 的特色了，目前还不是很了解，先放一放，过几天等了解了再补上。\n\n## 总结\n\n换上附赠的 RGB 键帽后，白色素雅的 Poker 顿时骚了起来，哈哈。\n\n由于是 mini 键盘，我的手托也就不那么合适（长了一截，无关紧要）。\n\n一把 60% 键盘，精简了多余的按键和尺寸，为便携带来了许多好处（要是再赠送一个保护套就更完美了）。做工上乘，手感尚佳，不过大键的手感稍肉，Cherry 原厂轴加上 PBT 键帽，算的是 IKBC 的良心之作，值得入手。（怎么感觉写成了软文 23333"},{"title":"构建一言 API 踩坑记录","subtitle":"","url":"/posts/f6e1eb2a/","date":"2017-10-30T02:44:41.000Z","updated":"2017-12-24T12:06:53.000Z","category":"实验室","tags":["Hitokoto","Flask","API"],"content":"## 前言\n\n最初是在手机上一个叫「一言」的 App 接触到 Hitokoto，一见倾心啊。之前我看书时遇到写的不错的句子就喜欢摘录下来，在有自己的博客之后，本想是单独写一篇博文来存放，后来分析了 NexT 的布局后，就想到在侧栏底部可以加上一个单独的模块。\n\n最开始，是使用别人的 API，后来觉得不太好，有诸多限制，而我又没有主机，于是就自己用 Javascript 写了一个本地的脚本。后来发现这样也不太好，因为本地的脚本每次加载势必要加载存放 Hitokoto 的 JSON 文件一次，当记录越来越多时，会消耗不必要的资源。毕竟每次只需要加载一条。\n<!--more-->\n\n## 获取一言\n\n最开始准备构建的时候，就遇到了一个问题：一言的数据库去哪里找。我翻便了 Google，基本都是提供 API 的，并不会将完整的数据库给你。这想想也正常，都把数据库给你了，那谁还用你的 API 呢。\n\n我就花了一下午，写了一个爬虫，对准了几个提供 API 的网站，开始爬去数据。但是由于 API 产生的数据是随机的，难免会有重复。所以爬取之后又要查重，着实花费了我不少时间。\n\n整个过程大概花了一天多，做成了一个 JSON 格式的文件，然后用 JS 导入成为数组，再随机访问数组的某一项，这便是最初“本地版”的「一言」了。\n\n## 转化数据库\n\n先前已经说过，一旦数据多了起来。那么数组的访问和加载都是问题，而访问慢的问题可以用数据库来解决。而这学期正好在学数据库这门课，于是便花了点时间将 JSON 格式的数据转化成 sqlite 数据库。JSON 格式的数据有需要的只有 3 项，分别是 ID（用以标识每个 Hitokoto）、HITOKOTO（每个 Hitokoto 的内容）、SOURCE（每个 Hitokoto 的出处）。知道了这些，转化的代码就呼之欲出了：\n\n```python\nimport json\nimport sqlite3\n\nJSON_FILE = \"hitodb.json\"\nDB_FILE = \"HITODB.db\"\nconn = sqlite3.connect(DB_FILE)\n\nwith open(JSON_FILE, 'r') as load_f:\n    data = json.load(load_f)\n    for line in data:\n        print(int(line[\"id\"]), line[\"hitokoto\"], line[\"from\"])\n        conn.execute(\n            'INSERT INTO HITOKOTO (ID, HITO, SOURCE) VALUES ({a}, \\'{b}\\', \\'{c}\\')'.\n            format(a=line['id'], b=line['hitokoto'], c=line['from']))\n        conn.commit()\n\nprint('Successfully')\n\nconn.close()\n```\n\n截至至本文发布，该「一言」数据库共收录了 880 条记录，以后我还会陆续添加。\n\n## 生成 API\n\n有了数据库，自然要构建一个 API，这里选用的是 Flask 框架提供的接口。\n\n首先你需要安装 Flask，而 Python 是自带 sqlite3 模块的。直接上代码：\n\n```python\nimport sqlite3\n\nfrom flask import Flask, jsonify\n\napp = Flask(__name__)\n\n\n@app.route('/')\ndef index():\n    return 'Hello World!'\n\n\n@app.route('/api/')\ndef get_hito():\n    conn = sqlite3.connect('HITODB.db')\n    hito = conn.execute(\n        'select * from hitokoto order by random() limit 1').fetchone()\n    hitokoto = \"{} ——「{}」\".format(hito[1], hito[2])\n    return 'function hitokoto() { ' + 'document.write(\\'{}\\');'.format(\n        hitokoto) + '}'\n\n\n@app.route('/api/json/')\ndef get_json():\n    conn = sqlite3.connect('HITODB.db')\n    hito = conn.execute(\n        'select * from hitokoto order by random() limit 1').fetchone()\n    hitokoto = {}\n    hitokoto['id'] = hito[0]\n    hitokoto['hito'] = hito[1]\n    hitokoto['source'] = hito[2]\n    return jsonify(hitokoto)\n\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', debug=True)\n```\n\n保存为 `run.py`。然后运行，打开 `http://0.0.0.0/api/` 如果没有意外的话，应当是成功了。接下来就是部署了。\n\n## 部署至 Heroku\n\n### 环境准备\n\n一开始担心是没有主机，后来才知道有「[Heroku](https://dashboard.heroku.com/)」这个造福大众的云平台服务。\n\n首先你需要安装 [Heroku 客户端工具](https://toolbelt.heroku.com/)，安装完成后，输入以下命令来验证安装是否成功：\n\n```bash\n$ heroku --version\n```\n\n安装成功后，在本地命令行登录 Heroku：\n\n```bash\n$ heroku login\n```\n\n然后输入你的帐号和密码即可\n\n### 创建应用\n\n可以在[网页端创建](https://dashboard.heroku.com/apps)，也可以在命令行创建：\n\n```bash\n$ heroku create wincer-hito\n```\n\n这里或许会提示你名字已经被使用了，换一个就好。接下来要初始化本地和远程代码库。\n\n```bash\n$ mkdir hitokoto\t\t\t\t\t# 创建本地代码仓库\n$ cd hitokoto\t\t\t\t\t\t# 切换至本地仓库目录\n$ git init\t\t\t\t\t\t\t# 初始化本地仓库\n$ heroku git:remote -a wincer-hito\t# 链接到远程仓库\n```\n\n### 部署应用\n\n除了代码和数据库外，两个必要的文件：`requirements.txt` 部署应用时，远程环境会自动安装 `requirements.txt` 文件中列出的依赖。我们 `requirements.txt` 文件内容如下：\n\n```python\nFlask==0.12.2\ngunicorn==19.4.5\n```\n\n接下来，我们如何告诉服务器如何运行这个文件呢？就要通过 `Procfile` 文件了。\n\n```ini\nweb: gunicorn run:app\n```\n\n以上就是 `Procfile` 的内容。\n\n另根据习惯，可自行添加对该项目的描述。\n\n接下来就是激动人心的提交了：\n\n```bash\n$ git add .\n$ git commit -m \"Init commit\"\n$ git push heroku master\n```\n\n打开 https://wincer-hito.herokuapp.com/api/ 看看效果吧！\n\n### 升级应用\n\n升级程序的时候，在所有的改动提交后，建议按照如下步骤升级：\n\n```bash\n$ heroku maintenance:on\n$ git push heroku master\n$ heroku run python run.py deploy\t\t# run.py改成自己的文件名\n$ heroku restart\n$ heroku maintenance:off\n```\n\n## 使用 API\n\n数据获取：\n\n\n- 请求地址：https://wincer-hito.herokuapp.com/api/\n- 请求方式：GET\n- 返回函数名 hitokoto 的 js 脚本，本质为 document.write 函数的脚本\n- 如果需要 json 格式的数据：https://wincer-hito.herokuapp.com/api/json/\n- 如果仅需要 hitokoto 主体：https://wincer-hito.herokuapp.com/api/main/\n\n\n在你想使用「一言」的地方插入以下代码：\n\n```html\n<script type=\"text/javascript\" src=\"https://wincer-hito.herokuapp.com/api/\"></script>\n<script>hitokoto();</script>\n```\n演示效果看侧栏。\n\n注：由于是 Heroku 的主机是在美国，所以该 API 延迟可能会有一点高。"},{"title":"Linux 与 Windows 10 用 GRUB 引导教程","subtitle":"","url":"/posts/ad42f575/","date":"2017-10-17T03:35:19.000Z","updated":"2018-02-05T02:13:49.000Z","category":"分享境","tags":["Linux","Windows","GRUB","双系统"],"content":"## 前言\n去年暑假的时候，写了一篇如何装 Linux 和 Windows 10 双系统的文章发在了简书上，我写这篇文章的原因是当初装双系统确实是折腾了许久，网上也找不到一篇详尽的教程。由于去年对于写教程还不是熟练，而这一年多的使用过程也遇到了一些问题，所以就准备「Refactoring」这篇文章。\n<!--more-->\n\n## EFI 分区\n在教程正式开始之前，先花一点时间说明 EFI 分区的组成和作用。\n首先，在你装了 Windows 之后，Windows 在装机过程中会将硬盘划分出一个约 100m 大小的分区，称为 EFI 分区这个分区就是起引导作用的。在资源管理器中是看不到的这个分区的，可以在磁盘管理中看到，管理则需要借助 [DG 工具](http://www.diskgenius.cn/)。便于说明，在装好了 Linux 之后，我将 EFI 挂载至 boot 分区截图：\n![](https://ae01.alicdn.com/kf/HTB1xK8ydi6guuRjy0Fm7610DXXac.png)\n可以看到，该分区包含 3 个文件夹（如果你没有装 Linux 的话，就只有两个），分别是 Boot、Microsoft 和 Manjaro，其中 Boot 文件夹就是 UEFI 引导所必需的文件。\n我们继续打开 `Microsoft/Boot` 文件夹：\n\n![](https://ae01.alicdn.com/kf/HTB10sdFdjbguuRkHFrd762.LFXa9.png)\n\n这些文件就是启动 Windows 10 所必需的，包含了语言包、字体等，BCD 包含了 Windows 引导开始以后的信息。其中，**bootmgfw.efi 是 Windows 默认引导文件**。\n1. EFI/Boot/bootx64.efi\n2. EFI/Microsoft/Boot/bootmgfw.efi\n\n以上是采用 UEFI 启动 Windows 10 的文件结构，也就是说，当你按下开机按钮的时候，首先 UEFI 找到 EFI 分区的 Boot 文件夹，然后加载 `bootx64.efi` 文件，读取文件信息，找到 `EFI/Microsoft/Boot/bootmgfw.efi`，按照 `bootmgfw.efi` 的要求，加载所需的启动信息，启动 Windows 10。\n\n## 准备工作\n在正式装系统之前，我们还需要做一些准备工作：\n### 关闭 Windows 的快速启动\n这个功能的作用是在于关机的时候不完全断电，类似将系统处于「休眠」状态，这样可以让开机更加迅速。但这也就导致了只能使用 Windows 系统。\n### 关闭 BIOS 的 Secure Boot 的功能\n在默认情况下，UEFI 固件只会加载那些被签名的引导程序。在缺少 Secure Boot 功能的传统 PC 机上，恶意的后门程序可以加载自身，进而摇身一变伪装成一个引导程序。这样的话，BIOS 就会在启动的时候加载后门程序，这样它就可以躲过操作系统，把自己隐藏得很深。\n但是不得不说，这对我们安装 Linux 造成了很大的困扰，也是直接导致我们重启到 Windows 10 后进不去 Linux 的原因。\n首先我们要关闭这个功能：进入 BIOS 找到 Secure Boot，选择 disabled，这样就关闭了。当然，有些人进入 BIOS 会发现 Secure Boot 这个选项是灰色的（比如我的就是），这时你需要先给你的 BIOS 设一个密码，然后就能关 Secure Boot 了。\n## 安装 Linux\n所有的准备都已经完成，这时就可以准备刻录 U 盘了，不推荐 UltraISO，经亲测，软碟通仅刻录 Ubuntu 能成功，其它绝大多数发行版都会失败。推荐「[Rufus](https://rufus.akeo.ie/)」和「[USBWriter](https://sourceforge.net/projects/usbwriter/)」，这两个软件都可以。\n刻录完成后，重启按 `f12`，选择从 USB 设备启动，对于绝大多数发行版来说一路回车就行了，只需要注意一点：**在选择挂载 boot 位置的时候，一定要挂载在 efi 分区**，别的都不行。\n重启之后，不出意外的话，你会直接进入 Windows 10，不要担心，这时 Linux 已经安装成功了，我们只需要将引导文件替换一下。\n\n## 替换引导文件\n先用 DG 打开 EFI 分区，你会看到多了一个文件夹，名称取决于你安装的是哪一个发行版。我安装的是 Manjaro Linux，名称就是 Manjaro，打开之后会发现里面有一个名为 grubx64.efi 的文件，这就是启动 Linux 的引导文件。和 Windows 10 的 bootmgfw.efi 类似，我们想要用 grubx64.efi 引导代替掉 bootmgfw.efi，这样就可以用 GRUB 引导了。步骤：\n1. 进入管理员命令行。方法：win + x，再按 a，这里注意看你打开的是 Powershell 还是 CMD，\n2. 输入以下命令：\n  ```powershell\n  bcdedit /set {bootmgr} path \\EFI\\Manjaro\\grubx64.efi\n  #如果报错，就把 {bootmgr} 用单引号引起来，CMD 和 Powershell 语法的区别\n  ```\n\n至此，如果你安装的是除 Arch 之外绝大多数发行版，那么接下来就和你没有啥关系了，你已经成功了，好好享受吧！\n\n开机之后会发现进入 GRUB 的引导了，通常会包含至少三个选项（以 Manjaro 举例）：Manjaro、Manjaro 高级选项和 Windows Manager。这就代表你已经完美的解决了 Windows 和 Linux 双系统引导的问题。\n## 修复 Windows 引导\n这一点是我安装 Arch Llinux 的时候发现的，Arch Linux 安装过程是手动安装的，在编写 GRUB 的时候会扫描不到 Windows Manager 所在的分区（当然可能不是所有人都会遇到），所以在 GRUB 界面可能会看不到 Windows Manager 选项，导致进不去 Windows 10，这里就需要手动编辑 GRUB 信息，我们打开 `/boot/grub/grub.cfg` 文件，发现里面确实没有 Windows 10 的启动信息，在后面加上：\n\n```bash\nmenuentry \"Microsoft Windows 10\" {\n  insmod part_get\n  insmod fat\n  insmod search_fs_uuid\n  insmod chain\n  search --fs-uuid --set=root $hints_string $fs_uuid\n  chainloader /EFI/Microsoft/Boot/bootmgfw.efi\n}\n```\n\n**注意**：\n\n这里的 `$hints_string`，代表的是终端执行命令：\n\n```bash\nsudo grub-probe --target=hints_string /boot/efi/EFI/Microsoft/Boot/bootmgfw.efi\n```\n后的输出；\n\n而 `$fs_uuid` 代表的是：\n\n```bash\nsudo grub-probe --target=fs_uuid /boot/efi/EFI/Microsoft/Boot/bootmgfw.efi\n```\n\n的输出。\n\n然后保存。在终端执行命令：`sudo grub-mkconfig -o /boot/grub/grub.cfg`，就 OK 了。\n\n到此，Arch Linux 和 Windows 10 双系统也配置完毕了。\n\n## 附加问题\n\n在使用这一年多的时间，遇到了以下的几个问题：\n1. 在 Windows 10 进行了一个大更新后，会发现 GRUB 引导界面没有了，还是直接进入了 Windows 10，这时只需要按照 `替换引导文件` 的方法重新输入一遍命令就行。\n2. 使用 Linux 某个发行版一段时间之后，难免会想尝试一下另一个发行版。这时请务必将之前的发型版的引导文件删除，否则可能会出现无论怎么设置都无法进入 GRUB 的情况。例如：我之前用的是 Ubuntu，我现在换成了 Manjaro，我就需要用 DG 删除 EFI 分区的 Ubuntu 文件夹。\n3. 在我使用 Manjaro 更新了一次 Linux 的内核后，进不去 Windows 10 了，这个时候千万不要直接修复 Windows 10 引导，这会格式化 EFI 分区，只需要按上面 [修复 Windows 引导](https://itswincer.com/posts/ad42f575/#%E4%BF%AE%E5%A4%8D-Windows-%E5%BC%95%E5%AF%BC) 的方法编辑一下 GRUB 就可以了。\n\n最后：祝使用愉快。"},{"title":"Kindle Papwerwhite 开箱 & 简评","subtitle":"","url":"/posts/6619f85a/","date":"2017-10-05T04:33:46.000Z","updated":"2017-12-23T03:39:47.000Z","category":"碎碎念","tags":["开箱","Kindle","简评","电子书"],"content":"> If you don't let go old things, new ones wouldn't come.                   —— Nicolas Wincer\n\n## 前言\n\n时间是在 9 月 27 日晚，我用了一年零 8 个月的 Kindle 正式宣布坏掉，原因是充不进电，我的第一反应是想着去修，后来还是打消了这个念头。主要是这个 Kindle 实在算是家族里的「老古董」了，我对 kpw3 的 300 ppi 也是种草许久，正好本着“旧的不去，新的不来”的观念，就入了一部 kpw3，其实在我想着要买  kpw3 的时候，是有点纠结 Voyage 的，因为用了快两年的 Kindle3 我已经习惯了实体翻页键，奈何囊中羞涩，只是为了这一个功能就要多花 600 +，有些不值当，想着等工作了之后直接上 Oasis。\n\n<!--more-->\n\n其实我最近是比较少看书了，现在看的这本《雪中悍刀行》看了半年多才看了一半，上本《将夜》看了一年，一方面是看的书越多，品味自然也高了起来，现在写的好的小说是越来越少，之前一直很喜欢的几个作者要么更新是越来越慢（比方说：烽火戏诸侯，愤怒的香蕉）、要么是书的质量不如之前（比方说：烟雨江南、猫腻），有点担心自己看完了就书荒了。\n\n我买 Kindle 不是为了亚马逊庞大的图书资源（我看书只自己在网上找），而是因为那块 E-ink 屏幕，而且因为 Kindle 那可怜兮兮的娱乐功能，用 Kindle 时可以更专注于看书。而国庆前几天一直忙于跑亲戚，所以直到今天才有空闲时间开箱。\n\n## 开箱\n\n这就是全部的配件（裸机 + 数据线）了：右边是卖家附赠的\n\n![全部配件](https://res.cloudinary.com/wincer/image/upload/v1530861449/blog/kindle_unpacking/pic1.jpg)\n\n| 参数   | 描述                 |\n| :----: | :-----------------: |\n| 阅读灯  | 4 颗                |\n| 解析度  | 300 ppi            |\n| 重量   | 205 g              |\n| 尺寸   | 169 × 117 × 9.1 mm |\n| 屏幕   | 6 吋                |\n| 容量   | 4 GB               |\n| 连接   | Wi-Fi              |\n| 运存   | 512 mb             |\n\n\n\n\n## 简评\n\n开完箱经过简单的设置之后，迫不及待的从电脑传了几本书（谁都阻止不了我想读书的心情！）。\n\n![首页截图](https://res.cloudinary.com/wincer/image/upload/v1530861472/blog/kindle_unpacking/pic2.png)\n\n吐槽一下，这里是无法像多看一样做成文件浏览的形式，也就是说，即使你把一些书放进新建的文件夹里（便于归类管理），它也是直接在首页显示。\n\n这就是阅读界面的选项了，选项少的可怜，而且页边距太大！我这已经设置页边距最小了。\n\n![书籍页面](https://res.cloudinary.com/wincer/image/upload/v1530861491/blog/kindle_unpacking/pic3.png)\n\n得益于 Kindle 这块 4:3 的屏幕，看漫画可以说是比手机更具优势。清晰度是够了，要是屏幕再大一些就好了：\n\n![漫画页面](https://res.cloudinary.com/wincer/image/upload/v1530861506/blog/kindle_unpacking/pic4.png)\n\n如果想要购买正版书，就在上方的搜索按钮输入书名：\n\n![在线书籍](https://res.cloudinary.com/wincer/image/upload/v1530861524/blog/kindle_unpacking/pic5.png)\n\n设置界面确实寒酸，不过想想要的只是纯粹的阅读体验，也就释然了：\n\n![设置1](https://res.cloudinary.com/wincer/image/upload/v1530861537/blog/kindle_unpacking/pic6.png)\n\n![设置2](https://res.cloudinary.com/wincer/image/upload/v1530861554/blog/kindle_unpacking/pic7.png)\n\n使用了~~半个多小时~~两天多了，简单总结一下感受：\n\n1. 300 ppi 看起书来真的是太 ™ 爽了\n2. 在翻页的速度上，相比前几代快了不少，当然和手机还是没法比\n3. 阅读灯对我来说没啥用，我晚上看书也会开台灯\n4. 页边距实在太大，我都已经调整成了最小边距了，可还是留白太多\n5. 系统功能相比多看来说还是少了一些，比如无法设置全刷页数\n\n## 后记\n\n买 kpw3 之前其实还有一个顾虑，就是刷不了「多看」，我的电子书资源多是 「epub」格式的，而 Kindle 的原生系统是**不支持**「epub」格式的（我一直搞不懂为什么亚马逊不支持）现在我每一本书都要转成 「mobi」 才能在 Kindle 上看。\n\n还有就是实体翻页键了，等我经济独立之后，一定要买 Oasis！"},{"title":"Spacemacs 生存指北","subtitle":"","url":"/posts/2aa541e6/","date":"2017-09-26T05:01:33.000Z","updated":"2017-12-23T11:38:23.000Z","category":"分享境","tags":["Spacemacs","编辑器"],"content":"## 简介\n\n[Spacemacs](http://spacemacs.org/) 是一份 [Emacs](https://www.gnu.org/s/emacs/) 的配置文件，将 [Vim](https://github.com/vim/vim) 的快捷键移植到了 Emacs 上，可以提供 Vimer 至 Emacs 的无缝衔接。有了 Spacemacs，你不需要花那么多时间去学习 Emacs 就可以真正用 Spacemacs 开始做一些事情。\n\n<!--more-->\n\n## 安装\n\n```bash\n$ mv ~/.emacs.d ~/.emacs.d.bak\n$ git clone https://github.com/syl20bnr/spacemacs ~/.emacs.d\n$ emacs\n```\n\nClone 至本地后，第一次使用 Spacemacs 时要加载一些 Package，以及根据你的喜好所生成的配置，建议一路回车。\n\n此时会加载很多的 Package，如果没有挂代理的话，就会很慢很慢，可以采用 [emacs-china](https://elpa.emacs-china.org/) 的配置源。\n\n## 快捷键\n\nSpacemacs 基本使用的是原生 Vim 的快捷键，此前请先熟悉 Vim 的操作。我这里只贴出个人认为比较常用的快捷键。\n\n### 配置文件\n\n`SPC f e d` 快速打开配置文件\n\n`SPC f e R` 同步配置文件\n\n`SPC q q ` 退出 Emacs\n\n`SPC q R` 重启 Emacs\n\n### 文件管理\n\n`SPC f f` 打开文件\n\n`SPC f t` neotree 方式显示文件路径\n\n`Ctrl s` 搜索当前文件（需安装 ivy layer）\n\n`*` 另一种搜索文件的姿势（需将光标置于需搜索的单词处）\n\n- `n`  下一个匹配\n- `N/p` 前一个匹配\n- `r` 改变范围：当前屏幕，当前函数，当前 buffer\n- `e` 编辑所有匹配（类似于替换）\n- `/` 在当前 project 搜索\n\n`SPC s c` 清除搜索高亮\n\n`SPC f R` 重命名当前文件\n\n`SPC f E` 使用 sudo 来编辑文件（当某些文件的权限是只读的时候）\n\n`SPC f D` 删除当前文件\n\n`SPC f r` 打开最近文件列表（需安装 ivy layer）\n\n`SPC f y` 复制当前文件的绝对路径\n\n`SPC f c` 复制文件\n\n### buffer 管理\n\n`SPC b b` 显示已经打开的 buffer\n\n`SPC b d` 关闭当前 buffer\n\n`SPC b h` 进入 Spacemacs 初始界面\n\n`SPC b N` 新建一个 buffer\n\n`SPC b R` 从自动备份的文件中恢复\n\n`SPC b Y` 复制整个 buffer 的内容\n\n`SPC b P` 将剪贴板的内容粘贴到整个 buffer\n\n`SPC Tab` 切换至上一个 buffer\n\n### 窗口管理\n\n`SPC n(number)` 跳转至第 n 号窗口\n\n`SPC 0` 跳转至 neotree 侧边栏\n\n`SPC w m` 当前窗口最大化\n\n`SPC w s` 或 `SPC w -` 水平分割窗口\n\n`SPC w v` 或 `SPC w /` 竖直分割窗口\n\n`SPC w =` 平衡窗口\n\n`SPC w d` 删除当前窗口\n\n`SPC w o` 切换至其他窗口\n\n`SPC t g` 将当前窗口与其他窗口 黄金分割\n\n### project 管理\n\n`SPC p f` 在当前 project 中查找文件\n\n`SPC p p` 切换项目\n\n`SPC /` 在该项目中搜索字符串\n\n`SPC p R` 在项目中替换字符串，先输入「匹配」的，再输入「替换」的字符串（我一般不使用这种方式，我用`*`来替换）\n\n### 缩进代码\n\n`SPC j =` 自动对齐\n\n`SPC m =` 美化代码（不适用于所有语言）\n\n### shell 操作\n\n`SPC '` 打开/关闭 Eshell（需安装 shell layer）\n\n`SPC a s` 打开其它种类的 Shell\n\n### 中断操作\n\n`C g` 输错命令时，可取消该次输入\n\n## 显示动态行号\n\n将  `dotspacemacs-line-numbers` 的值改为 'relative\n\n## Magit\n\nSpacemacs 中集成了 Git 管理工具，需先安装 git layer。\n\n常用的快捷键：\n\n| git                    | magit               |\n| ---------------------- | ------------------- |\n| `git init`             | `SPC g i`           |\n| `git status`           | `SPC g s`           |\n| `git add`              | `SPC g s` 弹出然后按 `s` |\n| `git add currentfile ` | `SPC g`             |\n| `git commit`           | `SPC g c c`         |\n| `git push`             | `SPC g P`           |\n| `git log`              | `SPC g l l`         |\n| `git checkout xxx`     | `SPC gn C`          |\n| `git checkout -- xxx`  | `SPC g s` 弹出然后按 `u` |\n| `git reset --hard xxx` | `SPC g s` 弹出然后按 `x` |\n\n## 守护模式\n\n终端使用 `emacs -daemon` 以守护模式开启 emacs：\n\n`$ emacsclient -c` 打开 Emacs GUI\n`$ emacsclient -t ` 打开 命令行 Emacs\n\n当开启守护进程时，点击关闭按钮后进程还是会保留在后台，如果想要彻底关闭 Emacs 可以：`SPC q q` 或者`$ killall emacs`\n\n以下是我针对我常用的一些语言做的一些特殊的设置：\n\n## C/C++\n\n我没有采用 Spacemacs 提供的 c/c++ layer，而是采用的 [Irony-Mode](https://github.com/Sarcasm/irony-mode)，因为原生的 c/c++ layer 自动补全需要 ycmd，而 ycmd 安装配置起来实在太麻烦了。\n\n### 快捷键\n\n`:gdb` 启用 gdb 调试\n\n`SPC c C` 编译程序\n\n- 默认是用 `cmake` 编译，可以替换成 `clang/gcc -g main.C -o main` （这些参数会被记住）\n\n\n## Python\n\nPython 用的 Spacemacs 自带的 python layer，添加了一些参数：\n\n```lisp\n(python :variables\n        python-enable-yapf-format-on-save t ;; 当保存的时候自动 `yapf' 美化\n        python-fill-column 80\t\t\t\t;; 开启 80 列的提示\n        python-sort-imports-on-save t)\t\t;; 当保存的时候自动排序导入的包\n```\n\n### 快捷键\n\n`, c c` 运行当前文件\n\n`, =` 美化代码\n\n`, '` 打开 IPython repl\n\n`, g` 跳转至定义处：\n\n- `, g g` 在当前窗口跳转至定义处\n- `, g G` 在另一窗口跳转至定义处\n- `, g b` 回到原处\n\n`, s` 将当前文件发送至 repl:\n\n- `, s b` 将当前 buffer 发送至 repl\n- `, s f` 将当前 defun 发送至 repl\n- `, s r` 将当前选中内容发送至 repl\n\n## JavaScript\n\n我将 JavaScript layer 自带的 repl 换成了 nodejs，自带的不太好用。\n\n```lisp\n(javascript :variables\n            tern-command '(\"node\" \"/home/wincer/.npm-global/bin/tern\")\t;; 指定 `tern' 的路径\n            javascript-disable-tern-port-files nil)\n```\n\n设置了一些快捷键：(o 开始的默认为用户自定义的)\n\n`SPC o s i` 启动 nodejs repl\n\n`SPC o s b` 将当前 buffer 发送至 repl\n\n`SPC o s r` 将选中内容发送至 repl\n\n`SPC o s l` 将当前行发送至 repl\n\n## Scheme\n\n我是在学 sicp 时才用到 Scheme，所以采用的 Scheme 实现是 MIT-Scheme，并将其设置为默认 repl：\n\n### 快捷键\n\n`, '` 切换至 repl\n\n`, s` 评估算式：\n\n- `, s b` 计算当前 buffer\n- `, s e` 计算最后一个表达式\n- `, s f` 计算当前定义的函数\n- `, s r` 计算当前选中的内容\n\n## 结语\n\n我的 Spacemacs 配置放在了 GitHub 上，[这是地址](https://github.com/WincerChan/Spacemacs-Config)。"},{"title":"写给 20 岁的自己","subtitle":"","url":"/posts/11ab0263/","date":"2017-08-28T16:00:00.000Z","updated":"2017-12-24T12:01:29.000Z","category":"碎碎念","tags":["成长","感想"],"content":"> 凡心所向，素履所往，生如逆旅，一苇以航。\n\n一直很喜欢海子对于时间的说法——“打马而过”。就像我还没来得及细数，20 个年头匆匆已逝。没有那么多时间细想，这一天就这么来临了，来不及回忆过去，也来不及憧憬未来，一眨眼，就发现自己已经 20 岁了。\n\n在许久之前，我便对自己的 20 岁有过憧憬，想着，20 岁的我会在哪里，做着什么事情。是有了一项划时代的发明，成为震惊世界的奇才；还是偏居一隅，发出「天地与我并生 万物与我为一」的感慨。是的，我希望自己能真实的活着，不像那些忙忙碌碌一辈子不知道为谁而活的人那样。不在意别人的眼光，不为了生存而活。\n\n<!--more-->\n\n但是，现在的我，也就只是在大学里，做着大多数人应该做的事情，过着大多数人应该过的生活。看来在这二十年的生命中，我还是不够坚韧。\n\n我想我是不甘于于平凡的，很小的时候，我就会告诉自己，不要去重复别人做过的事情，因为我是独一无二的（后来才知道原来小孩都会有这样的想法），我有自己的事情去做。现在回想起来，还真的觉得挺可爱的。\n\n![搏击俱乐部](https://ae01.alicdn.com/kf/HTB1dc97B5OYBuNjSsD4762SkFXaC.png \"搏击俱乐部\")\n\n《搏击俱乐部》里泰勒抢了一个便利店员（雷蒙）的钱包并拿枪指着他的后脑勺，雷蒙跪在地上颤抖着，泰勒问他想做什么，同时扳下击锤，雷蒙颤抖得更厉害了。\n\n“兽医”，雷蒙颤几乎是带着哭腔说了出来。\n\n“我知道了，我要拿走你的驾照。我随时会去看你，我知道你住在哪”，泰勒说。\n\n“要是在六星期内你没当上兽医，你就死定了”，泰勒把钱包还给他了，并让他跑回了家。\n\n同行的杰克表示不理解：“拜托 那有什么好玩的？那样做有什么意义？”\n\n泰勒背对着他，“明天会是他一生中最美的一天，他的早餐会比我们吃过的都甜美。”\n\n---\n\n蒋勋在《孤独六讲》中写到，好像只有孤独，生命可以变得丰富而华丽。\n\n无人理解的泰勒，他的人生想必是华丽到了极点。他内心所真正向往的地方是只有自己知晓的一方天地，他会去做自己想做的事，并因此让自己的生命变得有意义起来。\n\n这一切都是因为做自己喜欢的事情，无关别人，只是为了自己的热爱。\n\n从小到大，父母乃至老师灌输的思想就是：用心念书，从市重点初中，到省重点高中，再到一本大学，过更好的生活。\n\n是的，过去二十年我仿佛就是按照这个既定的轨迹，一步一步活成了别人眼中的自己。等到我现在可以反思我的生活时，才发现**我想做的事情**和**我应该做的事情**那条清楚的界限早已模糊不清，长期的压力仿佛让自己对一切都失去了兴趣。\n\n我抗争过吗？当然抗争过，不过一个人的力量终究是难以改变什么，泰勒也深知这一点，才会成立“搏击俱乐部”。\n\n这样的生活很可怕。\n\n![三傻大闹宝莱坞](https://ae01.alicdn.com/kf/HTB1O5AhKhSYBuNjSspj76073VXaT.png \"三傻大闹宝莱坞\")\n\n《三傻大闹宝莱坞》兰彻对法汗说：\n\n> 知道我为什么第一名吗？因为我热爱机械，工程学就是我的兴趣所在，知道你的兴趣吗？这就是你的兴趣……跟工程学说拜拜，跟摄影业结婚，发挥你的才能，想想迈克尔杰克逊的爸爸硬逼他成为拳击手，拳王阿里的爸爸非要他去唱歌，想想后果多可怕？\n\n是的，被别人强迫去做自己不喜欢的事情，是很可怕的。更可怕的是，被强迫的多了，就会麻木。\n\n从小学到高中，我的生活一直像父母要求的那样，努力，不轻言放弃。被强迫穿着这许多外衣的我，沿着既定的轨迹一点一点的行进。\n\n如果说，之前的我，不是为自己而活，那么从此时此刻，我就要像小时候自己想的那样，不为别人而活，为自己真实地活着。去寻找自己喜欢且甘之如饴的事情。\n\n---\n\n作家吴晓波在《把生命浪费在美好的事情上》中写到：\n\n> 喜欢，是一切付出的前提。只有真心的喜欢了，你才会去投入，才不会抱怨这些投入，无论是时间、精力还是感情。\n\n> 在这个世界上，不是每个国家每个时代每个家庭的年轻人，都有权利去追求自己所喜欢的未来，所以，如果你侥幸可以请千万不要错过。\n\n我还年轻，以后的路还很长，我可以做得更好。\n\n不要害怕前路，我会迈着缓慢而坚定的步伐走下去。\n\n我不要自己做到最好、最优秀，只希望能在接下来的时光里，变得柔软而坚韧。\n\n最后，二十岁快乐，送给自己。"},{"title":"再见 LiveRe，拥抱 Disqus","subtitle":"","url":"/posts/e5d13eb/","date":"2017-07-29T02:08:32.000Z","updated":"2018-03-08T11:35:36.000Z","category":"博客栈","tags":["Disqus","博客","评论"],"content":"没错，我又双叒叕换评论系统了，从最初的网易云跟帖，到后来的 LiveRe，再到现在的 Disqus，两个多月就换了好了三四次（中间从 LiveRe 切换过一次 Disqus，后来又换回来了）了，仿佛我在折腾这些非博客主体的路上越走越远，也幸好我的博客才建成，没啥人留言，不然就得不偿失了。\n\n<!--more-->\n\n## LiveRe\n\n其实 LiveRe 真的做的挺棒的，中国的本地化做的更是没话说，支持国内的社交媒体：微信、QQ、百度、人人、豆瓣、新浪，国外的支持的就更多了，上次我因为评论框颜色的问题发送了邮件，结果不到 12 个小时 LiveRe 中国区的负责人亲自发邮件解答了这个疑问，就这点来说简直太良心了。\n\n但是美中不足的是：\n\n1. 不支持游客评论（其实这点倒无关紧要）\n2. 不支持导出评论\n3. 在我博客的加载速度问题\n\n我最不能忍受的就是第三点了，由于我博客是采用了 CloudFlare 的 Keyless SSL 技术，流量都会走 CloudFlare 的 CDN 节点，但是由于节点在国外，国内访问速度实在是太慢了，每次点开网页都会看到圈圈不停的转，这简直不能忍啊，于是我就想做一个延时加载的，后来想想，既然都要做延时加载的了，那我为什么不干脆换成 Disqus 呢？\n\n## Disqus\n\n那么说到 Disqus，之前为什么会不用 Disqus 呢，主要还是担心国内不会翻墙用户无法评论的问题，后来想想其实这点不重要，因为：\n\n1. 我的博客只是在 [Google Search Console](https://www.google.com/webmasters/tools/home#utm_source=zh-CN-wmxmsg&utm_medium=wmxmsg&utm_campaign=bm&authuser=0) 添加了信息，没有在百度站长平台添加，~~所以百度是搜索不到我的网站~~现在貌似已经可以搜到了；既然是从谷歌搜索进入的话，那自然也就不存在不会翻墙的问题了；\n2. 不是所有的用户都需要看评论，于是我就把评论功能隐藏了起来，~~需要的话点击下方按钮加载评论~~，如果网络比较好的话，会自动显示，否则需要手动点击；\n\n这样优化过后，总算好多了。\n\n## 延迟加载\n\n原理嘛，先用 ajax 异步发送一个 get 请求至 Disqus 服务器，接收成功则屏蔽按钮，加载评论；超时则自动断开，并显示加载按钮：\n\n```html\n<button class=\"disqus_click_btn\">点击以加载评论</button>\n<%\n/*\n延迟加载 disqus，timeout 可以自己设置时长\n*/\n%>\n<script type=\"text/javascript\" id=\"disqus-lazy-load-script\">\n    $.ajax({\n    url: 'https://disqus.com/next/config.json',\n    timeout: 300,\n        success: function(){\n        var d = document;\n        var s = d.createElement('script');\n        s.src = '//<%= theme.comment.shortname %>.disqus.com/embed.js';\n        s.setAttribute('data-timestamp', + new Date());\n        (d.head || d.body).appendChild(s);\n        $('.disqus_click_btn').css('display', 'none');\n    },\n    error: function() {\n        $('.disqus_click_btn').css('display', 'block');\n    }\n    });\n</script>\n<%\n/*\n由于我超时时长设置得比较短，所以可能翻墙了还是没有自动加载评论，这时就需要手动点击加载了\n*/\n%>\n<script type=\"text/javascript\" id=\"disqus-click-load\">\n    $('.btn_click_load').click(() => {  //click to load comments\n        (() => { // DON'T EDIT BELOW THIS LINE\n            var d = document;\n            var s = d.createElement('script');\n            s.src = '//<%= theme.comment.shortname %>.disqus.com/embed.js';\n            s.setAttribute('data-timestamp', + new Date());\n            (d.head || d.body).appendChild(s);\n        })();\n        $('.disqus_click_btn').css('display','none');\n    });\n</script>\n```\n\n> 后续：我在这篇文章里面用了一种更合适的方式来[载入评论](/posts/migrating-from-hexo-to-hugo/#评论的加载)\n\n最后，列一下我对博客的优化：\n\n1. 使用 glup 插件压缩 html、css、js、img 等；\n2. CloudFlare 的 CDN 加速访问资源；\n3. ServiceWorker 提供离线访问技术；\n4. 延时加载 Disqus 评论；\n\n每一点优化我都有写文章，文章链接可以通过搜索关键字获取。"},{"title":"使用 Service Worker 优化网站","subtitle":"","url":"/posts/a0df572f/","date":"2017-07-25T05:06:47.000Z","updated":"2018-08-25T12:02:59.000Z","category":"实验室","tags":["ServiceWorker","博客","优化","sw-toolbox"],"content":"静态博客的内容是很适合用缓存来加速访问的，除了采用常见的 CDN 加速和压缩博文等方法，通过客户端也可以实现加速访问，本文介绍的是「服务工作线程—— Service Worker」。关于 Service Worker 的具体介绍见[这里](https://developers.google.com/web/fundamentals/getting-started/primers/service-workers)。本文主要需要的是它的离线加载的特性。\n\n<!--more-->\n\n本博客使用 Service Worker 可分为两个阶段，在我最初撰写本文的时候，使用的是 Service Worker 原生的接口。在不久之后，Google 推出了 [sw-toolbox](https://github.com/GoogleChromeLabs/sw-toolbox) 和 [sw-precache](https://github.com/GoogleChromeLabs/sw-precache) 用以让用户更全面的掌控 Service Worker 缓存的方式：包括版本控制、文件缓存级别、具体路径等，于是在我经历了漫长的实践后（其实是因为懒），有了本文 Version 2.0。\n\n## 启用 Service Worker\n\n### 添加注册代码\n\n以下注册代码需要在网站的根目录添加，这样才能保证接管整个网站的全部资源。\n\n```javascript\nif ('serviceWorker' in navigator) {\n    navigator.serviceWorker.register('/sw.js')\n    .then(function() {\n        console.log('A new service worker is being installed.');\n    })\n    .catch(function(error) {\n      console.log('Service worker registration failed:', error);\n    });\n  } else {\n    console.log('Service workers are not supported.');\n  }\n```\n\n将以上代码加入主题中，至于加在哪需要根据主题的结构决定。你只需要保证生成的静态资源中包含以上代码，那么就算添加成功。以 NexT 为例，你可以把以上代码添加到 ``/next/layout/_thrid-party/comments/ ` 下的任一评论配置文件中（前提是你开启了该评论组件）。\n\n### 添加静态资源\n\n将以下代码保存为 `sw.js`，并确保生成静态文件的时候，`sw.js` 在网站根目录下（你可以把它放在 `source` 文件夹内）。\n\n```javascript\n \"use strict\";\n (function() {\n     var cacheVersion = \"-180503\";\n     var staticCacheName = \"asset\" + cacheVersion;\n     var maxEntries = 100;\n     self.importScripts(\"https://cdn.jsdelivr.net/npm/sw-toolbox@3.6.0/sw-toolbox.js\");\n     self.toolbox.options.debug = false;\n     self.toolbox.options.networkTimeoutSeconds = 1;\n\n     /* staticImageCache */\n     self.toolbox.router.get(\"/(.*)\",self.toolbox.cacheFirst, {\n     \tcache: {\n     \t name: staticCacheName,\n             maxEntries: maxEntries\n     \t}\n     })\n })();\n```\n\n首先指定 cacheVersion，在刷新缓存的时候会进行匹配；其次是一个 Cache Storage 名称的有关变量，我这里只是简单划分为静态资源——全部从缓存中加载的资源；关闭 debug 模式，设置 Timeout 时间为 1s。\n\n其中 sw-toolbox 的[缓存级别](https://github.com/GoogleChromeLabs/sw-toolbox/blob/master/docs/api.md#handlers)共有 5 个（网络优先、缓存优先、速度优先、仅缓存、仅网络）。\n\n我这里采用的是 `cacheFirst`，即缓存优先加载。可针对具体的资源进行不同的缓存级别分配。\n\n其中 `self.toolbox.router.get` 表示每一个你需要操作的资源，第一个参数表示匹配的网址，第二个表示缓存级别，第三个是回调函数。\n\n具体到以本站为例的话，你可以参考本站的[配置文件](https://github.com/WincerChan/MyBlog/blob/hexo/source/sw.js)。\n\n## 加速效果\n\n### 离线\n\n可以看到在启用了 `Offline` 仍然可以加载页面\n\n![效果1](https://res.cloudinary.com/wincer/image/upload/v1530862392/blog/sw_optimize/pic1.gif)\n\n\n\n### 缓存 \n\n刷新页面可以看到许多资源是直接 ( from ServiceWorker ) 加载的，并未发起新的 http 请求。\n\n![效果2](https://res.cloudinary.com/wincer/image/upload/v1530862438/blog/sw_optimize/pic2.gif)\n\n## 先决条件\n\n### 浏览器\n\n [is Serviceworker ready](https://jakearchibald.github.io/isserviceworkerready/) 详细列出了所有浏览器支持的情况。\n\n![](https://res.cloudinary.com/wincer/image/upload/v1530862459/blog/sw_optimize/broswer_support.png)\n\n### HTTPS\n\n服务器工作线程只能工作在 HTTPS 加密的网站上，本地的 `localhost` 是默认安全。\n\n参考文章：\n\n- [服务工作线程：简介](https://developer.google.com/web/fundamentals/getting-started/primers/service-workers)\n- [ServiceWorkerRegistration](https://developer.mozilla.org/en-US/docs/Web/API/ServiceWorkerRegistration)"},{"title":"Python 实现多线程下载器","subtitle":"","url":"/posts/80689c8d/","date":"2017-07-19T06:53:24.000Z","updated":"2017-08-30T09:46:40.000Z","category":"实验室","tags":["Python","多线程"],"content":"## 前言\n\n我为什么会想到要写一个下载器呢，实在是被百度云给逼的没招了，之前用 Axel 配合直链在百度云下载视频能达到满速，结果最近两天 Axel 忽然不能用了，于是我就想着要不干脆自己写一个吧，就开始四处查询资料，这就有了这篇博客。\n\n我假设阅读这篇博客的你已经对以下知识有所了解：\n\n- Python 的文件操作\n- Python 的多线程\n- Python 的线程池\n- Python 的 requests 库\n- HTTP 报文的首部信息\n\n<!--more-->\n\n## 下载\n\n获取文件采用的是 requests 库，该已经封装好了许多 http 请求，我们只需要发送 get 请求，然后将请求的内容写入文件即可：\n\n```python\nimport requests\n\nr = requests.get('http://files.smashingmagazine.com/wallpapers/july-17/summer-cannonball/cal/july-17-summer-cannonball-cal-1920x1080.png')\nwith open('wallpaper.png', 'wb') as f:\n    f.write(r.content)\n```\n\n随后看看文件夹，那张名为 `wallpaper.png` 的图片就是我们刚刚下载的。\n\n但是这个功能太简单了，甚至简陋，我们需要多线程并发执行下载各自的部分，然后再汇总。\n\n## 拆分\n\n为了拆分，首先得知道数据块的大小，HTTP 报文首部提供了这样的信息：\n\n- 用 head 方法去获取 http 首部信息，再从获取的信息提取出 `Content-Length` 字段（上文图片大小为 261258 bytes）\n\n```python\nimport requests\n\nheaders = {'Range': 'bytes={}-{}'.format(0, 100000)}\nr = requests.get('http://files.smashingmagazine.com/wallpapers/july-17/summer-cannonball/cal/july-17-summer-cannonball-cal-1920x1080.png', headers = headers)\nwith open('wallpaper.png', 'wb') as f:\n    f.write(r.content)\n```\n\n我们得到了图片的前 100001 个字节（Range 的范围是包括起始和终止的），打开 `wallpaper.png` 你应该能看到一幅“半残”的图。\n\n这样我们里目标更近了一步，继续：\n\n- 确认线程数（比如 8 个），261258//8 = 32657，前 7 个线程都取 32657 个 bytes，第八个取剩余的\n\n\n```python\npart = size // nums\n\nfor i in range(nums):\n        start = part * i\n        if i == num_thread - 1:   # 最后一块\n            end = file_size\n        else:\n            end = start + part\n```\n\n- 每个线程获取到的内容按顺序写入文件（file.seek() 调节文件指针）\n\n\n```python\ndef down(start, end):\n\theaders = {'Range': 'bytes={}-{}'.format(start, end)}\n\t# 这里最好加上 stream=True，避免下载大文件出现问题\n\tr = requests.get(self.url, headers=headers, stream=True)\n\twith open(filename, \"wb+\") as fp:\n        fp.seek(start)\n        fp.write(r.content)\n```\n\n嘛，线程多了起来就扔到线程池让它来帮我们调度。\n\n## 封装\n\n功能复杂了，用对象来封装整理一下：\n\n```python\nclass Downloader(): \n    def __init__(self, url, num, name):\n        self.url = url\n        self.num = num\n        self.name = name\n        r = requests.head(self.url)\n        self.size = int(r.headers['Content-Length']) \n\n    def down(self, start, end):\n        \n        headers = {'Range': 'bytes={}-{}'.format(start, end)}\n        r = requests.get(self.url, headers=headers, stream=True)\n        \n        # 写入文件对应位置\n        with open(self.name, \"rb+\") as f:\n            f.seek(start)\n            f.write(r.content)\n        \n \n    def run(self):\n        f = open(self.name, \"wb\")\n        f.truncate(self.size)\n        f.close()\n        \n        futures = []\n        part = self.size // self.num \n        pool = ThreadPoolExecutor(max_workers = self.num)\n        for i in range(self.num):\n            start = part * i\n            if i == self.num - 1:   \n                end = self.size\n            else:\n                end = start + part - 1\n            # 扔进线程池\n            futures.append(pool.submit(self.down, start, end))\n        wait(futures)\n```\n\n至此，核心功能都完成了，剩下的就是实际体验的优化了。\n\n完整的代码已托管至 GitHub，地址见[这里](https://github.com/WincerChan/Py-Downloader)。\n\n## 结语\n\n很可惜，我写的这个下载器还是不能下载百度云直链，不过嘛，好多人都说结果不重要，都说重要的是过程，不是么？写这个下载器我也确实学到了许多，至于一开始我是出于什么样的目的？管他呢"},{"title":"导出 QQ 聊天记录","subtitle":"","url":"/posts/1060d444/","date":"2017-07-01T07:57:33.000Z","updated":"2019-04-12T02:02:59.000Z","category":"实验室","tags":["QQ","Python"],"content":"## 前言\n\n从 2013 年开始，手机 QQ 就已经不支持私人聊天记录的导出功能了（群聊的记录还是可以导出），目的当然是为了推广超级会员，毕竟超级会员的聊天记录有 2 年漫游时间，而不想给腾讯送钱的我，就只好另辟蹊径了。\n\n<!--more-->\n\n配合视频教程食用更加哦~：https://youtu.be/Y4y-UWg5vco\n\n## 准备\n\n我并不算是那种埋头造轮子的人，所以遇到问题总是先问谷歌，确实也寻找到了一些工具，可惜有的不能用能用的还要收费。看来还是需要自己动手（当然，不动手也就没有这篇文章了）。\n\n### 数据库位置\n\n安卓手机 QQ 的数据库文件保存在 `data/data/com.tencent.monileqq/databases/[QQ 号].db` 下，所以需要 Root（更改 AndroidManifest.xml 的 debuggable 属性之后可以使用 adb 工具导出），这里并非本文的重点，就不展开说了。数据库里面不仅有聊天记录，基本上包括了 QQ 号的所有信息。\n\n不幸的是，里面的重要数据被加密了。\n\n### 加密方式\n\n另外很幸运的是，加密方式采用的是「[异或加密](https://zh.wikipedia.org/zh-hans/%E5%BC%82%E6%88%96%E5%AF%86%E7%A0%81)」，而用于加密的字符串就是你手机的 [IMEI](https://zh.wikipedia.org/wiki/IMEI)，所有手机的 IMEI 都是不同的，这样也可以确保加密后的数据是唯一的，既然知道了加密方式和密钥，那么解密自然也就不是难事了。\n\n## 开始\n\n先想一下，我们聊天记录想导出成什么格式：\n\n我的想法是：`时间--发信人--内容` 这样的格式。打开数据库文件：\n\n如下图，mr_friend_\\** **\\_New 就是你与每一个好友聊天的信息，包括昵称、备注、qq 号码、聊天记录等，直接查看就会发现是被加密过的。这一串 32 位的字符串就是 QQ 号码的 md5 值。\n\n![](https://ae01.alicdn.com/kf/HTB1gaMPKeySBuNjy1zd760PxFXak.png)\n\n\n\n由于 QQ 在手机端使用的数据库是 sqlite，Python 有很方便的 sqlite 的工具，而且 Python 针对字符串处理很方便，这里就采用 Python 来解密。\n\n用浏览工具打开数据库，以我的数据库为例：\n\n![](https://ae01.alicdn.com/kf/HTB1Pf7yKkOWBuNjSspp760PgpXar.png)\n\n`msgData` 保存的就是聊天记录，`selfuin` 就是聊天对象的 QQ 号码，`time `就是发送消息的时间，既然知道了这三个就是我们想要的，那么接下来的就好办多了，解密这三个就好了。\n\n## 解密\n\n既然牵扯到解密，自然也就逃不掉编码和解码。尤其是 `msgData` 项，确实是花费了我好久才解决（哼，我才不会说这是因为我对 Python 的编码不熟悉呢）。\n\n代码已托管至 Gist，见[这里](https://gist.github.com/362331456a6e0417c5aa1cf3ff7be2b7.git)。\n\n参考：\n\n- [用 Python 解密手机 QQ 聊天记录](http://www.freebuf.com/articles/terminal/68224.html)"},{"title":"关于男乒退赛的一点看法","subtitle":"","url":"/posts/2cdb7149/","date":"2017-06-24T02:32:34.000Z","updated":"2017-12-24T10:34:54.000Z","category":"碎碎念","tags":["国乒"],"content":"> 6 月 23 日。马龙、樊振东、许昕宣布退出 2017 年国际乒联中国公开赛。\n\n本来针对这个事，我想写一篇长文来讲讲最近中国某些「魔幻」的地方，奈何后天就要考网络，只好暂且放下。\n\n我一般不在博客上转载文章，不过鉴于这几天实在没有时间写，于是决定转载一下微博的一篇文章，出处已无法考证。\n\n<!--more-->\n\n---\n\n憋了一晚上了，大半夜了，看着事情从最初了英勇豪迈，从振奋人心，担忧，到最后深深的无能为力。\n看它空降热搜，一路爬到第一，半个榜内都是国乒。\n看它被封，被禁，被删博。\n截了一路的图。\n这是国球。\n\n国家体育总局关心的是那几块闪闪发亮的金牌。所以呢，给他们空降教练组长，突然之间毫无征兆的给他们的恩师「另谋高就」，他们没法反抗，禁言，被收手机，不能发声，不能上微博。\n金牌可以再有，但国乒，这个从 2006 到 2016 年，敢在体育总局面前下军令状的梦之队，被瓦崩了，就不能重来。\n看到了吗，从杜塞世乒赛临阵换走孔令辉，到成都公开赛明升暗降刘国梁，风云诡辩，赛场上闪闪发亮的新老双子星，四个大满贯，转眼间就只剩下了马龙一人。\n有人说他们，不爱国，退赛，逃避，搞得和国旗上印的是刘国梁的脸一样。\n那你是没有看过，孔令辉在夺冠后的瞬间扯起衣服亲吻胸口的那个国旗小标。你是没有看过，许昕在赢下赛点后，扯着衣服指给全世界看，他是中国人，然后指着背后的 CHINA 留给世人一个坚不可摧的背影。\n你是没有见过，一个体育项目，2006 至 2016，在漫长的十年里，一个队伍包揽了世界大赛中，他们在制度约束下所能获得的所有金牌银牌，以及铜牌。\n是中国乒乓球。\n爱不爱国，铁骨铮铮，天地可鉴。\n所以为什么他们会放弃他们热爱的赛场，扣除上百的世界排名积分，在一个不用升国旗奏国歌的比赛中以这种极端的方式伸张正义？\n他们心寒。\n孔令辉走了，刘国梁走了。捧起国球一片天，使这个精神漫漫延续的人，都以这样的方式离开了他们所热爱的赛场，不是功满圆退，而是二话不说让你离开。\n国乒在今年刚刚重新聘选重组完教练组，刘国梁说不想从政只想呆在球场。马琳王皓，曾经世界冠军重新回到了国家队，以另一种方式，教练员的方式。\n然而，半年未到，体育总局下令国乒取消总教练主教练职位，设立组长分管男女队，让刘国梁去做乒协副主席。\n连李永波在内，有 20 多位的乒协副主席。\n毫无征兆。\n你让他们如何接受。\n这几天里，从东京到成都，他们到底经历了什么，只有他们自己知道。\n下午蔡振华蔡局到了成都，对刘国梁的卸任发表了态度。\n晚上，所有能发生声的运动员，无论是国家一队二队还是省队，退役没退役，还有教练员，都发了一条微博。他们都选择了用这种方式来抗议。\n后果是什么，禁赛，谩骂，卸甲归田？\n他们知道吗，同样也不知道。\n马龙，赌上了他最好的现在，樊振东，赌上了他前途无量的未来，许昕，赌上了奥运后好不容易重拾的好状态。\n他们怎么可以这么傻。\n国乒不是没了刘国梁就转不下去，也不是没了许昕马龙张继科樊振东就转不下去，事实上，马龙，刘国梁在里约后都有过退役的念头，但是又是什么让他们选择了依旧留在了赛场上？\n是那方寸球台，和牵动着万千国人心的白色小球。\n刘国梁，大满贯。退役后的第一天站在了教练员的位置上，至此，整整十四年。\n在这十四年，他有了两个可爱的女儿，一个叫赢赢，一个叫一一。\n赢，是中国队赢。一，使中国队第一。\n他这半生，都叱咤风云于这赛场，这一生中最重要的人，也与乒乓球挂了勾。\n\n发声，这只是见不惯也不能接受一代功臣沦落如此地步。\n不能反抗，唯有自燃。\n\n没有任何一个项目可以做到如此地步。教练员，运动员，把自己串在一起，做同一条绳上的蚂蚱。\n没有任何一个项目可以做到如此地步。女队教练员不够，男队教练去补，男队教练员不够，那运动员还可以坐镇场外。\n没有一个项目任何一个项目，和乒乓球一样可以看到四面五星红旗闪闪升旗的模样。\n\n拿什么赌？拿自己赌，拿世界第一去赌，拿整个职业生涯去赌。\n他们是连赛后忘记握手都要大肆报道严重批评的运动员，罢赛简直是想都不敢想的事情，而如今却发生了。\n为何会做出如此举动，我们都应该明白。\n\n这是中国乒乓球队历史上最没有把握的一次比赛。\n但我希望他们赢。\n\n那句话没有变，无论怎样都不会变，国乒长虹，剑指东京。\n\n不知道他们在酒店怎么样，有没有手机，看不看得到我们。\n\n如果看得到，想告诉他们。\n\n整个中国都在支持他们。\n\n---\n\n很奇怪，国乒为什么要改革？改革不是应该改掉不好的吗？日本队今年复制中国管理模式，韩国金泽洙回来重新凝聚团队，各国都在学习认可的管理模式，就因为上层的政治斗争，就随意改革？\n\n要建立一个国乒体系花了刘国梁 20 年的心血，而毁掉只需要一个会议。\n\n教练组扁平化，这是好听的说法，真实意思是业务和权力分开，由官僚进行垂直管理，中央集权。新建的“管理组”谁来空降？懂不懂乒乓球？会比一群世界冠军的教练还要懂？和教练组有分歧，谁听谁的？外行领导内行？\n\n政治斗争，高于金牌利益，高于项目，高于运动员。这就是中国体育界。\n\n为什么每一次，都要在巅峰的时候收割别人的心血，提走功勋，然后等低谷了再急巴巴请人来「临危受命」？前有中国女排，后，可能就是乒乓球。\n\n不仅是体育总局，其实这就是中国的现实。\n\n我很乐意看到中国这样最后会变得怎么样 :D"},{"title":"解除百度云下载限速","subtitle":"","url":"/posts/cfd78fa9/","date":"2017-06-15T06:32:00.000Z","updated":"2019-02-19T02:46:10.000Z","category":"分享境","tags":["教程","百度云加速","百度云","限速"],"content":"目前关于破解百度云限速的方法网上提供了许多种，实则是殊途同归，即：高速链接 + 多线程下载工具。而目前获取的链接的方法并非完美且存在一些限制，但聊胜于无。我将目前网上能搜集到的方法一一列举，同时也会针对每个方法的适用性与方便性做出评价。\n\n<!--more-->\n\n## TL; DR\n\nWindows 用 [PanDownload](/#PanDownload)。\n\n其它平台用 [PanDownload 网页版](/#Pandownload)。\n\n## 获取下载直链\n\n这一类方法都是以插件获取下载直链，再辅以多线程下载工具来达到不限速的目的，以下为各个插件的具体说明：（有关多线程下载工具 Axel 见文章末端）\n\n### 下载助手\n\n1. 下载[油猴脚本管理器](http://tampermonkey.net/)\n\n2. 安装[下载助手修改版](https://greasyfork.org/zh-CN/scripts/39776)脚本\n\n3. 打开百度云，勾选需要下载的文件\n\n4. 上方会出现「下载助手」的按钮，依次点击：*压缩按钮 -> 获取压缩按钮*：\n\n   ![下载助手](https://ae01.alicdn.com/kf/HTB1XhIyKkOWBuNjSspp760PgpXaD.png)\n\n此方法适用性应当比较高。以下是 Axel 开启 128 线程的示例：\n\n![下载实例](https://ae01.alicdn.com/kf/HTB1vlqNKgaTBuNjSszf760gfpXaF.png)\n\n缺点就是有些麻烦：需复制 Header 信息才可掉调用下载工具（如 Axel 等）下载，获得 Header 的方法就是打开调试窗口，粘贴该链接在 Chrome 地址栏，在 Network 选项卡中查看该链接的 Request Headers，至少需要将 Cookie、User-Agent 两项传入给下载工具。\n\n> **注意：这里的 Cookie 并不是当前域名（pan.baidu.com）的 Cookie，是 `pcs.baidu.com` 的 Cookie，其实所需要的仅仅是 Cookie 的 `BDUSS` 和 `pcsett` 值**\n\n### Pandownload\n\n在提供 Windows 客户端的同时，PanDownload 还于最近提供了网页版，可直接将分享的文件提取出直链 ：\n\n1. 打开[PanDownload 网页版](https://www.baiduwp.com/)，输入分享链接和提取码\n\n2. 会生成一个包含你想要下载文件的页面，点击\n\n3. 会进入这样的界面：\n\n   ![Pandownload 网页版界面](https://ae01.alicdn.com/kf/HTB1.xsVcUuF3KVjSZK9762VtXXau.png)\n\n直接点击即可通过浏览器下载（如果你想用其它的工具下载，记得传递 Cookie），当然你也可以使用 Aria2 RPC 下载。\n\n这是我使用 Aria2 下载的速度，配置文件见[这里](https://gist.github.com/WincerChan/40a63819b0fdd629e57e202ad82dbbee)：\n\n![配合 Aria2 的速度](https://ae01.alicdn.com/kf/HTB1Ql7VcUGF3KVjSZFv762_nXXa3.png)\n\n此方法的优点在于不用安装额外的浏览器插件，也不用下载客户端，比较方便手机和 Linux 用户。缺点在于 Aari2 的线程仍然有限，所以速度不会特别快，但也算比较理想了。\n\n### BaiduExporter\n\n> ~~自本文最近一次更新起，该方法获取的链接已无法在 Axel 中使用，原因是 URL 参数中的 app_id 失效，但这失效的 app_id 的 URL 却仍然可以用 aria2c 下载。~~可以使用我 [Fork 后修改](https://github.com/WincerChan/BaiduExporter)的版本作为代替。\n>\n> 我的小号在使用这个方法的时候被封了，直接 403，更换帐号后可正常下载。被封之后大概两天内会解封。建议线程数不要开太多，被封之后可以更换速盘下载。\n\n1. clone 该仓库\n\n2. *Chrome -> 更多工具 -> 扩展程序 -> 加载已解压的扩展程序（需勾选开发者模式） -> chrome/release（文件夹）*\n\n3. 进入想要下载文件的界面\n\n4. 勾选，点击 *导出下载 -> 文本导出 -> 拷贝下载链接*：![导出下载](https://ae01.alicdn.com/kf/HTB11O.dttcnBKNjSZR0763FqFXam.png)\n\n5. 复制链接后，是一串格式类似以下内容的命令：\n\n   ```bash\n   axel -o \"xxxxxx\" -H \"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\" -H \"Cookie: BDUSS=9aRnpJYjF-THlHUbbjxkTYUnjk^&8naddR2NscTF-cFZJVWV3cDBvVkVaeHpHOFNJcXRhQVFBQUFBJCQAAAAAAAAAAAEAAADvjlIvY3cwODI5OQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABKVg1oSlYNaS0; pcsett=4789643579-hukfa445465a15156c1515a5f12cxzw4\" \"URL\" -n 233\n   ```\n\n   其中包含两个 HTTP 首部信息：分别是 UA、Cookie，这两个信息在上一步骤的框里均会显示，**不要直接复制我的，Cookie 会过期**。其中最后一个参数 `-n 233` 是需要你手动输入的线程数量，即为采取 233 个线程下载。\n\n[该项目](https://github.com/acgotaku/BaiduExporter)算是目前比较完美的解决方案了，以下是使用 Axel 开启 256 个线程后的速度（不要在意中间的乱码）：\n\n![截图](https://ae01.alicdn.com/kf/HTB1YuS7B5OYBuNjSsD4762SkFXai.png)\n\n原项目是将链接导出至 ariac2 下载，但是 ariac2 却只能最多开启 16 个线程，这对一般下载任务也够了，但是对于百度这种老流氓来说（每个连接限速至 10Kb/s ），还是不够用的，所以我 Fork 后采用 Axel 代替 ariac2，Axel 可以设置任意连接数）。\n\n此方法也是我目前一直在使用的方法。\n\n### ADM + ES\n\n这个方法是酷安上流传已久的方法，但我一直都无法满速，还是在这里提一下吧，造福一下手机党：\n\n1. 安装 [ES 文件浏览器](https://www.coolapk.com/apk/com.estrongs.android.pop)\n2. 安装 ADM（酷安手机客户端下载）\n3. ADM 线程数调至最高\n4. 修改 User-Agent：*ADM -> 设置 -> 下载 -> 用户代理 -> \\<Custom>*，将以下内容复制进去：`netdisk;7.8.1;Red;android-android;4.3`\n5.  *ES 文件浏览器 -> 网络 -> 新建 -> 百度网盘*，随后登录就会进入网盘界面，进入文件夹找到需要下载的文件后 *长按 -> 更多 -> 打开为 -> 视频 -> ADM*，这样就会调用 ADM 下载了\n\n同样该方法并非完美，用「ES 文件浏览器」获取的百度云链接只能在该手机端使用，因为该链接是通过本地端口远程链接所生成的，故还是有一些限制，速度不稳定（会有一些不稳定的波动）：\n\n![ADM 下载](https://ae01.alicdn.com/kf/HTB1hMjxB2uSBuNkHFqD760fhVXaI.png)\n\n## 第三方客户端\n\n这一类方法使用的是别人已经封装好了的第三方客户端，其实就相当于把 获取链接的插件 + 多线程下载工具 打包好成为一个客户端。比上一类方法方便性会强一些，但适用性会弱一些。\n\n### PanDownload\n\n该软件只有 Windows 版。\n\n[该软件](https://pandownload.com/document/download.html)不仅支持加速下载，并支持在线解压缩，并且文档很详细。\n\n并且个人认为比速盘好，我有时候使用速盘下载提示限速，但此软件却能达到满速，推荐使用。\n\n### 速盘\n\n[该软件](https://www.speedpan.com/)同样是由爱吾一位大神创作，同样只有 Windows 版。\n\n![SpeedPan 1](https://ae01.alicdn.com/kf/HTB1wVyNKqmWBuNjy1Xa760CbXXah.png)\n\n与其它软件的不同之处在于它还支持网盘资源搜索的功能。\n\n据说是支持直接通过分享链接下载的，但我试了一下通过分享链接下载总是报错。但登录后下载还是可以的。\n\n![SpeedPan 2](https://ae01.alicdn.com/kf/HTB18HzCKeuSBuNjy1Xc763YjFXaP.png)\n\n### BaiduPCS-Go（全平台）\n\n[该项目](https://github.com/iikira/BaiduPCS-Go)是使用 Go 语言编写的**命令行**客户端，支持下载、分享、上传、离线下载等功能。\n\n我没有使用过该项目，但该项目在 GitHub 上收获 6.5k 的 star，应当是获得了许多人的认可。\n\n## 附 Axel 使用方法\n\n我为什么提倡使用 Axel 来代替 aria2c 作为多线程下载工具呢，原因是 aria2c 最多只能设置 16 线程下载，虽说网上有修改成 512 线程的版本，但我试了之后发现速度并没有提升。而 Axel 对此则没有限制。\n\n### 安装\n\n该软件已经附在各发行版的源仓库中了，直接安装就行。对于 Windows 来说可以自行从源码编译，这是[教程](https://github.com/axel-download-accelerator/axel#3-building-from-source)。\n\n### 使用\n\n终端输入 `axel --help`：\n\n```bash\n用法: axel [选项] 地址1 [地址2] [地址...]\n\n--max-speed=x\t\t-s x\t指定最大速率（字节 / 秒）\n--num-connections=x\t-n x\t指定最大连接数\n--output=f\t\t-o f\t指定本地输出文件\n--search[=x]\t\t-S [x]\t搜索镜像并从 X 服务器下载\n--no-proxy\t\t-N\t不使用任何代理服务器\n--quiet\t\t\t-q\t使用输出简单信息模式\n--verbose\t\t-v\t更多状态信息\n--alternate\t\t-a\t文本式进度指示器\n--help\t\t\t-h\t帮助信息\n--version\t\t-V\t版本信息\n```\n\n本文持续更新中。"},{"title":"Manjaro 大法好","subtitle":"","url":"/posts/7e325dad/","date":"2017-06-08T13:18:32.000Z","updated":"2017-06-10T12:17:29.000Z","category":"碎碎念","tags":["KDE","Linux"],"content":"### 前言\n\n从去年 8 月到现在，终于无法忍受 Ubuntu 了，原因有以下几点：\n\n1. 依赖太过混乱，自带 Python 默认版本居然是 2.7，而且更改默认版本后安装软件会各种报错\n2. 时不时报一个内部错误\n3. 软件版本更新太慢\n\n考虑到以上三点，我选择了  [Arch](https://www.archlinux.org/) 系的 [Manjaro Linxu](https://manjaro.org/)，选择 Arch 是因为去年有装过，是滚动更新模式，提供最新版本的软件，而不直接用的原因是安装步骤太过繁琐，没有必要，故而选择了基于 Arch 的 Manjaro 发行版。\n<!--more-->\n###  制作启动盘\n\n建议采用「[rufus](https://rufus.akeo.ie/)」烧制到 u 盘，制作的时候选择 dd 模式，不要选择 iso 模式，否则会无法从 u 盘启动，随后一路点点点。\n\n### 安装后的配置\n\n安装完成后，界面挺丑的，首先：\n\n1. 更换中国的源，建议 USTC，这是[教程](https://mirrors.ustc.edu.cn/help/manjaro.html)\n2. 换一张壁纸\n3. 将面板从底部删除，在顶部新建一个，添加一些部件\n4. 工作空间主题中更换观感和桌面主题\n5. 应用风格中更换窗口样式\n6. 更换图标包\n7. fcitx 输入法\n8. 安装 docky\n9. 美化终端，安装 zsh、Oh my zsh、powerline\n10. 配置 conky（之前 Ubuntu 上的不知道为什么不能用了）\n\n### 使用感想\n\n1. Arch 的包管理 pacman 比 Ubuntu 的不知道高到哪里去了，还有 Octopi 图形界面客户端\n2. 特效比 Ubuntu 华丽多了\n3. 可随意切换工作区，效率确实高了一些\n4. KDE 设置确实较多，需要花时间\n5. KDE Connect 简直方便到爆炸！\n\n### 效果图\n\n![](https://res.cloudinary.com/wincer/image/upload/v1530861702/blog/manjaro_great/result.png)"},{"title":"Hexo 博客备份","subtitle":"","url":"/posts/7efd2818/","date":"2017-06-02T13:37:00.000Z","updated":"2017-06-14T12:44:33.000Z","category":"博客栈","tags":["Hexo","教程","博客"],"content":"使用 Hexo 在 GitHub Pages 搭建博客时，博客作为一个单独的 GitHub 仓库存在，但是这个仓库只有生成的静态网页文件，并没有 Hexo 的源文件。这样一来换电脑或者重装系统后，再想找回源文件就比较麻烦了，这里推荐一种比较完美的方法解决备份问题。\n\n<!--more-->\n\n## 备份\n\n1. 创建仓库 [WincerChan.github.io](https://github.com/WincerChan/MyBlog)，如果同名仓库之前已经创建，请将之前的仓库改名，新建的仓库必须是 Username.github.io（如果你是将 Hexo 博客部署到了自己的服务器，那么仓库名可以随意设置，我这里就是随意设置的仓库）；\n2. 创建两个分支：master 和 hexo；\n3. 设置 hexo 为默认分支；\n4. 将刚刚创建的新仓库 `clone` 至本地，将之前的 hexo 文件夹中的 _config.yml、themes/、source/、scaffolds/、package.json 和 .gitignore 复制至 WincerChan.github.io 文件夹；\n5. 将 themes/next/（我用的是 NexT 主题）中的 `.git/` 删除，否则无法将主题文件夹 push（也可以将主题文件夹使用[子模块](https://git-scm.com/book/zh/v1/Git-%E5%B7%A5%E5%85%B7-%E5%AD%90%E6%A8%A1%E5%9D%97)的方式添加到该仓库)；\n6. 在 WincerChan.github.io 文件夹执行 `npm install` 和 `npm install hexo-deployer-git`（这里可以看一看分支是不是显示为 hexo）；\n7. 执行 `git add`、`git commit -m \"\"`、`git push origin hexo` 来提交 hexo 网站源文件；\n8. 执行 `hexo g -d` 生成静态网页部署至 Github 上。\n\n这样一来，[WincerChan.github.io](https://github.com/WincerChan/MyBlog) 仓库就有 master 分支和 hexo 分支，分别保存静态网页和源文件。\n\n## 修改\n\n在本地对博客修改（包括修改主题样式、发布新文章等）后：\n\n1. 依次执行 `git add`、`git commit -m \"\"` 和 `git push origin hexo` 来提交 hexo 网站源文件；\n2. 执行 `hexo g -d` 生成静态网页部署至 Github 上。\n\n即重复备份的 7-8 步骤，以上两步没有严格的顺序。\n\n## 恢复\n\n重装电脑后，或者在其它电脑上想修改博客：\n\n1. 安装 git；\n2. 安装 Nodejs 和 npm；\n3. 使用 `git clone git#github.com:WincerChan/WincerChan.github.io.git` 将仓库拷贝至本地；\n4. 在文件夹内执行以下命令 `npm install hexo-cli -g`、`npm install`、`npm install hexo-deployer-git`。\n\n## 附录\n\n这里稍作说明：\n\n### 添加 ssh-keys\n\n1. 在终端下运行：`ssh-keygen -t rsa -C \"yourname#email.com\"`，一路回车；\n2. 会在 .ssh 目录生成 `id_rsa`、`id_rsa.pub` 两个文件，这就是密钥对，id_rsa 是私钥，千万不能泄漏出去；\n3. 登录 Github，打开「Settings」-->「SSH and GPG keys」，然后点击「new SSH key」，填上任意 Title，在 Key 文本框里粘贴公钥 `id_rsa.pub` 文件的内容，注意不要粘贴成 `id_rsa`，最后点击「Add SSH Key」。\n\n### hexo 的源文件\n\n这里说一下步骤 4 为什么只需要拷贝 6 个，而不需要全部：\n\n1. `_config.yml `站点的配置文件，需要拷贝；\n2. `themes/ `主题文件夹，需要拷贝；\n3. `source` 博客文章的 .md 文件，需要拷贝；\n4. `scaffolds/` 文章的模板，需要拷贝；\n5. `package.json` 安装包的名称，需要拷贝；\n6. `.gitignore` 限定在 push 时哪些文件可以忽略，需要拷贝；\n7. `.git/` 主题和站点都有，标志这是一个 git 项目，不需要拷贝；\n8. `node_modules/` 是安装包的目录，在执行 `npm install` 的时候会重新生成，不需要拷贝；\n9. `public` 是 `hexo g` 生成的静态网页，不需要拷贝；\n10. `.deploy_git` 同上，`hexo g` 也会生成，不需要拷贝；\n11. `db.json `文件，不需要拷贝。\n\n其实不需要拷贝的文件正是 `.gitignore` 中所忽略的。\n\n### 持续部署\n\n关于如何使用 CI/CD 持续部署可以参考我[这篇文章](/posts/f011ea9c/)。"},{"title":"端午记","subtitle":"","url":"/posts/859c63e4/","date":"2017-05-27T16:09:20.000Z","updated":"2017-12-24T12:02:59.000Z","category":"碎碎念","tags":["随感","日记"],"content":"5 月马上就要过去\n\n似乎还没开始的这个学期，怎么就快结束了\n\n时间怎么这么快？\n\n<!--more-->\n\n长眠于 4 月之前的海子，对于时间，有一个生动的说法叫「打马而过」\n\n有时觉得，这种匀速流淌不可改变的东西，才是真 TMD 残忍。\n\n雨滴的出生到结束，就是从天空落向大地\n\n似乎它的宿命就是滴落大地\n\n---\n\n回到家中，躺在沙发上\n\n空气中弥漫着「熟悉的味道」\n\n想必那就是家的味道吧？\n\n---\n\n临近期末\n\n似乎应该很担心成绩挂科\n\n我理想中的大学不是这样的\n\n我讨厌把自己的能力和思考，都锁在一个 for 循环里\n\n循环的条件是：你是一个大学生\n\n那样该多无趣啊\n\n我想 break，就像现在躺在沙发上\n\n可以暂时跳出这个循环\n\n---\n\n突兀的断网\n\n调试了许久之后\n\n终于意识到可能没有网了\n\n这是 break 出循环的代价？\n\n---\n\n在家里总可以敞开去吃\n\n喝啤酒到胃涨还能强迫去吃饭\n\n吃的饱了\n\n总算能真切感受到自己不在循环里\n\n---\n\n明媚而灿烂的五月啊\n\n要是心情烦躁的时候，写写博客吧\n\n这也是断网唯一能做的开心事了"},{"title":"书推：雪中悍刀行","subtitle":"","url":"/posts/9a260fa1/","date":"2017-05-06T05:45:54.000Z","updated":"2017-12-24T12:21:29.000Z","category":"文字阁","tags":["书推","文摘"],"content":"### 简介\n\n有个白狐儿脸，佩双刀绣冬春雷，要做那天下第一；\n\n湖底有白发老魁爱吃荤；\n\n缺门牙老仆背剑匣；\n\n山上有个骑青牛的年轻师叔祖，不敢下山；\n\n有个骑熊猫扛向日葵不太冷的少女杀手；\n\n这个江湖，高人出行要注重出尘装扮，女侠行走江湖要注意培养人气，宗派要跟庙堂打好关系；\n\n而主角，则潇洒带刀，把江湖捅了一个通透；\n\n江湖是一张珠帘。大人物小人物，是珠子，大故事小故事，是串线。情义二字，则是那些珠子的精气神。\n\n<!--more-->\n\n\n### 简评（转）\n\n年少时，看武侠电视剧里的侠踪剑影，总是莫名憧憬，甚至意犹未尽处，还会忍不住幻想自己是位飞流倜傥、快意恩仇的大侠，剑收于鞘时渊渟岳峙、剑起时又能挥出一片水银泻地云卷云舒。\n\n日思夜想久了，于是便在心中有了一片江湖，有了一场江湖梦。\n\n我想不止我是如此。\n\n有句老话说，一千个读者的心中，就有一千个哈姆雷特。\n\n同样的，一千个被现实社会的条条框框桎梏住的俗人们心间，便也有一千座不同的江湖。\n\n求名者得名、求利者得利、求快意者得快意、求安稳者得安稳——这些在现实中并不存在的江湖就像是我们圆梦的地方，我们被称之为“规矩”“方圆”“社会准则”的枷锁束缚得越紧，就越是想要在内心最深处那片江湖里翻江倒海自在逍遥。\n\n说白了，我们心中江湖上的那个状若侠客的自己，才是我们真正想成为的自己。\n\n但人生有太多弯路，太多不可回头的路，一步踏错便再无转圜的余地，南辕北撤说的便是这个道理——有时候回头看，我们一路行来的方向，竟是和最初的梦想背道而驰，可我们被所谓社会的进步、所谓年轻人的成熟、所谓命运的安排这一类的东西追迫着、驱赶着，又着实没有时间停下来感伤，于是渐行渐远、梦想和现实也被拉扯得越来越沧海桑田。\n\n到最后，我们的梦想，只剩下一副骨架、一副残骸，即是那座每每热血沸腾时便在心间浮起的海市蜃楼般的偌大一个江湖。\n\n在那个江湖里，我们是最自在最洒脱不羁的那位侠客。\n\n### 文摘\n\n---\n\n**李淳罡**：\n\n1. 大雨依旧磅礴。\n\n   她不起身，徐凤年便一直撑着伞。\n\n   老剑神李淳罡望向这一幕，瞪大眼睛。\n\n   随即眼中黯然落寞缅怀追忆皆有。\n\n   那一年背负那女子上斩魔台，一样是大雨天气，一样是撑伞。\n\n   世人不知这位剑神当年被齐玄帧所误，木马牛被折并不算什么，只剩独臂也不算什么，这都不是李淳罡境界大跌的根由，哪怕在听潮亭下被困二十年，李淳罡也不曾走出那个自己的画地为牢。\n\n   原本与世已是无敌，与己又当如何？\n\n   李淳罡想起她临终时的容颜，当时她已说不出一个字，可今曰想来，不就是那不悔两字吗？\n\n   李淳罡走到大雪坪崖畔，身后是一如他与绿袍女子场景的撑伞男女。\n\n   她被一剑洞穿心胸时，曾惨白笑言：“天不生你李淳罡，很无趣呢。”\n\n   李淳罡大声道：“剑来！”\n\n   徽山所有剑士的数百佩剑一齐出鞘，向大雪坪飞来。\n\n   龙虎山道士各式千柄桃木剑一概出鞘，浩浩荡荡飞向牯牛大岗。\n\n   两拨飞剑。\n\n   遮天蔽日。\n\n   这一日，剑神李淳罡再入陆地剑仙境界。\n\n\n---\n\n**洪洗象**：\n\n1. 正在经楼找寻一部典籍的陈繇踉跄跑到窗口，颤颤巍巍推开窗户，老泪纵横，嘴唇颤抖道：“王师兄，小师弟成了！”\n\n   山中炼丹的宋知命顾不得一鼎炉被凡人视作仙物的丹药，扑通一声跪下去，磕头道：“武当三十六弟子宋知命，恭迎祖师爷！”\n\n   在东海寻觅到一名骨骼清奇闭关弟子的俞兴瑞，正坐蒲台上传授那名弟子内功心法，抚掌大笑，笑出了眼泪，激动万分道：“李玉釜，你掌教师叔终于要下山了！”\n\n   七十二峰朝大顶，二十四涧水长流。其中最长一条飞流直下的瀑布犹如神助，低端被掀起拉直，通向毗邻那座唯有一名年轻道人修习天道的小莲花峰，瀑布如一条白练横贯长空，数万香客见到此景，仿佛置身仙境，更加寂静无声，偌大一座武当山，几乎落针可闻。水起作桥为谁横？齐仙侠亲眼见到古剑连鞘飞出太虚宫，尾随其后，沿着悬挂两峰峰顶水桥奔掠向小莲花峰，看到骑牛的怔怔靠着龟驼碑，喃喃自语：“今曰解签，宜下江南。”\n\n   一身朴素道袍的洪洗象拍了拍尘土，骑上一只体型巨大的黄鹤，望向江南。\n\n   江南好，最好是红衣。\n\n2. 徐脂虎缓缓转头，问道：“你到底是谁？”  一直被寄予厚望去肩扛天道的年轻道士羞赧嚅喏道：“洪洗象啊。”\n\n   徐脂虎重复问道：“你来做什么？”\n\n   年轻道士壮着胆子说道：“那年在莲花峰，你说你想骑鹤。”\n\n   她转过身，背对着这个胆小鬼。\n\n   这个放言要斩断赵氏王朝气运的道人，深呼吸一口，笑道：“徐脂虎，我喜欢你。” \n\n   “不管你信不信，我已经喜欢你七百年。” \n\n   “所以这世上再没有人比我喜欢你更久了。” \n\n   “下辈子，我还喜欢你。”\n\n   丫鬟二乔眨巴眨巴水灵眸子，小脑袋一团浆糊，只看到小姐捂着嘴哭哭笑笑的，就更不懂了，唉，看来小姐说自己年纪小不懂事是真的呀。\n\n   年轻道士伸出手，轻声道：“你想去哪里，我陪你。”\n\n   这一曰，武当年轻掌教骑鹤至江南，与徐脂虎骑鹤远离江湖。\n\n   仙人骑鹤下江南，才入江湖，便出江湖。\n\n3. 年轻道士深呼吸一口，等女子依偎在他怀中，那柄横放在龟驼碑边缘的所谓吕祖佩剑出鞘，冲天而起，朝天穹激射而去，仿佛要直达天庭才罢休。\n\n   九天之云滚滚下垂。\n\n   整座武当山紫气浩荡。\n\n   他朗声道：“贫道五百年前散人吕洞玄，五十年前龙虎山齐玄帧，如今武当洪洗象，已修得七百年功德。”\n\n   “贫道立誓，愿为天地正道再修三百年！”\n\n   “只求天地开一线，让徐脂虎飞升！”\n\n   年轻道士声如洪钟，响彻天地间。\n\n   “求徐脂虎乘鹤飞升！”\n\n   黄鹤齐鸣。\n\n   吕祖转世的年轻道士盘膝坐下，望着注定要兵解自己的那下坠一剑，笑着合上眼睛。\n\n   陈繇等人不忍再看，老泪纵横。\n\n   有一虹在剑落后，在年轻道士头顶生出，横跨大小莲花峰，绚烂无双。\n\n   千年修行，只求再见。\n\n---\n\n**轩辕敬城：**\n\n1. 修身在正其心。\n\n   莫道书生无胆气，敢叫天地沉入海。\n\n   成事者，不惟有超世之才，亦必有坚韧不拔之志。\n\n   轩辕青锋脑海中走马观灯，那些诗词文章一一浮现。\n\n   “我入陆地神仙了。”\n\n   轩辕敬城闭上眼睛，只见他七窍流血，却神情自若地双手摊开，似乎想要包容那整座天地。\n\n   以他为圆心，大雪坪积水层层向外炸起。\n\n   那一瞬间，有九道雷电由天庭而来。\n\n2. 辕敬城每年酿当归酒三坛，两坛都让人送来庭院，自己只余一坛。\n\n   所以他从来都是喝不够酒，而这里却是从来不喝，任由年年两坛酒搁着闲置，年复一年，酒坛子越多，酒香也愈发醇厚。\n\n   她终于启封一坛酒，搬来一套尘封多年的酒具，酒具是那男人自制而成。\n   反正除了习武，那人仿佛没有不擅长的事情。\n\n   独坐的她盛了一杯酒，放在桌上，好似对于喝不喝酒，犹豫不决，她没来由开始恼恨自己，伸手猛地拍掉酒杯。\n\n   半响后她起身去拿回酒杯，才发现杯底刻有两行小字，字迹清逸出尘。\n\n   人生当苦无妨，良人当归即好。\n\n\n---\n\n**许涌关：**\n\n1. 一刹那。\n\n   瞎子老许头脑一片空白。\n\n   他既然能活着走下累累白骨破百万的沙场，能是一个蠢蛋？\n\n   在北凉，谁敢说这一句徐骁不过是驼背老卒？\n\n   除了大柱国，还有谁？\n\n   瞎子老许那一架需要拐杖才能行走的干枯身体剧烈颤颤巍巍起来。\n\n   最后这位北凉赖活着的老卒竟是泪流满面，转过头，嘴唇颤抖，哽咽道：“大柱国？”\n\n   那人并未承认也未否认，只是喊了一声瞎子老许：“许老弟。”\n\n   只见瞎子老许如同癫狂，挣扎着起身，不顾大柱国的阻止，丢掉拐杖，跪于地上，用尽全身所有力气，用光了三十年转战六国的豪气，用光了十年苟延残喘的精神，死死压抑着一位老卒的激情哭腔，磕头道：“锦州十八-老字营之一，鱼鼓营末等骑卒，许涌关，参见徐将军！”\n\n   锦州十八营，今曰已悉数无存，如那威名曰渐逝去的六百铁甲一样，年轻一些的北凉骑兵，最多只是听说一些热血翻涌的事迹。\n\n   鱼鼓营。\n\n   号称徐字旗下死战第一。\n\n   最后一战便是那西垒壁，王妃缟素白衣如雪，双手敲鱼鼓营等人高的鱼龙鼓，一鼓作气拿下了离阳王朝的问鼎之战。近千人鱼鼓营死战不退，最终只活下来十六人，骑卒许涌关，便是在那场战役中失去一目，连箭带目一同拔去，拔而再战，直至昏死在死人堆中。\n\n   其实，在老卒心中，大柱国也好，北凉王也罢，那都是外人才称呼的，心底还是愿意喊一声徐将军！\n\n   被徐骁搀扶着重新坐在木墩上的瞎子老许，满脸泪水，却是笑着说道：“这辈子，活够了。徐将军，小卒斗胆问一句，那徐小子莫不是？”\n\n    徐骁轻声道：“是我儿徐凤年。”\n\n   老卒脸贴着被大柱国亲手拿回的拐杖，重复呢喃道：“活够了，活够了……”\n\n   鱼鼓营最后一人，老卒许涌关缓缓闭目。\n\n   徐将军，王妃，有一个好儿子啊。\n\n   我老许得下去找老兄弟们喝酒去了，与他们说一声，三十万北凉铁骑的马蹄声只会越来越让敌人胆寒，小不去，弱不了。\n\n   徐字王旗下，鱼龙鼓响。\n\n   老卒许涌关，死于安详。\n\n---\n\n**温华：**\n\n1. 一个时辰后黄龙士缓缓走下马车，马车渐渐远去，消失于风雪中。\n\n   黄龙士没有急于入院，而是在巷弄来回走了两趟，这才推开门扉。\n\n   短短一炷香后，一名年轻男子断一臂，瘸一腿，自断全身筋脉，只存一条性命，只拎上那柄原本就属于自己的木剑，离开了院子。\n\n   巷中雪上长长一条血。\n\n   “在老子家乡那边，借人钱财，借你十两就还得还十二三两，我温华的剑，是你教的，我废去全身武功，再还你一条手臂一条腿！”\n\n   他在院中，就对那个黄老头说了这么一句话。\n\n   然后这个雪中血人在拐角处颓然蹲下，手边只剩下一柄带血木剑。\n\n   年轻游侠儿泪眼模糊，凄然一笑，站起身，拿木剑对准墙壁，狠狠折断。\n\n   此后江湖再无温华的消息，这名才出江湖便已名动天下的木剑游侠儿，一夜之间，以最决然的苍凉姿态，离开了江湖。\n\n   刺骨大雪中，他最后对自己说了一句。\n\n   “不练剑了。”\n\n---\n\n**徐凤年：**\n\n1. 徐凤年闭上眼睛，双手搭在春雷上，有些明白一些事情了，为何徐骁如今还像个老农那般喜欢缝鞋？轩辕敬城本该像张巨鹿那般经略天下，最不济也可以去跟荀平靠拢，却被自己堵在了一家三口的家门以外，堵在了轩辕一姓的徽山之上，即使一举成为儒圣，仍是不曾跨出半步。骑牛的最终还是下了山，但这种下山与在山上，又有什么两样？羊皮裘李老头儿十六岁金刚十九岁指玄二十四岁达天象，为何断臂以后仍是在江上鬼门关为他当年的绿袍儿，几笑一飞剑？\n\n   说到底，都是一个字。\n\n   徐凤年想着她的酒窝，摇晃站起身。\n\n   他就算不承认，也知道自己喜欢她。不喜欢，如何能看了那么多年，却也总是看不厌？\n\n   只是不知道，原来是如此的喜欢。\n\n   既然喜欢了，却没能说出口，那就别死在这里！\n\n   徐凤年睁眼以后，拿袖口抹了抹血污，笑着喊道：“姜泥！老子喜欢你！”\n\n   拓跋春隼冷笑不止，只不过再一次笑不出来。\n\n   一名年轻女子御剑而来，身后有青衫儒士凌波微步，逍遥踏空。\n\n   女子站在一柄长剑之上，在身陷必死之地的家伙身前悬空。\n\n   她瞪眼怒道：“喊我做什么？不要脸！”\n\n---\n\n**李当心：**\n\n1. 唉，闺女，等你大些，就会明白只要在一个男人心中好看，你就是天下最好看的姑娘了。”\n\n   “啊？可徐凤年说我长得一般呐，完了！”\n\n   “闺女真是长大了，娘很欣慰呐。闺女，娘真不好看？不行，再下山一趟，还得买些胭脂水粉，多扑一些在脸上就好看了。”\n\n   “娘你又乱花钱，爹肯定要跟笨南北蹲墙角唠叨去了，他们一起叨叨叨，可烦了。”\n\n   “让他们叨叨去。哪天不叨了才不好。”\n\n   这娘俩，似乎挺俗气。\n\n   亏得各自身后爱慕着她们两个的光头，是那般佛气。\n\n   小和尚将洗好的袈裟晾好，望向房内自语到，“又是一个天晴的好日子。李子，师父说我没悟性，你也说我笨，咱们寺里两个禅，我都不修。你便是我的禅，秀色可参。”\n\n   千山以外是千山，这就是江山；六宫粉黛独看你，这就是美人。\n\n   白衣僧人笑道：“去吧，睡觉去。” 小和尚嗯了一声，道：“东西怕打雷，我去门外给她念经去。” 白衣僧人摸了摸自己光头，这徒弟。站在千佛殿门口，看到在泥泞中奔跑顾不得雨水的笨南北，白衣僧人呢喃道：“笨南北啊，你有一禅，不负如来不负卿。\n\n   少妇才喊完，嗖一下，一名白衣僧人就以屁滚尿流的姿态窜出那栋巍峨阁楼，来到少妇面前，笑呵呵道：“媳妇，走累了没，给敲敲腿？”\n\n   若是外人在场，定要认为以这女子一路行来表现出的蛮横，肯定要好生拾掇一番白衣僧人才会罢休，但真见着了自己男人，她却是轻柔说道：“不累呢，只是好几天没见着你，有点想你啦。”\n\n   本名原来是李当心的白衣僧人笑容醉人，也不说话。\n\n   既然有她，天下无禅。"},{"title":"Hello World","subtitle":"","url":"/posts/4a17b156/","date":"2017-05-05T05:38:10.000Z","updated":"2017-12-24T10:38:28.000Z","category":"碎碎念","tags":["随笔","Hexo","NexT"],"content":"**在**朋友的推荐下，这个简易的博客搭建起来了。\n\n**折腾**了一天多，第一天结束的时候在 Github Pages 上看到自己的博客加载出来的时候，突然有种错综复杂的恍惚感。是的，它不是自己的 QQ 空间，不是新浪博客，不是豆瓣小站，也不是百度贴吧。它更像是属于自己的一块小小的领地，因而我满足这种归属感。我愿意、更乐于在上面安静劳作。\n\n**一个**之前为地主打工的农民，现在通过自身努力终于分到了一块地，不再需要帮地主的土地创造价值时，于是，这个农民重生了，他可以自豪的宣告：Hello World。当然，这个农民确切的来说是个码农。<!--more-->\n\n**主题**采用的是 Next，很好看的主题，使用文档见[这里](http://theme-next.iissnan.com/)。"}]